{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import eli5\n",
    "import joblib\n",
    "import wordcloud\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from colour import Color\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.preprocessing import minmax_scale, scale\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from mlgear.cv import run_cv_model\n",
    "from mlgear.models import runLR\n",
    "from mlgear.utils import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      engagement  engagement_changed  \\\n",
      "1              3                   0   \n",
      "2              2                   0   \n",
      "3              2                  -4   \n",
      "4              5                   0   \n",
      "5              5                   3   \n",
      "...          ...                 ...   \n",
      "2510           3                   3   \n",
      "2511           3                   1   \n",
      "2512           3                   0   \n",
      "2513           5                  -4   \n",
      "2514           5                   2   \n",
      "\n",
      "                                 why_engagement_changed NPS  \\\n",
      "1                                                     0  -8   \n",
      "2                                                     0  -7   \n",
      "3                                                     0   0   \n",
      "4                                                     0  -7   \n",
      "5     More engaged in the events/conferences related...  -9   \n",
      "...                                                 ...  ..   \n",
      "2510        Started to understand and to share the idea  -8   \n",
      "2511               Reading and thinking more about EA.   -8   \n",
      "2512                                                  0  -9   \n",
      "2513                                                  0   0   \n",
      "2514  I got a full-time job working in EA and think ...  -9   \n",
      "\n",
      "                                                details  \\\n",
      "1                                                     0   \n",
      "2                                                     0   \n",
      "3                                                     0   \n",
      "4     Too many weird/awkward people.  Too cultish an...   \n",
      "5     The ethnic diversity in the EA community seems...   \n",
      "...                                                 ...   \n",
      "2510                                                  0   \n",
      "2511                                                  0   \n",
      "2512                                                  0   \n",
      "2513                                                  0   \n",
      "2514  The community is a collection of many of the k...   \n",
      "\n",
      "      barrier_EA_too_demanding  barrier_limited_advice  barrier_no_jobs  \\\n",
      "1                            0                       0                0   \n",
      "2                            0                       0                0   \n",
      "3                            0                       0                0   \n",
      "4                            0                       0                0   \n",
      "5                            0                       0                0   \n",
      "...                        ...                     ...              ...   \n",
      "2510                         0                       0                1   \n",
      "2511                         0                       0                0   \n",
      "2512                         0                       0                0   \n",
      "2513                         0                       0                0   \n",
      "2514                         0                       0                0   \n",
      "\n",
      "      barrier_jobs_too_hard  barrier_idk_donate  barrier_idk_movement_build  \\\n",
      "1                         0                   0                           1   \n",
      "2                         0                   0                           0   \n",
      "3                         0                   0                           0   \n",
      "4                         0                   0                           0   \n",
      "5                         1                   0                           0   \n",
      "...                     ...                 ...                         ...   \n",
      "2510                      1                   0                           0   \n",
      "2511                      1                   0                           0   \n",
      "2512                      0                   0                           0   \n",
      "2513                      0                   0                           0   \n",
      "2514                      0                   0                           1   \n",
      "\n",
      "      barrier_no_mentor  barrier_no_diverse  barrier_unwelcoming  \\\n",
      "1                     1                   0                    0   \n",
      "2                     0                   0                    0   \n",
      "3                     0                   0                    0   \n",
      "4                     0                   1                    0   \n",
      "5                     1                   0                    0   \n",
      "...                 ...                 ...                  ...   \n",
      "2510                  0                   0                    0   \n",
      "2511                  0                   0                    0   \n",
      "2512                  0                   0                    0   \n",
      "2513                  0                   0                    0   \n",
      "2514                  0                   0                    0   \n",
      "\n",
      "      barrier_elitist  barrier_no_social  barrier_no_friends  \\\n",
      "1                   0                  0                   0   \n",
      "2                   0                  0                   0   \n",
      "3                   0                  0                   0   \n",
      "4                   0                  1                   0   \n",
      "5                   0                  0                   0   \n",
      "...               ...                ...                 ...   \n",
      "2510                0                  0                   1   \n",
      "2511                0                  0                   1   \n",
      "2512                0                  0                   0   \n",
      "2513                0                  0                   0   \n",
      "2514                0                  1                   0   \n",
      "\n",
      "      barrier_no_group  barrier_no_passion  no_barrier  \\\n",
      "1                    0                   0           0   \n",
      "2                    0                   0           0   \n",
      "3                    0                   0           0   \n",
      "4                    0                   0           0   \n",
      "5                    0                   0           0   \n",
      "...                ...                 ...         ...   \n",
      "2510                 1                   0           0   \n",
      "2511                 0                   0           0   \n",
      "2512                 0                   0           0   \n",
      "2513                 0                   0           0   \n",
      "2514                 0                   0           0   \n",
      "\n",
      "                                        barrier_details  \\\n",
      "1     Right now I am focused on becoming personally ...   \n",
      "2                                                     0   \n",
      "3                                                     0   \n",
      "4     Not diverse enough in the sense that EAs mostl...   \n",
      "5                                                     0   \n",
      "...                                                 ...   \n",
      "2510                                                  0   \n",
      "2511                                                  0   \n",
      "2512                                                  0   \n",
      "2513                                                  0   \n",
      "2514                                                  0   \n",
      "\n",
      "                    rentention_gwwc  retention_givewell  retention_ea_funds  \\\n",
      "1                                 0                   0                   0   \n",
      "2                                 0                   0                   0   \n",
      "3                                 0                   0                   0   \n",
      "4                                 0                   0                   0   \n",
      "5                                 0                   0                   0   \n",
      "...                             ...                 ...                 ...   \n",
      "2510                              0                   0                   0   \n",
      "2511                              0                   1                   0   \n",
      "2512  Giving What We Can Membership                   0                   0   \n",
      "2513                              0                   0                   0   \n",
      "2514  Giving What We Can Membership                   0                   0   \n",
      "\n",
      "      retention_donating  retention_project  retention_eag  retention_eagx  \\\n",
      "1                      0                  0              0               0   \n",
      "2                      0                  0              0               0   \n",
      "3                      0                  0              0               0   \n",
      "4                      0                  0              0               0   \n",
      "5                      0                  0              1               0   \n",
      "...                  ...                ...            ...             ...   \n",
      "2510                   0                  0              0               0   \n",
      "2511                   0                  0              0               0   \n",
      "2512                   0                  0              0               0   \n",
      "2513                   0                  0              0               0   \n",
      "2514                   0                  0              0               0   \n",
      "\n",
      "      retention_group  retention_group_leader  retention_ea_friends  \\\n",
      "1                   0                       0                     0   \n",
      "2                   0                       0                     1   \n",
      "3                   0                       0                     0   \n",
      "4                   0                       0                     0   \n",
      "5                   0                       1                     1   \n",
      "...               ...                     ...                   ...   \n",
      "2510                0                       0                     0   \n",
      "2511                0                       0                     0   \n",
      "2512                0                       0                     0   \n",
      "2513                0                       0                     0   \n",
      "2514                0                       1                     1   \n",
      "\n",
      "      retention_ea_forum  retention_ssc  retention_lw  retention_ea_fb  \\\n",
      "1                      1              0             1                1   \n",
      "2                      0              1             0                0   \n",
      "3                      0              0             0                0   \n",
      "4                      0              0             0                0   \n",
      "5                      0              0             0                0   \n",
      "...                  ...            ...           ...              ...   \n",
      "2510                   0              0             0                0   \n",
      "2511                   0              0             0                0   \n",
      "2512                   0              1             0                0   \n",
      "2513                   0              0             0                0   \n",
      "2514                   0              0             0                0   \n",
      "\n",
      "      retention_ea_discord  retention_future_perfect  \\\n",
      "1                        0                         0   \n",
      "2                        0                         0   \n",
      "3                        0                         0   \n",
      "4                        0                         0   \n",
      "5                        0                         0   \n",
      "...                    ...                       ...   \n",
      "2510                     0                         0   \n",
      "2511                     0                         0   \n",
      "2512                     0                         0   \n",
      "2513                     0                         0   \n",
      "2514                     0                         0   \n",
      "\n",
      "                                      retention_details  \n",
      "1     EA is aligned with my own altruistic goals. Th...  \n",
      "2                                                     0  \n",
      "3                                                     0  \n",
      "4                                                     0  \n",
      "5                                                     0  \n",
      "...                                                 ...  \n",
      "2510                               Reading 80.000 hours  \n",
      "2511                                                  0  \n",
      "2512                                                  0  \n",
      "2513                                                  0  \n",
      "2514                                                  0  \n",
      "\n",
      "[2514 rows x 38 columns]\n",
      "(2514, 38)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('~/Downloads/more data export experiences.csv')\n",
    "data.columns = ['engagement', 'engagement_changed', 'why_engagement_changed', 'NPS', 'details',\n",
    "       'barrier_EA_too_demanding', 'barrier_limited_advice', 'barrier_no_jobs', 'barrier_jobs_too_hard',\n",
    "       'barrier_idk_donate', 'barrier_idk_movement_build', 'barrier_no_mentor', 'barrier_no_diverse',\n",
    "       'barrier_unwelcoming', 'barrier_elitist', 'barrier_no_social', 'barrier_no_friends', 'barrier_no_group',\n",
    "       'barrier_no_passion', 'no_barrier', 'barrier_details', 'rentention_gwwc', 'retention_givewell',\n",
    "       'retention_ea_funds', 'retention_donating', 'retention_project', 'retention_eag', 'retention_eagx',\n",
    "       'retention_group', 'retention_group_leader', 'retention_ea_friends', 'retention_ea_forum', 'retention_ssc',\n",
    "       'retention_lw', 'retention_ea_fb', 'retention_ea_discord', 'retention_future_perfect', 'retention_details']\n",
    "data.fillna(0, inplace=True)\n",
    "data['engagement'] = (data['engagement'].apply(lambda s: 0 if s == 'Response' else s)\n",
    "                                        .apply(lambda s: str(s).split(' ')[0]\n",
    "                                               .replace('(', '').replace(')', ''))\n",
    "                                        .astype(int))\n",
    "data['engagement_changed'] = (data['engagement_changed'].apply(lambda s: 0 if s == 'Response' else s)\n",
    "                                                        .apply(lambda s: str(s).split(' ')[0]\n",
    "                                                               .replace('(', '').replace(')', ''))\n",
    "                                                        .astype(int) - 4)\n",
    "\n",
    "for barrier in [c for c in data.columns if 'barrier' in c and 'detail' not in c]:\n",
    "    data[barrier] = data[barrier].apply(lambda s: 0 if s == 0 else 1)\n",
    "\n",
    "for retention in [c for c in data.columns if 'retention' in c and 'detail' not in c]:\n",
    "    data[retention] = data[retention].apply(lambda s: 0 if s == 0 else 1)\n",
    "\n",
    "data = data.iloc[1:]\n",
    "show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "engagement\n",
      "3    733\n",
      "4    470\n",
      "5    456\n",
      "2    424\n",
      "0    388\n",
      "1     43\n",
      "Name: engagement, dtype: int64\n",
      "###\n",
      "engagement_changed\n",
      " 0    739\n",
      "-4    579\n",
      " 1    304\n",
      " 3    270\n",
      " 2    267\n",
      "-1    238\n",
      "-2    101\n",
      "-3     16\n",
      "Name: engagement_changed, dtype: int64\n",
      "###\n",
      "barrier_EA_too_demanding\n",
      "0    2292\n",
      "1     222\n",
      "Name: barrier_EA_too_demanding, dtype: int64\n",
      "###\n",
      "barrier_limited_advice\n",
      "0    2258\n",
      "1     256\n",
      "Name: barrier_limited_advice, dtype: int64\n",
      "###\n",
      "barrier_no_jobs\n",
      "0    2000\n",
      "1     514\n",
      "Name: barrier_no_jobs, dtype: int64\n",
      "###\n",
      "barrier_jobs_too_hard\n",
      "0    2104\n",
      "1     410\n",
      "Name: barrier_jobs_too_hard, dtype: int64\n",
      "###\n",
      "barrier_idk_donate\n",
      "0    2417\n",
      "1      97\n",
      "Name: barrier_idk_donate, dtype: int64\n",
      "###\n",
      "barrier_idk_movement_build\n",
      "0    2177\n",
      "1     337\n",
      "Name: barrier_idk_movement_build, dtype: int64\n",
      "###\n",
      "barrier_no_mentor\n",
      "0    2240\n",
      "1     274\n",
      "Name: barrier_no_mentor, dtype: int64\n",
      "###\n",
      "barrier_no_diverse\n",
      "0    2309\n",
      "1     205\n",
      "Name: barrier_no_diverse, dtype: int64\n",
      "###\n",
      "barrier_unwelcoming\n",
      "0    2362\n",
      "1     152\n",
      "Name: barrier_unwelcoming, dtype: int64\n",
      "###\n",
      "barrier_elitist\n",
      "0    2250\n",
      "1     264\n",
      "Name: barrier_elitist, dtype: int64\n",
      "###\n",
      "barrier_no_social\n",
      "0    2350\n",
      "1     164\n",
      "Name: barrier_no_social, dtype: int64\n",
      "###\n",
      "barrier_no_friends\n",
      "0    2031\n",
      "1     483\n",
      "Name: barrier_no_friends, dtype: int64\n",
      "###\n",
      "barrier_no_group\n",
      "0    2251\n",
      "1     263\n",
      "Name: barrier_no_group, dtype: int64\n",
      "###\n",
      "barrier_no_passion\n",
      "0    2411\n",
      "1     103\n",
      "Name: barrier_no_passion, dtype: int64\n",
      "###\n",
      "no_barrier\n",
      "0    2374\n",
      "1     140\n",
      "Name: no_barrier, dtype: int64\n",
      "###\n",
      "retention_givewell\n",
      "0    2206\n",
      "1     308\n",
      "Name: retention_givewell, dtype: int64\n",
      "###\n",
      "retention_ea_funds\n",
      "0    2347\n",
      "1     167\n",
      "Name: retention_ea_funds, dtype: int64\n",
      "###\n",
      "retention_donating\n",
      "0    2361\n",
      "1     153\n",
      "Name: retention_donating, dtype: int64\n",
      "###\n",
      "retention_project\n",
      "0    2274\n",
      "1     240\n",
      "Name: retention_project, dtype: int64\n",
      "###\n",
      "retention_eag\n",
      "0    2313\n",
      "1     201\n",
      "Name: retention_eag, dtype: int64\n",
      "###\n",
      "retention_eagx\n",
      "0    2420\n",
      "1      94\n",
      "Name: retention_eagx, dtype: int64\n",
      "###\n",
      "retention_group\n",
      "0    2046\n",
      "1     468\n",
      "Name: retention_group, dtype: int64\n",
      "###\n",
      "retention_group_leader\n",
      "0    2269\n",
      "1     245\n",
      "Name: retention_group_leader, dtype: int64\n",
      "###\n",
      "retention_ea_friends\n",
      "0    1770\n",
      "1     744\n",
      "Name: retention_ea_friends, dtype: int64\n",
      "###\n",
      "retention_ea_forum\n",
      "0    2275\n",
      "1     239\n",
      "Name: retention_ea_forum, dtype: int64\n",
      "###\n",
      "retention_ssc\n",
      "0    2154\n",
      "1     360\n",
      "Name: retention_ssc, dtype: int64\n",
      "###\n",
      "retention_lw\n",
      "0    2318\n",
      "1     196\n",
      "Name: retention_lw, dtype: int64\n",
      "###\n",
      "retention_ea_fb\n",
      "0    2402\n",
      "1     112\n",
      "Name: retention_ea_fb, dtype: int64\n",
      "###\n",
      "retention_ea_discord\n",
      "0    2484\n",
      "1      30\n",
      "Name: retention_ea_discord, dtype: int64\n",
      "###\n",
      "retention_future_perfect\n",
      "0    2359\n",
      "1     155\n",
      "Name: retention_future_perfect, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in data.dtypes[data.dtypes == int].keys():\n",
    "    print('###')\n",
    "    print(c)\n",
    "    print(data[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you very much! I love the community!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice([d for d in data['details'].values if d != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()    \n",
    "    txt = ''.join(ch for ch in txt if ch not in exclude)\n",
    "    return txt\n",
    "\n",
    "custom_stop_words = stop_words + ['i', 'ea']\n",
    "tfidf = TfidfVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=0.6,\n",
    "    max_features=300,\n",
    "    stop_words=custom_stop_words\n",
    ")\n",
    "tfidf_text = tfidf.fit_transform([clean_text(d) for d in data['details'].values if d != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit 2 clusters\n",
      "Fit 4 clusters\n",
      "Fit 6 clusters\n",
      "Fit 8 clusters\n",
      "Fit 10 clusters\n",
      "Fit 12 clusters\n",
      "Fit 14 clusters\n",
      "Fit 16 clusters\n",
      "Fit 18 clusters\n",
      "Fit 20 clusters\n",
      "Fit 22 clusters\n",
      "Fit 24 clusters\n",
      "Fit 26 clusters\n",
      "Fit 28 clusters\n",
      "Fit 30 clusters\n",
      "Fit 32 clusters\n",
      "Fit 34 clusters\n",
      "Fit 36 clusters\n",
      "Fit 38 clusters\n",
      "Fit 40 clusters\n",
      "Fit 42 clusters\n",
      "Fit 44 clusters\n",
      "Fit 46 clusters\n",
      "Fit 48 clusters\n",
      "Fit 50 clusters\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adapted from https://www.kaggle.com/jbencina/clustering-documents-with-tfidf-and-kmeans\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    iters = range(2, max_k+1, 2)\n",
    "\n",
    "    sse = []\n",
    "    for k in iters:\n",
    "        sse.append(MiniBatchKMeans(n_clusters=k, init_size=1024, batch_size=2048, random_state=20).fit(data).inertia_)\n",
    "        print('Fit {} clusters'.format(k))\n",
    "\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    ax.plot(iters, sse, marker='o')\n",
    "    ax.set_xlabel('Cluster Centers')\n",
    "    ax.set_xticks(iters)\n",
    "    ax.set_xticklabels(iters)\n",
    "    ax.set_ylabel('SSE')\n",
    "    ax.set_title('SSE by Cluster Center Plot')\n",
    "    return plt, sse\n",
    "\n",
    "plt, sse = find_optimal_clusters(tfidf_text, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 - Size 461\n",
      "also, ive, eas, many, dont, really, much, good, im, feel, think, like, would, people, community\n"
     ]
    }
   ],
   "source": [
    "def cluster_counts(clusters):\n",
    "    unique, counts = np.unique(clusters, return_counts=True)\n",
    "    cc = dict(zip(unique, counts))\n",
    "    return dict(sorted([(k, v) for k, v in cc.items()], key=lambda x: x[1], reverse=True))\n",
    "\n",
    "\n",
    "# Adapted from https://www.kaggle.com/jbencina/clustering-documents-with-tfidf-and-kmeans\n",
    "def get_top_keywords(data, clusters, cluster_counts, labels, n_terms):\n",
    "    df = pd.DataFrame(data.todense()).groupby(clusters).mean()\n",
    "    for i,r in df.iterrows():\n",
    "        print('\\nCluster {} - Size {}'.format(i, cluster_counts[i]))\n",
    "        print(', '.join([labels[t] for t in np.argsort(r)[-n_terms:]]))\n",
    "\n",
    "\n",
    "clusters = MiniBatchKMeans(n_clusters=1,\n",
    "                           init_size=1024,\n",
    "                           batch_size=2048,\n",
    "                           random_state=20).fit_predict(tfidf_text)\n",
    "get_top_keywords(tfidf_text, clusters, cluster_counts(clusters), tfidf.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "CLUSTER 0 - SIZE 922\n",
      "[('community', 235), ('people', 228), ('would', 100), ('like', 92), ('think', 90), ('im', 77), ('feel', 76), ('eas', 57), ('dont', 56), ('also', 51), ('many', 50), ('much', 49), ('career', 49), ('good', 48), ('really', 47), ('group', 47), ('ive', 44), ('movement', 44), ('get', 43), ('lot', 38), ('even', 38), ('effective', 37), ('work', 36), ('seems', 34), ('less', 34), ('principles', 34), ('find', 33), ('involved', 31), ('sometimes', 31), ('great', 31), ('experience', 30), ('could', 30), ('new', 30), ('see', 30), ('one', 30), ('diversity', 29), ('ideas', 29), ('bit', 29), ('enough', 28), ('social', 26), ('change', 26), ('introduce', 26), ('know', 26), ('time', 25), ('better', 25), ('way', 25), ('friends', 24), ('excited', 24), ('need', 24), ('especially', 24), ('others', 24), ('still', 23), ('local', 23), ('hard', 23), ('etc', 23), ('world', 23), ('ai', 22), ('want', 22), ('makes', 21), ('interested', 21), ('seem', 21), ('love', 21), ('positive', 21), ('things', 21), ('focus', 21), ('found', 20), ('life', 20), ('members', 20), ('lack', 20), ('job', 20), ('person', 20), ('often', 20), ('make', 20), ('climate', 19), ('met', 19), ('thinking', 19), ('important', 19), ('cause', 19), ('first', 19), ('issues', 18), ('core', 18), ('general', 18), ('quite', 17), ('skills', 17), ('well', 17), ('however', 17), ('impact', 17), ('big', 17), ('believe', 16), ('part', 16), ('causes', 16), ('id', 16), ('events', 16), ('us', 16), ('welcoming', 15), ('someone', 15), ('didnt', 15), ('little', 15), ('felt', 15), ('friend', 15), ('interesting', 15), ('give', 15), ('without', 15), ('though', 15), ('resources', 14), ('bad', 14), ('feeling', 14), ('experiences', 14), ('help', 14), ('jobs', 14), ('around', 14), ('research', 14), ('come', 14), ('difficult', 14), ('hours', 14), ('always', 14), ('doesnt', 14), ('towards', 14), ('elitist', 14), ('introducing', 14), ('best', 13), ('may', 13), ('negative', 13), ('diverse', 13), ('pretty', 13), ('high', 13), ('global', 13), ('something', 13), ('eg', 13), ('large', 12), ('altruism', 12), ('small', 12), ('needs', 12), ('different', 12), ('wish', 12), ('advice', 12), ('maybe', 12), ('going', 12), ('made', 12), ('given', 12), ('somewhat', 12), ('certain', 12), ('human', 12), ('groups', 12), ('risk', 12), ('might', 12), ('average', 12), ('areas', 12), ('actually', 12), ('charities', 12), ('extremely', 12), ('personal', 12), ('future', 11), ('getting', 11), ('view', 11), ('across', 11), ('amount', 11), ('working', 11), ('become', 11), ('mostly', 11), ('discussions', 11), ('80000', 11), ('simply', 11), ('feels', 11), ('problems', 11), ('highly', 11), ('put', 11), ('individuals', 11), ('far', 11), ('rather', 11), ('sense', 11), ('level', 10), ('sure', 10), ('animal', 10), ('facebook', 10), ('health', 10), ('answer', 10), ('intellectual', 10), ('meet', 10), ('within', 10), ('question', 10), ('talk', 10), ('times', 10), ('problem', 10), ('making', 10), ('nice', 10), ('theres', 10), ('values', 10), ('online', 10), ('meetups', 10), ('academic', 10), ('idea', 10), ('kind', 10), ('appreciate', 10), ('two', 9), ('particularly', 9), ('women', 9), ('influence', 9), ('worried', 9), ('apply', 9), ('ones', 9), ('thought', 9), ('worry', 9), ('learn', 9), ('common', 9), ('lots', 9), ('reason', 9), ('rationality', 9), ('due', 9), ('ways', 9), ('reading', 9), ('generally', 9), ('share', 9), ('reasons', 9), ('strongly', 9), ('support', 9), ('outside', 9), ('approach', 9), ('take', 9), ('go', 9), ('offputting', 9), ('try', 9), ('donations', 9), ('it’s', 9), ('thing', 9), ('turned', 8), ('white', 8), ('stuff', 8), ('overall', 8), ('wrong', 8), ('respect', 8), ('whole', 8), ('weird', 8), ('mental', 8), ('specific', 8), ('givewell', 8), ('instead', 8), ('since', 8), ('focused', 8), ('heard', 8), ('years', 8), ('everyone', 8), ('whether', 8), ('likely', 8), ('topics', 8), ('terms', 8), ('including', 8), ('significant', 8), ('understand', 8), ('views', 8), ('fact', 8), ('rationalist', 8), ('organizations', 8), ('path', 8), ('thats', 8), ('already', 8), ('donating', 8), ('becoming', 8), ('real', 8), ('learning', 8), ('giving', 8), ('probably', 8), ('bring', 7), ('although', 7), ('currently', 7), ('post', 7), ('full', 7), ('forum', 7), ('smart', 7), ('fun', 7), ('basic', 7), ('safety', 7), ('folks', 7), ('goal', 7), ('moral', 7), ('point', 7), ('happy', 7), ('done', 7), ('several', 7), ('80k', 7), ('member', 7), ('background', 7), ('understanding', 7), ('issue', 7), ('open', 7), ('intimidating', 7), ('conversations', 7), ('tend', 7), ('use', 7), ('nothing', 7), ('higher', 7), ('donate', 7), ('decisions', 7), ('enjoy', 7), ('seeing', 7), ('past', 7), ('almost', 7), ('poor', 7), ('lesswrong', 7), ('cant', 7), ('least', 7), ('live', 6), ('survey', 6), ('communities', 6), ('wonderful', 6), ('taking', 6), ('action', 6), ('except', 6), ('inclusive', 6), ('got', 6), ('concerns', 6), ('similar', 6), ('concept', 6), ('looking', 6), ('woman', 6), ('terrible', 6), ('building', 6), ('possible', 6), ('last', 6), ('year', 6), ('gender', 6), ('poverty', 6), ('information', 6), ('paths', 6), ('event', 6), ('said', 6), ('male', 6), ('active', 6), ('religious', 6), ('noticed', 6), ('read', 6), ('opportunities', 6), ('benefit', 6), ('extent', 6), ('otherwise', 6), ('clear', 6), ('place', 6), ('engage', 6), ('newcomers', 6), ('aware', 6), ('despite', 6), ('type', 6), ('strong', 6), ('concerned', 6), ('status', 6), ('goals', 6), ('perspective', 6), ('actions', 6), ('course', 6), ('example', 6), ('arrogance', 6), ('discussion', 6), ('disagree', 6), ('call', 6), ('suspect', 6), ('uncomfortable', 6), ('valuable', 6), ('care', 6), ('young', 6), ('theyre', 6), ('efforts', 6), ('socially', 6), ('conversation', 6), ('useful', 6), ('value', 6), ('philosophy', 6), ('altruists', 6), ('cultish', 5), ('comfortable', 5), ('area', 5), ('end', 5), ('heavily', 5), ('majority', 5), ('helping', 5), ('broader', 5), ('actual', 5), ('hope', 5), ('continue', 5), ('long', 5), ('motivated', 5), ('finding', 5), ('direct', 5), ('school', 5), ('interacting', 5), ('wonder', 5), ('computer', 5), ('meaningful', 5), ('personally', 5), ('prefer', 5), ('dominated', 5), ('huge', 5), ('hesitant', 5), ('everything', 5), ('related', 5), ('income', 5), ('fit', 5), ('students', 5), ('contribute', 5), ('intelligence', 5), ('actively', 5), ('lives', 5), ('elitism', 5), ('nyc', 5), ('les', 5), ('chance', 5), ('perhaps', 5), ('wouldnt', 5), ('effort', 5), ('disappointed', 5), ('run', 5), ('current', 5), ('money', 5), ('necessary', 5), ('based', 5), ('various', 5), ('effectiveness', 5), ('avoid', 5), ('considering', 5), ('tasks', 5), ('researchers', 5), ('main', 5), ('leave', 5), ('join', 5), ('start', 5), ('attended', 5), ('comes', 5), ('communication', 5), ('cool', 5), ('havent', 5), ('nerdy', 5), ('worse', 5), ('content', 5), ('home', 5), ('discuss', 5), ('attend', 5), ('london', 5), ('look', 5), ('culture', 5), ('away', 5), ('seen', 5), ('ie', 5), ('i’m', 5), ('cea', 5), ('orgs', 5), ('careers', 5), ('rational', 5), ('specifically', 5), ('beliefs', 5), ('effectively', 5), ('side', 5), ('experienced', 5), ('don’t', 4), ('necessarily', 4), ('telling', 4), ('wasnt', 4), ('feelings', 4), ('rights', 4), ('agree', 4), ('potential', 4), ('say', 4), ('mindset', 4), ('starting', 4), ('credentials', 4), ('choice', 4), ('decided', 4), ('lacking', 4), ('fields', 4), ('mine', 4), ('interest', 4), ('thoughts', 4), ('contact', 4), ('amazing', 4), ('pursue', 4), ('wellbeing', 4), ('quality', 4), ('welfare', 4), ('incredibly', 4), ('recommend', 4), ('40', 4), ('club', 4), ('meetings', 4), ('oxford', 4), ('discouraging', 4), ('superior', 4), ('able', 4), ('among', 4), ('international', 4), ('2017', 4), ('conference', 4), ('welcome', 4), ('established', 4), ('policy', 4), ('scientists', 4), ('gives', 4), ('limited', 4), ('influencing', 4), ('coming', 4), ('jargon', 4), ('emotional', 4), ('questions', 4), ('right', 4), ('term', 4), ('completely', 4), ('connect', 4), ('public', 4), ('à', 4), ('de', 4), ('create', 4), ('never', 4), ('i’ve', 4), ('guidance', 4), ('started', 4), ('improving', 4), ('choices', 4), ('improved', 4), ('highimpact', 4), ('yet', 4), ('creating', 4), ('plans', 4), ('putting', 4), ('helpful', 4), ('seriously', 4), ('perspectives', 4), ('country', 4), ('truly', 4), ('align', 4), ('parts', 4), ('changing', 4), ('projects', 4), ('organisations', 4), ('spend', 4), ('act', 4), ('knowledge', 4), ('obviously', 4), ('meetup', 4), ('substantial', 4), ('2019', 4), ('second', 4), ('development', 4), ('larger', 4), ('convinced', 4), ('introduced', 4), ('1', 4), ('andor', 4), ('impression', 4), ('existential', 4), ('went', 4), ('decent', 4), ('particular', 4), ('account', 4), ('opinion', 4), ('deeply', 4), ('humans', 4), ('animals', 4), ('ethical', 4), ('age', 4), ('exists', 4), ('glad', 4), ('disagreement', 4), ('remember', 4), ('anything', 4), ('imo', 4), ('qualified', 4), ('number', 4), ('therefore', 4), ('thoughtful', 4), ('mind', 4), ('guys', 4), ('meta', 4), ('insular', 4), ('associated', 4), ('involvement', 4), ('youre', 4), ('super', 4), ('guide', 4), ('leaders', 4), ('professional', 4), ('case', 4), ('half', 4), ('priorities', 4), ('frustrating', 4), ('previously', 4), ('supportive', 4), ('willing', 4), ('identify', 4), ('shift', 4), ('field', 4), ('grow', 4), ('else', 4), ('taken', 4), ('impossible', 4), ('follow', 4), ('perceive', 4), ('harder', 4), ('consider', 4), ('attempt', 4), ('updated', 4), ('leads', 4), ('sharing', 3), ('name', 3), ('sf', 3), ('bay', 3), ('interacted', 3), ('early', 3), ('seemed', 3), ('society', 3), ('word', 3), ('oriented', 3), ('direction', 3), ('spread', 3), ('older', 3), ('power', 3), ('along', 3), ('besides', 3), ('voices', 3), ('available', 3), ('applied', 3), ('standards', 3), ('grad', 3), ('racial', 3), ('used', 3), ('researcher', 3), ('unless', 3), ('science', 3), ('shame', 3), ('accessible', 3), ('altruist', 3), ('sexual', 3), ('changed', 3), ('vague', 3), ('maximizing', 3), ('concrete', 3), ('points', 3), ('ask', 3), ('tell', 3), ('living', 3), ('racist', 3), ('attending', 3), ('ethnicity', 3), ('blog', 3), ('inclusion', 3), ('2018', 3), ('kinds', 3), ('backgrounds', 3), ('lived', 3), ('charity', 3), ('food', 3), ('serious', 3), ('distress', 3), ('spending', 3), ('outsiders', 3), ('brought', 3), ('relevant', 3), ('awkward', 3), ('university', 3), ('wider', 3), ('politics', 3), ('every', 3), ('dedicated', 3), ('top', 3), ('effects', 3), ('cities', 3), ('narrow', 3), ('prioritizing', 3), ('talent', 3), ('low', 3), ('message', 3), ('include', 3), ('countries', 3), ('ability', 3), ('apart', 3), ('earn', 3), ('spent', 3), ('forums', 3), ('theoretical', 3), ('xrisk', 3), ('require', 3), ('shy', 3), ('understandable', 3), ('broadly', 3), ('barrier', 3), ('struggle', 3), ('keep', 3), ('upon', 3), ('list', 3), ('altruistic', 3), ('order', 3), ('basically', 3), ('education', 3), ('assumptions', 3), ('overwhelming', 3), ('talking', 3), ('exist', 3), ('project', 3), ('data', 3), ('solve', 3), ('10', 3), ('subset', 3), ('population', 3), ('board', 3), ('mean', 3), ('race', 3), ('studies', 3), ('complex', 3), ('2', 3), ('encouraging', 3), ('easier', 3), ('focusing', 3), ('podcast', 3), ('behaviour', 3), ('fall', 3), ('overconfident', 3), ('saying', 3), ('trust', 3), ('org', 3), ('positions', 3), ('dogmatic', 3), ('answered', 3), ('detail', 3), ('state', 3), ('fairly', 3), ('curious', 3), ('discussing', 3), ('humility', 3), ('fully', 3), ('major', 3), ('can’t', 3), ('individual', 3), ('vast', 3), ('slate', 3), ('star', 3), ('codex', 3), ('page', 3), ('hero', 3), ('behind', 3), ('mainly', 3), ('lovely', 3), ('aligned', 3), ('exposure', 3), ('warm', 3), ('fix', 3), ('gone', 3), ('reaching', 3), ('application', 3), ('appears', 3), ('sort', 3), ('malaria', 3), ('nets', 3), ('difference', 3), ('increase', 3), ('men', 3), ('shown', 3), ('criticism', 3), ('gotten', 3), ('numbers', 3), ('rest', 3), ('meeting', 3), ('book', 3), ('turn', 3), ('normal', 3), ('earelated', 3), ('transparent', 3), ('easily', 3), ('treated', 3), ('resource', 3), ('engaged', 3), ('demographics', 3), ('elite', 3), ('benefits', 3), ('aspiring', 3), ('bigger', 3), ('burden', 3), ('impressive', 3), ('english', 3), ('speaking', 3), ('donation', 3), ('exclusive', 3), ('universities', 3), ('competitive', 3), ('website', 3), ('closed', 3), ('itd', 3), ('save', 3), ('scary', 3), ('discussed', 3), ('traits', 3), ('beyond', 3), ('standard', 3), ('nuance', 3), ('discourse', 3), ('presenting', 3), ('frequently', 3), ('x', 3), ('—', 3), ('offer', 3), ('rich', 3), ('somehow', 3), ('beneficial', 3), ('material', 3), ('utility', 3), ('show', 3), ('net', 3), ('basis', 3), ('b', 3), ('engaging', 3), ('moment', 3), ('answers', 3), ('fantastic', 3), ('caring', 3), ('foundational', 3), ('optimize', 3), ('types', 3), ('sexism', 3), ('miss', 3), ('condescending', 3), ('known', 3), ('articles', 3), ('organization', 3), ('ago', 3)]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'details': data[data['details'] != 0]['details'], 'cluster': clusters})\n",
    "for name, group in df.groupby('cluster'):\n",
    "    print('###')\n",
    "    print('CLUSTER {} - SIZE {}'.format(name, group.size))\n",
    "    counts = dict(Counter(sum([clean_text(v).split() for v in group['details'].values], []))).items()\n",
    "    print(sorted([(c[0], c[1]) for c in counts if c[1] > 2 and c[0].lower() not in custom_stop_words], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df.groupby('cluster'):\n",
    "    print('###')\n",
    "    print('CLUSTER {} - SIZE {}'.format(name, group.size))\n",
    "    print(group['details'].values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "target_ = (data['engagement'] >= 3).astype(int)\n",
    "folds = folds.split(data, target_)\n",
    "results2 = run_cv_model(train=tfidf_text,\n",
    "                        target=target_.values,\n",
    "                        model_fn=runLR,\n",
    "                        params={'C': 10.0, 'solver': 'lbfgs'},\n",
    "                        eval_fn=auc,\n",
    "                        fold_splits=folds,\n",
    "                        n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for _, m in results2['model'].items():\n",
    "    df = pd.DataFrame(list(zip(tfidf.get_feature_names(), m.coef_[0])))\n",
    "    col = df[0]\n",
    "    val = df[1]\n",
    "    df.drop(0, axis=1, inplace=True)\n",
    "    df = df.T\n",
    "    df.columns = col\n",
    "    dfs.append(df)\n",
    "\n",
    "dfs = pd.concat(dfs)\n",
    "word_means = dfs.mean(axis=0).sort_values(ascending=False)\n",
    "word_means = pd.DataFrame(word_means)\n",
    "word_means.columns = ['coefficient']\n",
    "word_means['word'] = word_means.index\n",
    "word_means.reset_index(inplace=True, drop=True)\n",
    "counts = dict(Counter(sum([clean_text(v).split() for v in group['details'].values], []))).items()\n",
    "counts_df = pd.DataFrame(counts)\n",
    "counts_df.columns = ['word', 'frequency']\n",
    "words_df = word_means.merge(counts_df, on='word', how='left')\n",
    "words_df = words_df[words_df['frequency'].fillna('') != '']\n",
    "words_df['frequency'] = words_df['frequency'].astype(int)\n",
    "show(words_df, max_rows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [Color('#2458EB')]\n",
    "colors.extend(list(Color('#2458EB').range_to(Color('#31E7FE'), 81))[1:])\n",
    "colors.extend(list(Color('#31E7FE').range_to(Color('#8da0a2'), 21))[1:])\n",
    "colors.extend(list(Color('#a18f8c').range_to(Color('#ffad9e'), 21))[1:])\n",
    "colors.extend(list(Color('#ffad9e').range_to(Color('#d80909'), 81))[1:])\n",
    "webcolors = [c.get_web() for c in colors]\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "dr_cmap = LinearSegmentedColormap.from_list('DataRobot',\n",
    "                                            webcolors,\n",
    "                                            N=len(colors))\n",
    "x = np.arange(-1, 1.01, 0.01)\n",
    "y = np.arange(0, 40, 1)\n",
    "X = np.meshgrid(x, y)[0]\n",
    "plt.xticks([0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200],\n",
    "           ['-1', '-0.8', '-0.6', '-0.4', '-0.2', '0',\n",
    "            '0.2', '0.4', '0.6', '0.8', '1'])\n",
    "plt.yticks([], [])\n",
    "im = plt.imshow(X, interpolation='nearest', origin='lower', cmap=dr_cmap)\n",
    "\n",
    "def word_cloud_plot(wc, font_path=None):\n",
    "    dict_freq = {wc_word['word']: wc_word['frequency'] for _, wc_word in wc.iterrows()}\n",
    "    dict_coef = {wc_word['word']: wc_word['coefficient'] for _, wc_word in wc.iterrows()}\n",
    "    \n",
    "    def color_func(*args, **kwargs):\n",
    "        word = args[0]\n",
    "        palette_index = int(round(dict_coef[word] * (len(colors) - 1)))\n",
    "        r, g, b = colors[palette_index].get_rgb()\n",
    "        return 'rgb({:.0f}, {:.0f}, {:.0f})'.format(int(r * 255),\n",
    "                                                    int(g * 255),\n",
    "                                                    int(b * 255))\n",
    "\n",
    "    wc_image = wordcloud.WordCloud(stopwords=set(),\n",
    "                                   width=2048, height=2048,\n",
    "                                   relative_scaling=0.5,\n",
    "                                   prefer_horizontal=1,\n",
    "                                   color_func=color_func,\n",
    "                                   background_color=(0, 10, 29),\n",
    "                                   font_path=font_path).fit_words(dict_freq)\n",
    "    plt.imshow(wc_image, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "\n",
    "words_df['coefficient'] = minmax_scale(scale(words_df['coefficient']))\n",
    "word_cloud_plot(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(results2['model'][1], doc=data['details'].values[0], vec=tfidf, targets=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(results2['model'][1], doc=data['details'].values[1], vec=tfidf, targets=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(results2['model'][1], doc=data['details'].values[2], vec=tfidf, targets=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'details': data['details'], 'pred': results2['train']})\n",
    "print(df3.sort_values('pred').loc[df3['pred'] < 0.5, 'details'].values[:10])\n",
    "print('...')\n",
    "print(np.flip(df3.sort_values('pred', ascending=False).loc[df3['pred'] > 0.5, 'details'].values[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros(300)\n",
    "\n",
    "def embed(text, embeddings_dict):\n",
    "    words = [clean_text(w) for w in re.split(r'\\W+', text) if w not in custom_stop_words and w != '']\n",
    "    return np.mean(np.array([embeddings_dict.get(w, blank) for w in words]), axis=0)\n",
    "\n",
    "print('Load GloVe...')\n",
    "embeddings_dict = joblib.load('/Users/peter.hurford/dev/project-stanza/data/glove.pkl')\n",
    "text = data['details'].values.tolist()\n",
    "print('Embedding...')\n",
    "embeddings_text = [embed(t, embeddings_dict=embeddings_dict) for t in text if t != 0]\n",
    "embeddings_text = [blank if e.shape == () else e for e in embeddings_text]\n",
    "embeddings_df = pd.DataFrame(embeddings_text)\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt, sse = find_optimal_clusters(embeddings_df, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters2 = MiniBatchKMeans(n_clusters=38,\n",
    "                            init_size=1024,\n",
    "                            batch_size=2048,\n",
    "                            random_state=20).fit_predict(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'details': data['details'], 'cluster': clusters2})\n",
    "for name, group in df2.groupby('cluster'):\n",
    "    print('###')\n",
    "    print('CLUSTER {} - SIZE {}'.format(name, group.size))\n",
    "    counts = dict(Counter(sum([clean_text(v).split() for v in group['details'].values], []))).items()\n",
    "    print(sorted([(c[0], c[1]) for c in counts if c[1] > 1 and c[0].lower() not in custom_stop_words], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df2.groupby('cluster'):\n",
    "    print('###')\n",
    "    print('CLUSTER {} - SIZE {}'.format(name, group.size))\n",
    "    print(group['details'].values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['details'].apply(lambda s: '' if s == 0 else s) + ' ' + data['why_engagement_changed'].apply(lambda s: '' if s == 0 else s)\n",
    "\n",
    "for col in [c for c in data.columns if 'barrier' in c]:\n",
    "    text = text + ' ' + data[col].apply(lambda x: col.replace('barrier', '').replace('_', ' ') if x == 1 else '')\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(\n",
    "    min_df=5,\n",
    "    max_df=0.6,\n",
    "    max_features=300,\n",
    "    stop_words=custom_stop_words\n",
    ")\n",
    "tfidf_text2 = tfidf2.fit_transform([clean_text(d) for d in text])\n",
    "plt, sse = find_optimal_clusters(tfidf_text2, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters3 = MiniBatchKMeans(n_clusters=18,\n",
    "                            init_size=1024,\n",
    "                            batch_size=2048,\n",
    "                            random_state=20).fit_predict(tfidf_text2)\n",
    "get_top_keywords(tfidf_text2, clusters3, cluster_counts(clusters3), tfidf2.get_feature_names(), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'details': data['details'], 'cluster': clusters3})\n",
    "for name, group in df3.groupby('cluster'):\n",
    "    print('###')\n",
    "    print('CLUSTER {} - SIZE {}'.format(name, group.size))\n",
    "    counts = dict(Counter(sum([clean_text(v).split() for v in group['details'].values], []))).items()\n",
    "    print(sorted([(c[0], c[1]) for c in counts if c[1] > 1 and c[0].lower() not in custom_stop_words], key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df3.groupby('cluster'):\n",
    "    print('###')\n",
    "    print('CLUSTER {} - SIZE {}'.format(name, group.size))\n",
    "    print(group['details'].values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('community', 298), ('diversity', 84), ('weird', 84), ('job', 65), ('principle', 62), ('hard', 59), ('cause', 59), ('giving', 31), ('elitist', 25), ('resource', 16), ('animal', 11), ('lonely', 9)]\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER diversity: '*divers*', '*white*', '*men *', '*man *', '*young*', '*inclusi*', '*exclusi*', '*unwelcom*'\n",
      "###\n",
      "\n",
      "The ethnic diversity in the EA community seems not good.\n",
      "\n",
      "I was kicked out of an EA memes group on Facebook for angrily telling someone he shouldn't post a meme with the word \"n*gger\" on it (except he posted the full word as part of the meme). I didn't curse, but I was quite sarcastic in my replies to his self-defenses. In the end, I was kicked out of the group and he wasn't. This really makes me think that EA is overwhelmingly white and not inclusive enough. I also got some bad feelings about EA when I saw so many anti-feminist posts on the \"Dark EA\" facebook group. I've met some wonderful EA people, but this stuff concerns me. \n",
      "\n",
      "I find the EA community to be in large part exclusionary, particularly to women. I have found EAs that I admire and respect, but as a whole, I would not say that the EA community is interested in helping spread the concept of effective altruism, unfortunately. \n",
      "\n",
      "Still looking for people in the broader category of Doing Good Better, and feeling lonely in the movement as an older woman in a small town.\n",
      "\n",
      "EA needs to be more welcoming of non-English speakers and people with life experiences different to the \"classic EA\" mindset. Not diversity for the sake of diversity but instead about broadening the inputs and voices contributing to EA as a community. Some of the core ideas in EA are unconventional. But now that they have been laid down, influential members defend them against any change or further unconventional influence.\n",
      "\n",
      "Gender and racial diversity are lacking; it's no fun being a minority in a monoculture\n",
      "\n",
      "I would love to see a more diverse array of causes represented and to get the opportunity to meet with NGOs in other fields who have an EA mindset. I worry that the increasing prominence of AI safety research is quite alienating to, say, poverty NGOs. There is very little transferrable information for advocates within the EA community to learn from computer science specialists. I think that a large portion of the EA community should be made up of AI/X-risk folks, but I think it's a shame to lose the much more accessible roots that EA sprung from.\n",
      "\n",
      "Disregarding the impacts of climate change and the 6th extinction event, even from a solely human welfare point of view seems incredibly silly, but is quite common\n",
      "\n",
      "I don't feel comfortable in the Spanish EA group because it's a \"boy's club\" where I have to bear sexist and sometimes even racist comments. I'm the only woman, and also the only immigrant and non-white person. I don't feel safe and persistently discriminated against. Given this situation, I stopped attending several local meetings and events. \n",
      "\n",
      "Very male dominated. Huge diversity issues in terms of ethnicity. Not welcoming to non-mathsy people. West coast USA is the worst. Oxford office is pretty bad for this too.\n",
      "\n",
      "I would be hesitant to introduce a friend to EA because EAs can be discouraging of do gooding that is not typical EA work but that still makes the world better. EAs also bring up racist or sexist ideas in the spirit of questioning everything, which can be alienating for people of color and women. \n",
      "\n",
      "Too white\n",
      "\n",
      "EA suffers from a terrible lack of diversity and inclusion. As a non-White member of the community from a lower income background, I often felt very alienated, lonely, and unwelcome at international EA gatherings such as at EA Globals in 2017 and 2018. I also feel that many EAs including 80 000 Hours career coaches lack empathy for and understanding of people with my kinds of backgrounds and lived experiences such as having faced significant financial stress, relied on some form of charity food aid, lived with systemic and persistent racial discrimination including in the job market, and also being active in a religious community. I have also been very unwell these last few years, and felt very uncared for during EA Globals, and was at high risk of having a serious health incident, and no one noticed or even reached out in kindness even as I wandered around the conference venue alone and in distress. This could be because they don't understand that distress is expressed differently in different cultures and they lack the intercultural understanding to read different signals of distress. More diversity and inclusion in EA could have made me feel more welcome and supported. \n",
      "\n",
      "I would be very excited to introduce a friend to certain people within the EA community, especially those who have experience relevant to my friend's interests, but I would not necessarily be excited to invite them to the average EA social event, mostly because I find people at EA/rationalist events in the Bay area can be awkward and unwelcoming.\n",
      "\n",
      "The lack of racial and gender diversity in the movement is a persistent and serious problem for the movement and I see it as direct reason why I (and others) would become less involved (this coming from someone who has dedicated most of my college years to running and EA group and who is dedicating their career to a top EA cause).    Some more thoughts about this lack of diversity.    CAUSES OF THE ISSUE:  To some extent this is \"founder effects\" and a biproduct of the fact that the movement has grown out of cities like Oxford. However, I other factors contribute; such as the inaccessible jargon and narrow definitions of \"rationality\" and \"intelligence\" that have been imported from the rationalist community. The way in which some people in our movement seem to actively derive glee from labeling cause areas and organizations as \"ineffective\" or people as \"irrational\" or \"too emotional\" is an active impediment to having a more inclusive movement.    CONSEQUENCES:  - Heightened risk of making moral errors or prioritizing the wrong issues due to homogeneity among the people in charge of charting the path of our movement.  - Smaller talent pool, loss of engagement from otherwise dedicated members (I've felt this happening myself).  \n",
      "\n",
      "Ea has a problem of diversity, which makes it difficult to be\"socially satisfying\" for many people\n",
      "\n",
      "Would like to see a stronger focus on diversity and inclusion, especially as it relates to class differences and physical/cognitive ability.    Also would love to see the online materials be made more accessible for someone who's never heard of ea before. It can be really intimidating to get into this movement if you don't have a local group to smooth the transition and most people don't have access to that.\n",
      "\n",
      "Taiwan, \"ROC\", or even \"Taiwan, Province of\" was not listed in the country options. I chose to not list \"China\" because I acknowledge the contentious nature of the 'country status' question. If EA wants to remain truly impartial, it should maybe make an effort in this regard. While I understand the rationale for EA's approach to China, it is also problematic.  There is nothing altruistic in human rights violations and silencing democratic voices. Furthermore, opposing or challenging views are necessary in order to continuously rethink the effectiveness of our approaches. If an institution simply decides to ignore or silence groups/data that do not align with its own goals, and EA just accepts this, then whole point of EA is moot. \n",
      "\n",
      "Over obsession with fraudulent issues (AGI) obsuring discussion on real world issues (poverty, climate change, human rights etc.)    Certain members are racist arseholes.\n",
      "\n",
      "It depends on their background and their way of seeing the world, and which community. The online EA community is very hardcore: I wouldn't introduce many people to that. The local EA community is friendlier, but has diversity gaps (in gender, race, and \"are you highly quantitative/technical in your studies or profession, or a philosopher\"), so I would be cautious about who I introduced to it.\n",
      "\n",
      "The overly proud focus on logic in discussions sometimes comes at the cost of decent human polite behaviour.     EA can feel elitist and seems quite targeted to ivory league graduates. \n",
      "\n",
      "Positive: a commitment to be evidence based  Negative: seems to fall too often for authority argument, too much inequality in the distribution of status and influence within EA, not enough inclusive to minorities and some member despise other for 'uneffective' career choice. \n",
      "\n",
      "I think we should care more about diversity especially in leading EA .org positions. I am also concerned about spending all our resources on long-termism forgetting about actual suffering of humans and animals \n",
      "\n",
      "Almost everyone in the community seems to be very young (in their 30s at most), so I'm not so sure they're the best judges of what makes a fulfilling career, since they're only starting their own. (Below, by \"not diverse enough\" I primarily mean this kind of diversity, not, for instance, gender and race diversity.) The ethical and philosophical discussions were also fairly basic, which is understandable given the age of the people involved. For these reasons, I'm not convinced this group should be so eager to influence the lives of trillions of people in the far future (apart from simply helping make sure that future exists). The people seem to be very intellectually curious, however, and discussing various issues with them has been fun. \n",
      "\n",
      "I found it very welcoming and friendly. I've noticed that our group isn't very diverse though.\n",
      "\n",
      "Would be cool if EA could manage to be more diverse considering age, ethnicity, academic backround, gender, etc\n",
      "\n",
      "There is not enough diversity and representation from other fields of study. Too many Computer Scientists and Mathematicians.\n",
      "\n",
      "The EA community in thoroughly awesome, but I'm not excited about introducing anyone to anything in general. When I meet someone interested by EA principles, the mere mention of the existence of a large and diverse community is usually sufficient to excite *them*.\n",
      "\n",
      "I think it would be good for the community if the percentage of women was higher\n",
      "\n",
      "Not diverse enough. Too male, white, math & computer science, young. I can't understand most of the discussions on EA Forum and LessWrong. Too much emphasis on AI rather than global poverty. Not enough in the developing world. \n",
      "\n",
      "I feel very aligned with the core ideas of EA, however my first exposure to people in the community was underwhelming. As a generalisation, I found EA members to be more egotistical, less warm, and less socially aware than the average population. I would like to see the EA community become more diverse (especially more women and more people from humanities backgrounds), and I would like to see the community improve in social skills and interpersonal altruism. \n",
      "\n",
      "Occasional negative experiences from meetups when interacting with men with poor social skills  \n",
      "\n",
      "The overall messaging online seems to have moved away from an inclusive \"most people can make a big difference\" to a message about super high value career paths, and that is one way people will feel less valued in the community. I have also seen a large disparity in the distribution of support (monetary and otherwise) to groups and individuals around the world, and that is very offputting, and also signals that the community doesn't value us. \n",
      "\n",
      "It’s full of well intentioned people but so dominated by white men who are often think themselves superior that I’ve gotten fed up with it all, which is a shame.\n",
      "\n",
      "It’s so dominated by white men who think they know everything and that numbers can explain everything I can’t be bothered with events and online discussion any more.\n",
      "\n",
      "I have sooo many thoughts, but I’m going to leave them most of them for a later time. I think this movement needs a healthy skepticism for rationalism and the role it has played in our history. I also think “the diversity” issue is way broader in scope than it’s currently being treated as. We should be asking not just, how can we bring more “diverse” people into EA, but rather why does this not appeal to most people (and instead to people who have traditionally and continue to hold great power), and what can we learn about our own movement from the reasons others might reject it? \n",
      "\n",
      "I've routinely seen women, people of color, and older people treated dismissively and/or disrespectfully. I know numerous people in those demographics who are bought into EA ideas and actively work to implement them in the world, but want little or nothing to do with the EA community.\n",
      "\n",
      "Movement should not be narrowed down to a small subset of elite researchers on AI. The benefits of having a more diverse and broader movement are substantial.\n",
      "\n",
      "I would like to see more women, and more people outside high-tech circles involved and in leadership positions.\n",
      "\n",
      "Neg:  - the movement is extremely biased towards english speaking countries . I do not see much effort - especially from the english speaking part of the movement - to change this.  - the movement is pretty undemocratic: even as someone who spends a lot of time thinking and working for EA related things I am not able to participate in a sort of election process for the leaders (such as CEA or 80k). And I see no efforts to change this.  - there seems to be a lack of exploring new ideas / ways of doing stuff: the explore / exploit tradeoff says 37%! I feel that we barely have touched 2%.  - EAs seem to neglect the donation part. Many EAs 'invest' in their careers and skip the donation part. I think these are not mutual exclusive and it should be almost obligatory to donate as an aspiring EA.  - EA is relying on signaling a lot: I have spent quite some time with people from the big universities such as Stanford, Harvard or Oxford. They do not differ much from good students at other places.  - EA is degrading the work of many people: The idea of high-impact careers could be communicated in a way so that people that are in their 30-50's don't feel bad for only being a doctor, teacher, nurse or whatever. I think the movement is thereby rejecting a lot of potentially highly valuable people.  - EA events sometimes are extremely competitive and can lack the fun that is necessary to glue together a community  - CEA's community building department with 3(!) people is ridiculous.They need more manpower!  - The EA movement is heavily dependent on Facebook, Google and Slack. Many times it is simply impossible to attend events without having a Facebook Account, CEA forces you to have an Google Account to apply for funding. The reasons for rejecting these services are numerous and there are good open alternatives.  - Additionally: Most of the time it is really really hard to get contact to local EAs because: there is no website for them, a closed facebook group, people do not answer your mails / Facebook requests.    pos:  -  All in all it is an extremely impressive movement with some of the brightest minds. I'm proud being a part of it.  \n",
      "\n",
      "I don't know much about your community, and I am not a part of it. I like your ideas, and I appreciate the work you are doing. It's possible I'm being unreasonable, but judging purely by what I've read online, especially LessWrong, your community seems too likely to be unwelcoming for me to want to try to get involved (I'm shy, and Christian, and conflict averse, and not willing to devote my life to EA, and I strongly suspect people would try to talk me out of things I don't want to have to argue about and not take no for an answer - which, again, may be unfair, but it's often the feeling I've gotten.) Your (very early) question about how involved people were was backwards, by the way, at least for me - I follow EA guidelines for donation, but my community involvement is mostly limited to reading GiveWell charity evaluations. And I would be much more excited to introduce my hypothetical friend to the body of research - and idea of \"no, we can actually do this\" - than the community, because... well, see above. I'm not part of the community, and don't know if it'd be good for hypothetical-friend. But the ideas, the work and the research and the chance to save lives, are amazing, and I really do appreciate what you're doing. I just also find you scary. Don't worry; I find lots of people scary. \n",
      "\n",
      "I know you have heard it before but i feel it lacks diversity and is somewhat elitist which would prevent me from introducing some others who shared similar values to it \n",
      "\n",
      "If they were young/impressionable, I'd still be excited -- maybe even more so -- but I'd feel a need to supplement their common sense so that they don't burn out or head into various standard pitfalls.  And if I didn't have time to do that, I'd feel worried about introducing them but would probably still do it.\n",
      "\n",
      "The first impression of EA's core messages can be a bit black-and-white and pretentious. If you dig deeper and get to know the movement a world of respectful discussion and nuance appears. This makes me sometimes hesitant to introduce my friends to the movement. \n",
      "\n",
      "I would like to see the community become more diverse, particularly with respect to age, gender, and ethnicity. \n",
      "\n",
      "I like the ITN Framework, because it is one attempt to deal with rivalry and achieve some additionality and counterfactual impact. EA needs more diversity in thinking and approaches - less optimization and more search, and explore topics around embodied practices, collective intelligence. My personal interest is rivalry, and antirivalrous goods, or ways how to change mental models (seeing people as processes and not objects, seeing people as emergent properties of whole ecosystems... )\n",
      "\n",
      "One thing I noticed here is there is seemingly a big crossover between those interested in Jordan Peterson and EA broader community here, and that strikes me as presenting a barrier to access. What I mean is, if that is someone's first experience in the community, and they don't know to ask \"so what does this guy think and why do you believe him, \" it's likely that this subject will alienate potential new members, the ones you need for resilience and fresh ideas through diversity. \n",
      "\n",
      "Last time I was at a meetup I found myself somehow the most in-touch person present. While it was fun being the only one who knew the HPMOR URL by heart, introducing the organiser to SSC, and giving hope to the only other person present who had heard of Brian Tomasik, I wonder if it's a good or bad thing that the average general EA-related knowledge level in the community appears to be decreasing. I'd say I appreciate the diversity of ideas but am wary about losing our way, in a sense\n",
      "\n",
      "No human has a truly altruistic utility function, and the false pretence of true altruism may impede us from finding the most true and beautiful possible compromise of our real utility functions.\n",
      "\n",
      "First EA people I met were just the most wonderful human beings. However, nudity at parties really put me off. Can find that EA people are too elitist.\n",
      "\n",
      "EA could benefit from being less insular.     The ideas of economists like Tyler Cowen, Robin Hanson, Glen Weyl, etc. are very relevant. There's a great deal of skepticism regarding AI risk from the broader AI research community that isn't taken seriously enough.    Generally I think the standard of diversity of ideas set by the 80,000 hours podcast is great and should be a benchmark for the community more broadly.\n",
      "\n",
      "I worry that some EA's can be a bit dismissive of non-EA beliefs or concerns. EA is not a very diverse sphere, neither in demographics nor in background.\n",
      "\n",
      "I've had a very positive experience with the EA community. Considering how multifarious the movement is and how quickly it is changing, I think people have done a great job being inclusive and welcoming to newcomers.\n",
      "\n",
      "Culture can feel non diverse and elitist at points (particularly at conferences vs other meetups like socials)\n",
      "\n",
      "As this survey will likely show, the movement has some serious diversity problems, which could be symptomatic of, or in the future cause, problems with the ideologies promoted, and if nothing else gives outsiders good reason to distrust us and makes out already controversial views lower traction. I think more thought and research should go into the causes of these problems and what if anything can be done about them.\n",
      "\n",
      "My answers might seem strange given that I identified as part of the community, but the fact is I'm a journeyman who wants to learn more.\n",
      "\n",
      "I get that EA (at least from my view and how it's explained to me) is about rationality and a more consequentialist way of thinking. But this modality of spreading the message is, pardon my french, dogshit (IMO).    Everyone I've interacted w/ at EA is so emotionless and too logical; too academic too and not pragmatic enough.    So many look at problems just in terms of numbers instead of seeing what is in front of their own eyes.    Overall, though I can relate to these people as I've worked in tech/STEM for so long, 99% of the general public, IMO, will think they're robots.    It's no way to market what is a very important movement to push.    People in the EA movement, from my view, need to improve their people skills and think more pragmatically.    Otherwise you will have the typical business-douchebags who can talk-the-talk and spin things effectively walk all over the EA side of the fence.    Also, re 80k, maybe I'm misinterpreting their mission, but again, it seems like they think people are robots. You can't expect people en masse to work shitty jobs they don't find maximally fulfilling and donate a decent chunk of their salary to people on the other side of the world.    It's instances like this where a clear lack of human understanding plagues EAs — from my view, anyway.    It just seems to me everything is so oriented towards analytical-thinking that the actual foundational empathy required to do-good is lost.    All just my opinion that I imagine most will disagree with.    Just my observation as somebody who does has dealt with the software-engineer types my whole career. I see similar patterns.\n",
      "\n",
      "I'd like to see more diversity of interventions financed in animal protection-related projects. I'd like to see climate change prioritazed by the EA community.\n",
      "\n",
      "It seems to share the biases common to the tech community which skews white, relatively affluent, kinda libertarian and very male, and has trouble considering realities that primarily affect other groups to be truly important, despite the real justification for taking a macro perspective on the effects of giving \n",
      "\n",
      "I think it could be more inclusive of other academia such as the humanities, besides philosophy and politics. Even though it is enlightening and I am very happy to be learning information outside of what I am studying, a lot of the talks at my local group can sometimes be hard to understand when you are not surrounded by the discourse that is being discussed. Additionally, I believe the introduction of different academic areas would be more insightful for the community and bring a new perspective, specifically history.\n",
      "\n",
      "Too few women and diversity and too much maths/\"hard sciences\"  (says the mathematician...)\n",
      "\n",
      "I think EAs (at least the ones I’ve interacted with) aren’t willing enough to admit (to themselves and others) that they’re human - with all the ingrained selfishness and dishonesty that entails. They too easily think of themselves as purely utility-maximising, good-doing agents, and then are disappointed when they or others don’t live up to this impossible standard. At least within my group, EA needs a heavy dose of realism and humility with respect to what an individual human can and will do.\n",
      "\n",
      "I can experience some frustration with EA community, especially with the younger people getting involved. They can be quite dogmatic, lacking nuance in their thinking, they are also arrogant, and use EA as a signalling contest, to compete to be \"the most effective\". I have a feeling sometime that the \"altruism\" side is left on the side. I also feel that there is a lot of focus on research and researchers, while I do think it is needed, I also beleive that other type of work are very useful, especially for implementation. I have a management background and work as a consultant, and we are very few like this, and there is almost 0 jobs around this type of skills with 80000h. I think that EA could be quite elitist and only value very specific type of people (aka researcher in AI). This make the organization more and more homogenous, and makes me want to leave sometimes. \n",
      "\n",
      "Yes - it can be a bit narrow and exclusive, especially in assuming specific world views. eg I am a progressive christian & baby boomer - both are minority groups in EA - that is fine, but assumptions (at times) are frustrating eg assumptions that all EAs are rationalist skeptic atheists or utilitarians or young-ish\n",
      "\n",
      "years ago, I thought the commerical that was made (white guy marries laptop) was tone deaf \n",
      "\n",
      "EA Global is far too exclusive. Many people who wanted to attend were not allowed to!\n",
      "\n",
      "The reason it's not higher is because sometimes the community can come across a little unfriendly, and also has some pretty different ideas from the mainstream so it'd have to be a soft introduction! I also didn't get more actively involved in EA stuff for several years because I didn't feel very at home as a woman without a Philosophy post-graduate degree! This has improved a bit since but the EA community is still not at all diverse.\n",
      "\n",
      "I have had people attempt to optimize my life for me because of their dedication to effectiveness. It has been a great source of unhappiness and discomfort, largely because they value how my output metrics contribute to making the world better over actually valuing me as a living breathing human being. A person. I believe the principles of EA are solid, but they can easily be misapplied to cause harm to individuals.\n",
      "\n",
      "as to the german community: i can understand their commitment to changing the world simply via getting a fitting job. that´s great. that makes sense. but. it only makes sense, if they are better than those who would get the jobs otherwise. and somehow basically everybody in the community beliefs that they are superior to those others... even if 50% are superior, there is no exciting answer as for the rest.   some/many ea´s in germany want to stay a small group without diluting effects to the core principles. i strongly disagree. it would be great if all people would focus their donations to effective organisations. but as for the reality it might be even better, than the average organisation doubles it´s effectiveness because of hords of people starting to ask questions like: \"hey, organisation x, what do we get... is this the best way... we are not interesting in the percentage of money which reaches africa...\". i think it´s important to get the idea of effectiveness in more peoples mind. they do not need to become effective altruists.     \n",
      "\n",
      "Scott Alexander's https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/ was outright haunting.  Can't invert an ill conditioned matrix and made EA seem more Superman Villain and less be nice and humble and give people bed nets. \n",
      "\n",
      "Lacking diversity in several ways, making it unappealing to people who don’t fit in with the general EA trope.\n",
      "\n",
      "EA Global 2019 SF was well managed and a positive experience. However, it felt a little stale. I would like to see some new voices and perspectives, including those critical of EA. The community is also heavily geared towards young career professionals.  More balance would also be valuable.\n",
      "\n",
      "Way too much dancing on the head of a pin. People way too young and inexperienced with how the real world works.\n",
      "\n",
      "A significant amount of community members have poor social skills. Many come across as naiive and prideful. I'd be worried introducing most people to anything but a hand-selected group of EAs, lest they be turned off by arrogance and inability communicate their views with sensitivity and nuance. Terrible on diversity, not great with women. As a mixed race person who didn't grow up rich, I often feel uncomfortable and out of place, despite having attended elite universities for undergraduate and graduate school.\n",
      "\n",
      "Answered 40 only with a 6 because I think the EA community is currently lacking in many areas I think and I'm worried that introducing people to EA might actually curtail their impact, mostly due to lack of diversity of opinions, career paths and expertise in EA.\n",
      "\n",
      "I feel consideration of or research into moral compass of humans and the following basis of human ethics would be a good idea, given the neuroscience of ethics:  value, practicality, reality, sentience, well-being  (the number of items \"pinged\" seems to vary from 1-5)\n",
      "\n",
      "Being a young woman without an advanced degree, I haven't always felt like I fit the \"EA stereotype\". It has been difficult for me to make personal connections within the EA community and I would have similar concerns about introducing any of my friends to the community. \n",
      "\n",
      "Met a woman two months ago, who works as a researcher for a charitable cause fund. They had been invited to EAGlobal 2019 in SF, and attended but were turned off by the repetitious questioning they got from other participants. They described the conversations as quite stiff and instrumentalist, and found the lack of diversity in participants frustrating.    Sounds a little like the community they experienced was a little too utility-maximising in their approach to connecting to humans.\n",
      "\n",
      "I wish it were more diverse and accepting. \n",
      "\n",
      "It is very frustrating that there are few women in EA.\n",
      "\n",
      "Imo our community was too goal oriented at the expense of friendliness & human relations / friendship. I'm working on improving that.\n",
      "\n",
      "The community is and encourages itself to be: white, male, middle to upper class, US-and UK-centric, colonialist, \"rationalist\". The community does not believe in systemic issues such as racism or sexism. The community does not consider that capitalism may be a problem. The community believes itself to be the most important cause: 'meta' charities get all the focus.    I do frequently tell friends and colleagues about EA, and encourage them to follow the principles around cause selection and donations, however I strongly discourage people from becoming involved in the community itself.\n",
      "\n",
      "While I'd love to work for an EA organization, I don't know that it's realistic for me as a person with a young family needing a stable income and preferably some kind of pension in a city near my aging parents/in-laws. Reading EA material did help me come to terms with certain aspects of how I live my life and the career path I have chosen.\n",
      "\n",
      "Diversity issues. If you want to discuss in more detail: kathryn.mecrow@gmail.com. \n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER weird: '*weird*', '*awkward*', '*social*', '*offputting*', '*comfortable*', '*cult*', '*rude*', '*nerd*', '*off-putting*', '*offputting*'\n",
      "###\n",
      "\n",
      "Too many weird/awkward people.  Too cultish and inward-facing (on a social level) for me to bring in some of my friends.\n",
      "\n",
      "Don’t really feel comfortable sharing on a survey \n",
      "\n",
      "Much of the EA community is too weird along other dimensions (vegan, poly, mental health issues) and not cool/competent enough    Would be excited to introduce them to specific people\n",
      "\n",
      "I would introduce them to GiveWell, Future Perfect, and Animal Evaluators.  Besides those, my actual experience with EA on facebook has been subpar.  People seem too robotic and even rude on occasion.  They seem more interested in efficiency than they do community building.\n",
      "\n",
      "I'm worried that it can feel a bit cult-like.\n",
      "\n",
      "Gender and racial diversity are lacking; it's no fun being a minority in a monoculture\n",
      "\n",
      "I may feel that some people in the EA community lack basic social skills, hence I can be worried that new people will be \"scared off\" if interacting with the wrong people in the beginning. \n",
      "\n",
      "I don't feel comfortable in the Spanish EA group because it's a \"boy's club\" where I have to bear sexist and sometimes even racist comments. I'm the only woman, and also the only immigrant and non-white person. I don't feel safe and persistently discriminated against. Given this situation, I stopped attending several local meetings and events. \n",
      "\n",
      "I would love to be able to find work in EA related fields but have found it difficult to find entry-level roles.\n",
      "\n",
      "EA suffers from a terrible lack of diversity and inclusion. As a non-White member of the community from a lower income background, I often felt very alienated, lonely, and unwelcome at international EA gatherings such as at EA Globals in 2017 and 2018. I also feel that many EAs including 80 000 Hours career coaches lack empathy for and understanding of people with my kinds of backgrounds and lived experiences such as having faced significant financial stress, relied on some form of charity food aid, lived with systemic and persistent racial discrimination including in the job market, and also being active in a religious community. I have also been very unwell these last few years, and felt very uncared for during EA Globals, and was at high risk of having a serious health incident, and no one noticed or even reached out in kindness even as I wandered around the conference venue alone and in distress. This could be because they don't understand that distress is expressed differently in different cultures and they lack the intercultural understanding to read different signals of distress. More diversity and inclusion in EA could have made me feel more welcome and supported. \n",
      "\n",
      "It gives off a bit of a cult feel at times, and from my limited experience, some of us can be quite full of themselves so I would recommend it with some reservation.\n",
      "\n",
      "I would be very excited to introduce a friend to certain people within the EA community, especially those who have experience relevant to my friend's interests, but I would not necessarily be excited to invite them to the average EA social event, mostly because I find people at EA/rationalist events in the Bay area can be awkward and unwelcoming.\n",
      "\n",
      "Ea has a problem of diversity, which makes it difficult to be\"socially satisfying\" for many people\n",
      "\n",
      "Theres a lot of focus on rationality and less on...being a good person also with being social and connecting people  being just..good-hearted. To yourself and everyone around you\n",
      "\n",
      "I love, love, love my NYC EA group and the wonderful people I've met there.    However, \"Big EA\" has always seemed intimidating and off-putting. I was very briefly involved in an EA group in another city around 2010, and it was so unpleasant that I didn't even try to go to another until 2016, when I moved to NYC.    \"Big EA\" always feels like it's a contest who can be the biggest wonk with the mathiest brain. I get it, I get it: making tons of money and/or being extremely clever (in an EA way) are necessary for making the world a better place.    I'm not clever, and certainly not in the ways that \"Big EA\" loves and rewards. The things I'm really good at - being a social worker, being diligent and reliable and unflappable and kind - don't generate much income and don't make EAs excited.    But here I am: diligently and reliably doing the work that I was put on earth to do, making my paltry monthly donations to highly effective causes for the past ten years, and being kind and encouraging to my EA community. So, do I get to call myself an effective altruist?    For my local group, I know the answer is yes. But I always strongly suspect that \"Big EA\" (eg. EA Global, the web forums, groups in other cities, etc.) would not welcome me, and that I would be extremely uncomfortable there.\n",
      "\n",
      "It is at times difficult to describe the concept of EA to people.\n",
      "\n",
      "I just attended the EA Doing Good Better Conference in Asia. I am a new community builder in the Philippines and I am really happy that I am part of this social movement.\n",
      "\n",
      "I feel the EA community has become the \"EA / Rationality\" community. I wish there was more separation between both since I'm not really interested in \"Rationality\" and I find the nerdy, AI safety focussed, super-rational approach to EA off-putting sometimes.\n",
      "\n",
      "It's a very nerdy community and people, on average, are a bit more socially awkward than other groups I know. I like it but it may not be everyone's preference (even if they, as an individual, are EA-inclined) \n",
      "\n",
      "The EA community online currently has issues where a lot of spaces are IMO overmoderated, making it difficult to introduce a newcomer to what feels like a \"natural\" conversation and social hub (and ultimately driving people towards weird areas like Dank EA Memes). I'm not sure where I would suggest a newcomer go in order to hang out and converse with other EAs -- the EA Corner Discord server might be the best option but it itself has major issues with drama and only really accommodating certain conversation styles.\n",
      "\n",
      "Generally, extremely lovely people who are very welcoming even to the 'out group'. Generally very excepting, thoughtful, and have in mind what their flaws as a community are.   We are a bit weird, but I like to think it's endearing.\n",
      "\n",
      "I feel very aligned with the core ideas of EA, however my first exposure to people in the community was underwhelming. As a generalisation, I found EA members to be more egotistical, less warm, and less socially aware than the average population. I would like to see the EA community become more diverse (especially more women and more people from humanities backgrounds), and I would like to see the community improve in social skills and interpersonal altruism. \n",
      "\n",
      "It's a great community for me and others like me, but seems hard to get into if you are not too interested in ideas and nerdy stuff\n",
      "\n",
      "I am concerned by the culture of effective altruism, especially with respect to awareness of inappropriate power imbalances in sexual relationships, hero worship and the poor incentives to call out bad behaviour of those with status in the community. \n",
      "\n",
      "I feel like the community is a subculture if it’s own and that more disagreement might be healthy\n",
      "\n",
      "Occasional negative experiences from meetups when interacting with men with poor social skills  \n",
      "\n",
      "The overall messaging online seems to have moved away from an inclusive \"most people can make a big difference\" to a message about super high value career paths, and that is one way people will feel less valued in the community. I have also seen a large disparity in the distribution of support (monetary and otherwise) to groups and individuals around the world, and that is very offputting, and also signals that the community doesn't value us. \n",
      "\n",
      "many EAs are too nerdy\n",
      "\n",
      "it can be difficult to talk about with others as seems cultish. need more business people as they have a lot of influence, and more outreach to people with experience.\n",
      "\n",
      "The EA community is socially stifling. I often find spending time with groups of EAs to be quite tiring. There are many reasons for this:  - Higher than normal fraction of people with limited social skills  - Many people overestimate their social skills  - (Attempted) intellectual showing off  - Intellectual pissing contests  - Many people reject \"normie\" social norms simply because they're normal (for example, the disdain that many people have for small talk or for being gentle about disagreeing)  - Distaste for mainstream culture (sports, for example)  - An insistence that every conversation should be about things that seem EA-related\n",
      "\n",
      "I fully identify with the principles of EA, but the community can often be off-putting, especially condescension toward non-longtermist causes.\n",
      "\n",
      "I think the community was extremely quick - maybe too quick - in absorbing me. It was a bit weird to experience that I'm \"what the community regards as valuable\". I felt some kind of pressure at times.\n",
      "\n",
      "reference to 'the movement', 'the community' etc makes it feel a little cult-like. Surely it is just a way of thinking...?  Also, the focus on 'EA jobs'. This is a very limited field and those working or aspiring to work in this field should not be seen as 'more than'. Those people still need the rest of society to grow their food, build their houses, drive their trains etc\n",
      "\n",
      "Positive discussion culture. People are aspiring to be rational, but nonetheless kind to each other. \n",
      "\n",
      "Although I'm still very much interested in the community, I've become more concerned about the current norm for doing prioritization within EA. Specifically, I think that by maximizing impact with respect to our values we end up with \"free-rider\" problems where we each focus on cause areas that only we think are important.    Also, the more weird that EA priorities get (mainly I have in mind the shift towards influencing the far future) the more difficult it is to pitch it to friends.\n",
      "\n",
      "Wouldn't be super excited, as its a bit culty and off-putting.\n",
      "\n",
      "On average, I perceive the EA community to be somewhat intellectually elitist and low in social skills and \"welcomingness\"\n",
      "\n",
      "Overall it's some of the most wonderful, thoughtful, and focused people I've met. At our worst however, we lose kindness and social intelligence in our efforts to maximize impact. \n",
      "\n",
      "I love the blog Giving Gladly and the supportive and informative emails I get from Givewell. I don't think I would ever feel comfortable attending an EA event because I'm not \"pure-EA\" enough. I am not planning on changing to a higher earning career, though of course I will do what I can to earn the most I can within my field (massage therapy/energy healing). I feel that my spiritual beliefs would not be accepted in the EA community or would simply make people feel uncomfortable. But I wish that that weren't the case so I could make EA friends without feeling like my own decisions will be frowned upon. \n",
      "\n",
      "It would be nice to have a clear and frequently updated list of what most EAs believe to be the most important cause areas. I have seen different lists around, and it can be difficult to communicate about EA to others when there is not a centralized, updated, defensible resource to use as a tool.\n",
      "\n",
      "It is really hard to be involved in the community itself as someone who is an 'average person'. The EA community itself seems to award high status to Ivy Leaguers who are very accomplished. I did not even consider aligning my career towards it, because it feels like careers for EAs would not even want me. If it were not for Jeff Kauffman's, Julia Wise's, and Kelsey Piper's online presence, I would have a lot of difficulty feeling like this was a movement for me.\n",
      "\n",
      "Y’all are fucking nerds.\n",
      "\n",
      "I'm starting to get the feeling that the EA community is a little too interested in just discussing things and not interested enough in putting things into action. Maybe this is due to risk aversion but maybe its also a little to do with enjoying discussing nerdy topics too much.\n",
      "\n",
      "Culture can feel non diverse and elitist at points (particularly at conferences vs other meetups like socials)\n",
      "\n",
      "I think many EA members come off as less socially skilled, which can be a problem for people on the other end of that spectrum. I personally don't have too much of an issue with it but I would give pause to introducing certain friends into the core community.\n",
      "\n",
      "I have grown somewhat disillusioned with the EA community and philosophy.  In the community, I perceive intellectual arrogance and some cultish behaviour (although I admit this is not necessarily a \"rational\" perception, but more of an uncomfortable feeling).   In the philosophy or theoretical basis of EA, I feel that   a) the parts that feel most evident and easy to be somewhat certain of are not original (e.g. the morality of maximising utility) and  b) the parts that are original (i.e. the pointing out of particular causes, like XR) are most questionable from an epistemic point of view, hence harder to trust.   \n",
      "\n",
      "I would feel excited to introduced them to many relevant ethical and intellectual ideas associated with EA. I would feel nervous about introducing them to the community itself -- since I think any given person has a decent chance of finding the community offputtingly insular, undersensitive to what people previously unfamiliar with EA will find weird/uncomfortable, etc. \n",
      "\n",
      "I fundamentally care about helping the extreme poor, about working against climate change, and more generally leveraging my privileged position to make the world better, not worse. Effective Altruism has useful resources for me to find out how to do this. Not to be rude, but I don't really identify with the EA community. Especially on the forums there are some strange discussions such as plant welfare and the more obscure sounding apocalyptic scenarios that to me just sound outlandish.    Nonetheless there's some fantastic discussions and research here, and it's very encouraging to find like-minded people. For me EA is more of a resource. I suspect there are many people on the fringes with a similar perspective.\n",
      "\n",
      "It can be difficult to understand what the up to the minute recommendations are donating to specific charities or taking certain career paths. I don’t have the time to do the research and I appreciate the info on GiveWell and other sites but there’s often a disclaimer that the data is a year or two out of date but without much follow up on where to go. \n",
      "\n",
      "I am very happy with EA thinking, but not with the community. I feel  (and this is just my experience) its very dominated by guys, and mostly the non-social kinds. In the past I've worked for a local EA group and felt my voice was not at all heard, even though I had one of the best credentials (e.g. in terms of university degrees). I felt I was approached as the 'social one', who was good to have at events for mingling, but not for the 'real content'. I have honestly been hesitant to invite friends/colleagues to EA events because of this tendency, even though I know many of them would align with EA thinking. Many of the non-social EA guys I'm referring to here tend to be so fanatic in their EA beliefs that it comes across as closed off and doesn't encourage new people to join. This halters the spread of EA. \n",
      "\n",
      "A bit cultish, a bit tech-bro-ish. There's an element of \"if everyone adhered to my system, the world would be fixed\" which is not really the case. \n",
      "\n",
      "EA is a great principle, but it can be hard to introduce others to the concept as it can seem both somewhat rigid, and somewhat cultish.  I personally also find the 'approved' EA charities very narrow in scope (even if this is understandable).\n",
      "\n",
      "At meet-ups people can often be very intense in a way that can be off-putting, although, of course I have met some great people through the community. \n",
      "\n",
      "I enjoy the EA community and wish to see it grow. They are people with values and a type of nerd geekiness that is relatable, and home-feeling. I believe continuing to attract such members will be beneficial to the group as a whole.\n",
      "\n",
      "I get that this is the EA survey, but it's weird seeing so little references to the rationalist(/ea) community i.e. I basically conflate the two in practice. But yeah, I love the ea/rationality community! I'm super grateful for the two jobs I got through the community, too. I'm mostly (VERY) jaded about grad school and about having discouraging experiences with people who are famous within the community (being brushed off by several people, and being told my research was *harmful* by one person I respected at the time).\n",
      "\n",
      "It's very difficult to engage people in tasks beyond the mere agreement that EA, as a movement, is right. We need more people engaging full-time in EA in my country, but it's hard to people to mantain their incentives to this task.\n",
      "\n",
      "I feel very comfortable in our lcal EA-group. They combine rational thinking with social skills. I enjoy to spend time with them even outside the EA-topics.\n",
      "\n",
      "It's hard to introduce people to EA when so many of the associated concepts (e.g., X-risk) seem so weird at first glance. \n",
      "\n",
      "Most people are very welcoming to newcomers who are unfamiliar to the goals of EA, but sometimes newcomers at in-person events are treated as not worth the time by more experienced EA community members.    Memorably, my wife tried to start a conversation with someone at a Meetup. He asked her her opinion on some particular, and she said she didn't know about it. He simply turned around and left. I think he was \"protecting his time\" but it was very off-putting.\n",
      "\n",
      "I said 6 to question 40 because as much as I would enjoy sharing EA with others, I am weary to get them too excited about a community that is challenging to break into - apart from getting a job at an EA org, aligning with an EA career path and donating, EA doesn't have much of a community or culture beyond attending a local event (if one exists) and going to  global. Many other brands and movements have strong cultures that will pull people away from EA. In the long-run I imagine EA will become more of a tool that many people use to select careers and less of an established community with a strong identity and lifestyle. \n",
      "\n",
      "A lot of EAs are pretty socially awkward; there are only a few I'd be willing to introduce my friends to. The term 'effective altruist' can come across as a bit snobbish.\n",
      "\n",
      "My excitement about introducing new people to EA is somewhat tempered by a desire not to seem like a cult.\n",
      "\n",
      "I have encountered two common problematic first impressions of EA for those who previously did not know of it during member-recruitment and club events:    - That the meaning of EA is confusing and its purpose poorly communicated  - That EA is elitist in its definition of \"effective\" and how it communicates its core values \"downwards\"    I think that a more strengths-based and social approach to new members and how EA events are run would at least alleviate elements of both these problems.\n",
      "\n",
      "I think it’s in a bit of an intellectual and social bubble—not to a huge/fatal extent but it’s the main thing I’d suggest improving\n",
      "\n",
      "Find it an environment that challengs me to be ambitous, though sometimes leads to feelings of intimidation. This is, however, the main reason I involve myself - to maintain high ambitions in the 'right' cause areas. Though consequently, rejection from EA Orgs / ambitious career paths does lead to feelings of inadequacy that I might not have experienced, outside of the community. For now, I'm comfortable enough with this tradeoff.\n",
      "\n",
      "EA is great because of the people. everyone i've met has been really lovely and interesting and kind.  I'm so involved in the community because of the people i've met, and my conviction that we have shared values, concerns and beliefs.   much less so because of the core EA orgs, although I respect their work.  to me, the community is what makes EA special, and the values that have been cultivated - openness to learn, humbleness, willingness to argue and debate. and a genuine sense of caring for others.  without the community and without having met the people, investing loads of time and resources into EA, specifically community building, wouldn't have 1/10 of the appeal to me. \n",
      "\n",
      "I have nothing but respect for the EA community, but some people perceive its members to be weird/nerdy. I tend to be more excited about communicating the ideas than presenting their exponents.\n",
      "\n",
      "It's a bit disheartening to me to see so few likes/shares on EA's (MacAskill, GiveWell, etc) social channels. Any new YouTube content makes me really happy. Future Perfect makes me happy. Publishing the results of my donations and the community's donations is extremely motivational for me\n",
      "\n",
      "To avoid isolation and hasty decisions, I would feel uncomfortable introducing someone without offering some significant time for in-person discussions.\n",
      "\n",
      "I resonated a lot with an EA forum post about feeling terribly behind the ball compared to more experienced EAs, about how hard it is to qualify for EA-group jobs, and about feeling depressed by knowing how ineffective one is likely to be over the course of one's life. Still trying to sort out how I feel about the difficulty of contributing to the EA project.\n",
      "\n",
      "Finding and creating opportunities for meaningful involvement was difficult. It was also disheartening not to find any fitting job offers within EA organizations.\n",
      "\n",
      "It's one of the best communities I've found for meeting nice and interesting people, the social benefits are a large part of why I spend time with EAs.  I eat meat and don't think animals have moral value, so I feel alienated by the norm of vegan food.  I think it's quite susceptible to group think, eg on controversial and difficult topics like AI Safety\n",
      "\n",
      "A significant amount of community members have poor social skills. Many come across as naiive and prideful. I'd be worried introducing most people to anything but a hand-selected group of EAs, lest they be turned off by arrogance and inability communicate their views with sensitivity and nuance. Terrible on diversity, not great with women. As a mixed race person who didn't grow up rich, I often feel uncomfortable and out of place, despite having attended elite universities for undergraduate and graduate school.\n",
      "\n",
      "There was a great TED talk on how activist movements need introverts but don't know how to use or engage them. Specifically looking at ways to benefit from people who don't want to meet face-to-face, read social media but don't want to post, etc. can still support and benefit a movement. EA needs to learn those lessons and stop being a movement for extroverts only. Even the questions in this survey show a massive bias against introverts. Look at the pairings in question #12 where learning and personal action are in a forced linkage with social action. So there's no way for a person to read everything they can find and apply the lessons to their own decisions in a meaningful way (half of answer #5) but not participate at all socially (half of answer #1). Which is my truth that is not at all correctly reflected when I answered #3.\n",
      "\n",
      "Some effective altruists I met at Oxford had poor social skills and did not seem to care very much about the feelings / perspectives of non-effective altruists or even effective altruists they did not share much in common with. I think this is bad for two reasons. First it might turn off some potential effective altruists. Second there is lots of wisdom in other communities / perspectives that I think effective altruists may miss out on if they dismiss them too readily.\n",
      "\n",
      "I find the recent focus on doing a lot with a small group rather than persuading a wider audience to give to higher impact charities very off putting. There is an arrogance about it and I worry it could go very wrong. My experience with the ea community in Montreal was very uncomfortable. I generally find the focus on ai safety comcerningly self serving - working in ML is a very nice career option. The Facebook forum is deeply intimidating.   \n",
      "\n",
      "Being a young woman without an advanced degree, I haven't always felt like I fit the \"EA stereotype\". It has been difficult for me to make personal connections within the EA community and I would have similar concerns about introducing any of my friends to the community. \n",
      "\n",
      "It's not as cool to be weird as you lot think it is!\n",
      "\n",
      "I have many positive thoughts, and many negative experiences. My single-biggest issue with the EA community is arrogance and dogmatic thinking. I have had a difficult time getting individuals past certain 'mantras', for lack of a better word, because they feel that EA is all-or-nothing. This keeps many microdonations from reaching EA supply chains, and I believe is cumulatively worse than having people get involved in small sums at the start, with an increase as their understanding and conviction rises.\n",
      "\n",
      "Any smart approach to social needs and interest must always challenge itself.  I don't think that is a challenge for EA as I believe it does that well.  But complacency is the enemy of all social innovation.  I am glad to see/feel that EA advances.\n",
      "\n",
      "It is really difficult to align your life with EA principles if you have already finished your studies before getting in contact with EA.\n",
      "\n",
      "Esoteric jargon is off-putting. Dense text is off-putting, need for better visual communication. \n",
      "\n",
      "Utilitarianism gets bad rap in my academic community. Also in my wider political and cultural community, emphasis on 'rationality' is also unpopular.\n",
      "\n",
      "I think I'd introduce them to EA ideas, but with less jargon. Show them some selected EA resources and introduce them to some select people. But I just don't think \"EA\" generically has that much to offer; on the margin I want people with EA goals to be less rather than more engaged with the EA community/social network. (Because I suspect this is better for the world/higher-impact.)\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER elitist: '*elitis*', '*hostile*', '*condescen*', '*dismissive*'\n",
      "###\n",
      "\n",
      "I believe we need a message that resonates to the average citizen.  Elitism will limit our impact in the longer term.  On a related note, we (very much including our NYC group) would benefit from more evenly corresponding to the demographic makeups of the communities we live in - not that this is easy, but for our group to be completely unrepresentative will, again, limit us.  We must find ways to connect with and include the public, without sacrificing our core values!\n",
      "\n",
      "The overly proud focus on logic in discussions sometimes comes at the cost of decent human polite behaviour.     EA can feel elitist and seems quite targeted to ivory league graduates. \n",
      "\n",
      "Don't summarize EA like this to someone new: \"We are elitist who don't think climate change is important. In addition we think Nestle and Monsanto are morally good companies because they act in a capitalist way. Also it is good that we can buy T-shirts for 5€ because those textile factory workers get a few cent of that and don't have to live as a farmer anymore.\"  The friend I brought to the local EA group almost punched him.\n",
      "\n",
      "I watched several videos from a EA global panel (circa 2017?) that expressed views I found abhorrent. I can’t remember precisely but it could have been something involving cities that was extraordinarily dismissive of poor people and common sense. It strongly turned me off EA. Sorry I can’t remember more detail.\n",
      "\n",
      "I feel like the EA community is very elitist and I am not sure if it's great\n",
      "\n",
      "A sort of moral elitism can be felt sometimes from those very devoted to EA principles.\n",
      "\n",
      "I fully identify with the principles of EA, but the community can often be off-putting, especially condescension toward non-longtermist causes.\n",
      "\n",
      "I've routinely seen women, people of color, and older people treated dismissively and/or disrespectfully. I know numerous people in those demographics who are bought into EA ideas and actively work to implement them in the world, but want little or nothing to do with the EA community.\n",
      "\n",
      "Elitism makes it hard for lots of people to fully integrate\n",
      "\n",
      "I get a slight elitist perception. The organizations I look at for work tend to hire folks with degrees from prestigious institutions. I would love to see passion, and ability to learn prioritized for those of us excited to contribute with a more alternative career path to this point or academic background. \n",
      "\n",
      "I know you have heard it before but i feel it lacks diversity and is somewhat elitist which would prevent me from introducing some others who shared similar values to it \n",
      "\n",
      "On average, I perceive the EA community to be somewhat intellectually elitist and low in social skills and \"welcomingness\"\n",
      "\n",
      "It's a good community. Too elitist perhaps, except the elitism has good rational justifications.\n",
      "\n",
      "Concern that it comes across as elitist, which can be intimidating.\n",
      "\n",
      "First EA people I met were just the most wonderful human beings. However, nudity at parties really put me off. Can find that EA people are too elitist.\n",
      "\n",
      "I worry that some EA's can be a bit dismissive of non-EA beliefs or concerns. EA is not a very diverse sphere, neither in demographics nor in background.\n",
      "\n",
      "Culture can feel non diverse and elitist at points (particularly at conferences vs other meetups like socials)\n",
      "\n",
      "I sometimes miss the personal side in the EA community (My local group is cool but on international events I feel quite lost). Furthermore sometimes EA feels a bit elitist and competitive (again this applies more to the international than the local level). \n",
      "\n",
      "If I were to introduce a friend I would be careful where I directed them - their experience could be very hit or miss. Some chance they would encounter someone who was condescending or had poor understanding of how their speech/actions affects others. \n",
      "\n",
      "The local community is okay but the community at large is full of elitism and is not great. \n",
      "\n",
      "I can experience some frustration with EA community, especially with the younger people getting involved. They can be quite dogmatic, lacking nuance in their thinking, they are also arrogant, and use EA as a signalling contest, to compete to be \"the most effective\". I have a feeling sometime that the \"altruism\" side is left on the side. I also feel that there is a lot of focus on research and researchers, while I do think it is needed, I also beleive that other type of work are very useful, especially for implementation. I have a management background and work as a consultant, and we are very few like this, and there is almost 0 jobs around this type of skills with 80000h. I think that EA could be quite elitist and only value very specific type of people (aka researcher in AI). This make the organization more and more homogenous, and makes me want to leave sometimes. \n",
      "\n",
      "I have encountered two common problematic first impressions of EA for those who previously did not know of it during member-recruitment and club events:    - That the meaning of EA is confusing and its purpose poorly communicated  - That EA is elitist in its definition of \"effective\" and how it communicates its core values \"downwards\"    I think that a more strengths-based and social approach to new members and how EA events are run would at least alleviate elements of both these problems.\n",
      "\n",
      "I've found some of the EA Facebook group comments to be unnecessarily hostile. I also think that EAs could do a better job reaching out to religious communities. I can't remember the source, but I remember seeing a survey suggesting that many EAs are non-religious (admittedly, like me). However, I think that EA principles can be applied well in religious contexts, especially for those concerned with global poverty/public health.\n",
      "\n",
      "After reading about the principles of EA, I enthusiastically discussed with some of my friends. Some of my friends had already heard of EA and were already very turned off by it. They told me how the people in the community come off as \"elitist\". I now see how saying something like \"being a doctor is not a good way to save lives, you could do better being a software engineer and buying malaria nets\" can seem condescending. It loosely translates to \"you think you're doing good, but I'm doing MORE good than you.\" \n",
      "\n",
      "Arbitrary place to vent: I feel like my local group (shout out to EA Ottawa; I hope this is not public) is not very welcoming. I feel like it's pretty condescending to non-utilitarians or people who don't get the material, and that makes me demotivated about our local group.\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER hard: '*intimidat*', '*hard*', '*difficult*', '*overwhelm*', '*tiring*', '*obscure*'\n",
      "###\n",
      "\n",
      "Early on, I encountered some EAs who seemed like hardliners and that turned me off - they were really adamant about not taking action on climate change, which I was passionate about at the time. (I currently believe that society should devote more resources to mitigating and adapting to climate change, but not necessarily EA.)\n",
      "\n",
      "I was kicked out of an EA memes group on Facebook for angrily telling someone he shouldn't post a meme with the word \"n*gger\" on it (except he posted the full word as part of the meme). I didn't curse, but I was quite sarcastic in my replies to his self-defenses. In the end, I was kicked out of the group and he wasn't. This really makes me think that EA is overwhelmingly white and not inclusive enough. I also got some bad feelings about EA when I saw so many anti-feminist posts on the \"Dark EA\" facebook group. I've met some wonderful EA people, but this stuff concerns me. \n",
      "\n",
      "The lack of clarity about what EA jobs were available, and the credentials required for them, hit me hard last year. I have not been motivated to apply to any jobs other than EA ones and had trouble entering a mindset of satisficing with respect to job choice, since I was so focused on finding a \"calling\" or the \"best\" choice. I thought EA direct work jobs were the answer because I had heard about people who were just out of college getting them in the few years before I applied, and because I thought they were plausibly the best way to do good with my career. But between the time those people were hired and the time I was looking, standards increased. I particularly regret that the advice floating around last year was \"do ops,\" so I decided to do that instead of grad school, and now the advice is \"do grad school.\"\n",
      "\n",
      "I would love to be able to find work in EA related fields but have found it difficult to find entry-level roles.\n",
      "\n",
      "Positive: it has changed how I view INGOs and their work, become more critical.  Negative/positive: it sometimes feel as if the movement and its members can come of as a bit single-minded: hard to talk about \"new ideas\" that does not fit into established EA views. However, this seems to have changed a bit, like GiveWell investigating opportunities to influence gov. spending and policy.\n",
      "\n",
      "Ea has a problem of diversity, which makes it difficult to be\"socially satisfying\" for many people\n",
      "\n",
      "Would like to see a stronger focus on diversity and inclusion, especially as it relates to class differences and physical/cognitive ability.    Also would love to see the online materials be made more accessible for someone who's never heard of ea before. It can be really intimidating to get into this movement if you don't have a local group to smooth the transition and most people don't have access to that.\n",
      "\n",
      "It can be tiring to onboard people. Currently I tend to preserve energy and only onborad people who wouldn't require much effort. \n",
      "\n",
      "A significant barrier to me becoming more involved in EA is that I struggle to motivate myself to do the work necessary to get myself on a high-impact career trajectory. I've been involved in EA for five years, yet have only applied to one EA job (despite thinking I ought to apply for more), and currently still have little idea what type of job I want or what career path I want to pursue. Doing the work of creating career plans and taking action based on them is something that is hard for me and that I keep putting off.    80,000 Hours provides a lot of career advice that can be helpful to creating career plans, but it is by no means inevitable that a person who strongly agrees with core EA principles with a desire to have a high impact career will thereby transition to a high-impact career in a reasonable amount of time upon discovering 80,000 Hours. It takes a certain amount of motivation and self-direction as well. Any additional support or mentorship that any EAs can provide me to help me create EA career plans and apply to EA jobs would thus be very helpful.\n",
      "\n",
      "I think, there needs to be a list of activities that (new) members can do, that eases them into being active EAs. Currently, it feels like many of the possible actions require taking on big projects or making big life decisions. As a student, that can feel overwhelming (and a lot of new EAs are students, right?).    I have been talking to a few of my fellow EAs in Effective Altruism Aarhus about possibly creating a database with small tasks, that one can do in a few hours or days (does this exist already?). Then researchers and organisations could add the tasks with a small motivation.  I might not be able to take on a big project, but I can definitely spend a weekend improving a researcher's code, preprocessing data, etc. This would require, that the main projects that the task contributes to, has been decided on based on EA principles of course, so the members do not have to spend hours analysing and prioritizing the tasks.  A space for thinking big, and a space for actually doing things.    An example is climate change. We all (should) know, that it is a huge problem, but few people actually have any idea about how to act on that knowledge without making big structural changes to one's life (in terms of career). By having a set of small tasks, that one can complete, we get less \"frozen\" or anxious. Obviously, EA is about having an actual impact, and sometimes people do need to make big structural changes to their lives, but perhaps having a transitional path will make it more clear, where one's skills can actually be used to solve these kinds of problems?\n",
      "\n",
      "It depends on their background and their way of seeing the world, and which community. The online EA community is very hardcore: I wouldn't introduce many people to that. The local EA community is friendlier, but has diversity gaps (in gender, race, and \"are you highly quantitative/technical in your studies or profession, or a philosopher\"), so I would be cautious about who I introduced to it.\n",
      "\n",
      "It is great for the highly educated and resource-rich... but is hard to be embraced by 1) non-educated who are not going to have capacity/time to absorb complex messages/philosophy, and 2) people who feel they are too exhausted/stressed/indebted to give an amount that feels substantial and/or would need to force a reduced lifestyle on their families to give more.  \n",
      "\n",
      "Sometimes I have the impression that it's hard to join a group (because it is not as open as it should)\n",
      "\n",
      "I love, love, love my NYC EA group and the wonderful people I've met there.    However, \"Big EA\" has always seemed intimidating and off-putting. I was very briefly involved in an EA group in another city around 2010, and it was so unpleasant that I didn't even try to go to another until 2016, when I moved to NYC.    \"Big EA\" always feels like it's a contest who can be the biggest wonk with the mathiest brain. I get it, I get it: making tons of money and/or being extremely clever (in an EA way) are necessary for making the world a better place.    I'm not clever, and certainly not in the ways that \"Big EA\" loves and rewards. The things I'm really good at - being a social worker, being diligent and reliable and unflappable and kind - don't generate much income and don't make EAs excited.    But here I am: diligently and reliably doing the work that I was put on earth to do, making my paltry monthly donations to highly effective causes for the past ten years, and being kind and encouraging to my EA community. So, do I get to call myself an effective altruist?    For my local group, I know the answer is yes. But I always strongly suspect that \"Big EA\" (eg. EA Global, the web forums, groups in other cities, etc.) would not welcome me, and that I would be extremely uncomfortable there.\n",
      "\n",
      "It is at times difficult to describe the concept of EA to people.\n",
      "\n",
      "I feel people who call themselves EAs are often overconfident in their ability to calculate all eventualities and what should be done. I think people in general continually overestimate their abilities to predict the future and all influencing factors (there is research supporting this claim as well). Still, EAs in particular don't much take this uncertainty factor into account. Most everytime I talk to someone about this, they are unfazed or don't agree with me. I'm not saying you shouldn't try to calculate things. I'm saying you should include the uncertainty in your forecasts or recommendations.   Second, EAs through this overt trust in their own mental capacity often come across, in my opinion, as cold or calculating. That's why I have many EAs as loose companions, because of the interesting discussions and knowledgeable-ness, but few close friends, because I find it hard to \"connect\", as I am apparently just different than them. Also, lots of EAs didn't like me/find me interesting (I believe).\n",
      "\n",
      "Still find EA forum very intimidating. \n",
      "\n",
      "The EA community online currently has issues where a lot of spaces are IMO overmoderated, making it difficult to introduce a newcomer to what feels like a \"natural\" conversation and social hub (and ultimately driving people towards weird areas like Dank EA Memes). I'm not sure where I would suggest a newcomer go in order to hang out and converse with other EAs -- the EA Corner Discord server might be the best option but it itself has major issues with drama and only really accommodating certain conversation styles.\n",
      "\n",
      "It's always remarkably hard to convey the principles of EA to someone. They bring their own emotional baggage and opinions, and my explanation is likely distorted by my own .\n",
      "\n",
      "It's a great community for me and others like me, but seems hard to get into if you are not too interested in ideas and nerdy stuff\n",
      "\n",
      "I'm somewhat nervous to bring up/introduce EA because it's hard to talk about it without seeming like you're insulting people and you risk personally offending people who are very attached to certain causes.\n",
      "\n",
      "it can be difficult to talk about with others as seems cultish. need more business people as they have a lot of influence, and more outreach to people with experience.\n",
      "\n",
      "The EA community is socially stifling. I often find spending time with groups of EAs to be quite tiring. There are many reasons for this:  - Higher than normal fraction of people with limited social skills  - Many people overestimate their social skills  - (Attempted) intellectual showing off  - Intellectual pissing contests  - Many people reject \"normie\" social norms simply because they're normal (for example, the disdain that many people have for small talk or for being gentle about disagreeing)  - Distaste for mainstream culture (sports, for example)  - An insistence that every conversation should be about things that seem EA-related\n",
      "\n",
      "Elitism makes it hard for lots of people to fully integrate\n",
      "\n",
      "Neg:  - the movement is extremely biased towards english speaking countries . I do not see much effort - especially from the english speaking part of the movement - to change this.  - the movement is pretty undemocratic: even as someone who spends a lot of time thinking and working for EA related things I am not able to participate in a sort of election process for the leaders (such as CEA or 80k). And I see no efforts to change this.  - there seems to be a lack of exploring new ideas / ways of doing stuff: the explore / exploit tradeoff says 37%! I feel that we barely have touched 2%.  - EAs seem to neglect the donation part. Many EAs 'invest' in their careers and skip the donation part. I think these are not mutual exclusive and it should be almost obligatory to donate as an aspiring EA.  - EA is relying on signaling a lot: I have spent quite some time with people from the big universities such as Stanford, Harvard or Oxford. They do not differ much from good students at other places.  - EA is degrading the work of many people: The idea of high-impact careers could be communicated in a way so that people that are in their 30-50's don't feel bad for only being a doctor, teacher, nurse or whatever. I think the movement is thereby rejecting a lot of potentially highly valuable people.  - EA events sometimes are extremely competitive and can lack the fun that is necessary to glue together a community  - CEA's community building department with 3(!) people is ridiculous.They need more manpower!  - The EA movement is heavily dependent on Facebook, Google and Slack. Many times it is simply impossible to attend events without having a Facebook Account, CEA forces you to have an Google Account to apply for funding. The reasons for rejecting these services are numerous and there are good open alternatives.  - Additionally: Most of the time it is really really hard to get contact to local EAs because: there is no website for them, a closed facebook group, people do not answer your mails / Facebook requests.    pos:  -  All in all it is an extremely impressive movement with some of the brightest minds. I'm proud being a part of it.  \n",
      "\n",
      "Although I'm still very much interested in the community, I've become more concerned about the current norm for doing prioritization within EA. Specifically, I think that by maximizing impact with respect to our values we end up with \"free-rider\" problems where we each focus on cause areas that only we think are important.    Also, the more weird that EA priorities get (mainly I have in mind the shift towards influencing the far future) the more difficult it is to pitch it to friends.\n",
      "\n",
      "It seems really hard to do something significantly impactful.\n",
      "\n",
      "With the large shift towards far-future cause areas, it’s becoming much harder to welcome new people into EA. These topics are important, but less accessible to someone that is not from an engineering or science background.    I’m not suggesting that we divert attention away from these causes, but more effort needs to invested into building a pipeline/onboarding for new people to discover and engage with EA.\n",
      "\n",
      "Concern that it comes across as elitist, which can be intimidating.\n",
      "\n",
      "It would be nice to have a clear and frequently updated list of what most EAs believe to be the most important cause areas. I have seen different lists around, and it can be difficult to communicate about EA to others when there is not a centralized, updated, defensible resource to use as a tool.\n",
      "\n",
      "The information is fairly overwhelming at first in terms of both volume & complexity so more effective summaries would be beneficial. This would also be useful for explaining the material to interested friends/colleagues/acquaintances\n",
      "\n",
      "It is really hard to be involved in the community itself as someone who is an 'average person'. The EA community itself seems to award high status to Ivy Leaguers who are very accomplished. I did not even consider aligning my career towards it, because it feels like careers for EAs would not even want me. If it were not for Jeff Kauffman's, Julia Wise's, and Kelsey Piper's online presence, I would have a lot of difficulty feeling like this was a movement for me.\n",
      "\n",
      "Besides being fairly obscure and hard to understand without some background in philosophy, I have found all of the contacts I've met in EA to be polite, open, and focused on the problems at hand. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I have grown somewhat disillusioned with the EA community and philosophy.  In the community, I perceive intellectual arrogance and some cultish behaviour (although I admit this is not necessarily a \"rational\" perception, but more of an uncomfortable feeling).   In the philosophy or theoretical basis of EA, I feel that   a) the parts that feel most evident and easy to be somewhat certain of are not original (e.g. the morality of maximising utility) and  b) the parts that are original (i.e. the pointing out of particular causes, like XR) are most questionable from an epistemic point of view, hence harder to trust.   \n",
      "\n",
      "EA discussions are often somewhat intimidating because of the particularly high standards of specificity and accountability demanded, or at least endorsed/expected by adherents to EA principles. It can create a barrier to entry when it comes to engaging in the conversations.\n",
      "\n",
      "80,000 hours has been helpful in thinking clearly about my career path, but it also made me feel overwhelmed. \n",
      "\n",
      "I fundamentally care about helping the extreme poor, about working against climate change, and more generally leveraging my privileged position to make the world better, not worse. Effective Altruism has useful resources for me to find out how to do this. Not to be rude, but I don't really identify with the EA community. Especially on the forums there are some strange discussions such as plant welfare and the more obscure sounding apocalyptic scenarios that to me just sound outlandish.    Nonetheless there's some fantastic discussions and research here, and it's very encouraging to find like-minded people. For me EA is more of a resource. I suspect there are many people on the fringes with a similar perspective.\n",
      "\n",
      "It can be difficult to understand what the up to the minute recommendations are donating to specific charities or taking certain career paths. I don’t have the time to do the research and I appreciate the info on GiveWell and other sites but there’s often a disclaimer that the data is a year or two out of date but without much follow up on where to go. \n",
      "\n",
      "Sad it isn’t bigger so that there was a closer local group, harder to get to meet ups far away. Would prefer if the talks were more practical focused. \n",
      "\n",
      "EA is a great principle, but it can be hard to introduce others to the concept as it can seem both somewhat rigid, and somewhat cultish.  I personally also find the 'approved' EA charities very narrow in scope (even if this is understandable).\n",
      "\n",
      "It's very difficult to engage people in tasks beyond the mere agreement that EA, as a movement, is right. We need more people engaging full-time in EA in my country, but it's hard to people to mantain their incentives to this task.\n",
      "\n",
      "It's hard to introduce people to EA when so many of the associated concepts (e.g., X-risk) seem so weird at first glance. \n",
      "\n",
      "I think it could be more inclusive of other academia such as the humanities, besides philosophy and politics. Even though it is enlightening and I am very happy to be learning information outside of what I am studying, a lot of the talks at my local group can sometimes be hard to understand when you are not surrounded by the discourse that is being discussed. Additionally, I believe the introduction of different academic areas would be more insightful for the community and bring a new perspective, specifically history.\n",
      "\n",
      "Too few women and diversity and too much maths/\"hard sciences\"  (says the mathematician...)\n",
      "\n",
      "Can be intimidating.\n",
      "\n",
      "EA lacks standardisation or a guide book which is agreed upon and updated regularly to provide a foundational understanding of EA’s principles. For this reason, I find it hard to explain what EA is uniquely.\n",
      "\n",
      "Find it an environment that challengs me to be ambitous, though sometimes leads to feelings of intimidation. This is, however, the main reason I involve myself - to maintain high ambitions in the 'right' cause areas. Though consequently, rejection from EA Orgs / ambitious career paths does lead to feelings of inadequacy that I might not have experienced, outside of the community. For now, I'm comfortable enough with this tradeoff.\n",
      "\n",
      "As a digital nomad it's hard to get involved in the community in person, and hang out with value-aligned people.\n",
      "\n",
      "Sometimes the ideas come across as a little bit \"crazy\" to normal people (e.g., wild animal suffering) which can make it hard to connect people with the community\n",
      "\n",
      "I resonated a lot with an EA forum post about feeling terribly behind the ball compared to more experienced EAs, about how hard it is to qualify for EA-group jobs, and about feeling depressed by knowing how ineffective one is likely to be over the course of one's life. Still trying to sort out how I feel about the difficulty of contributing to the EA project.\n",
      "\n",
      "Finding and creating opportunities for meaningful involvement was difficult. It was also disheartening not to find any fitting job offers within EA organizations.\n",
      "\n",
      "It's one of the best communities I've found for meeting nice and interesting people, the social benefits are a large part of why I spend time with EAs.  I eat meat and don't think animals have moral value, so I feel alienated by the norm of vegan food.  I think it's quite susceptible to group think, eg on controversial and difficult topics like AI Safety\n",
      "\n",
      "Most of my interaction with EA has been positive.    I found EA Global London to be a bit overwhelming. I hadn't been interacting with EA for a while before I attended, so I felt very \"out of the loop\", and under-qualified. I did meet a lot of great people there, but overall I didn't enjoy the conference much. I still hope to go again one day.\n",
      "\n",
      "I find the recent focus on doing a lot with a small group rather than persuading a wider audience to give to higher impact charities very off putting. There is an arrogance about it and I worry it could go very wrong. My experience with the ea community in Montreal was very uncomfortable. I generally find the focus on ai safety comcerningly self serving - working in ML is a very nice career option. The Facebook forum is deeply intimidating.   \n",
      "\n",
      "Being a young woman without an advanced degree, I haven't always felt like I fit the \"EA stereotype\". It has been difficult for me to make personal connections within the EA community and I would have similar concerns about introducing any of my friends to the community. \n",
      "\n",
      "The EA community in Connecticut is organized mostly around students, so it’s harder for others like myself to fit in\n",
      "\n",
      "I have many positive thoughts, and many negative experiences. My single-biggest issue with the EA community is arrogance and dogmatic thinking. I have had a difficult time getting individuals past certain 'mantras', for lack of a better word, because they feel that EA is all-or-nothing. This keeps many microdonations from reaching EA supply chains, and I believe is cumulatively worse than having people get involved in small sums at the start, with an increase as their understanding and conviction rises.\n",
      "\n",
      "It is really difficult to align your life with EA principles if you have already finished your studies before getting in contact with EA.\n",
      "\n",
      "The job advice on 80000 hours is mostly for people in the UK or US. The \"best or nothing\" approach gives standards, which are very hard to meet and make choosing a career (especially with additional constraints like location) almost impossible.\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER job: '*job*', '*career*', '*80*'\n",
      "###\n",
      "\n",
      "The lack of clarity about what EA jobs were available, and the credentials required for them, hit me hard last year. I have not been motivated to apply to any jobs other than EA ones and had trouble entering a mindset of satisficing with respect to job choice, since I was so focused on finding a \"calling\" or the \"best\" choice. I thought EA direct work jobs were the answer because I had heard about people who were just out of college getting them in the few years before I applied, and because I thought they were plausibly the best way to do good with my career. But between the time those people were hired and the time I was looking, standards increased. I particularly regret that the advice floating around last year was \"do ops,\" so I decided to do that instead of grad school, and now the advice is \"do grad school.\"\n",
      "\n",
      "EA can seem inaccessible and I sometimes wonder if the advice is appropriate for me. I feel like there should be more advice for those who maybe aren't going to be/ or are unable to be at the cutting edge of EA work, but would still like to be involved where their skills can be used. As in, not everyone can be an AI researcher, and so more advice for less ambitious or intellectual jobs would be good.\n",
      "\n",
      "I'd like to see less infighting among EAs. As the anonymous author of a recent 80k blog post notes, \"There’s an enormous amount of wasted time on infighting between groups working on the same cause.\"\n",
      "\n",
      "EA suffers from a terrible lack of diversity and inclusion. As a non-White member of the community from a lower income background, I often felt very alienated, lonely, and unwelcome at international EA gatherings such as at EA Globals in 2017 and 2018. I also feel that many EAs including 80 000 Hours career coaches lack empathy for and understanding of people with my kinds of backgrounds and lived experiences such as having faced significant financial stress, relied on some form of charity food aid, lived with systemic and persistent racial discrimination including in the job market, and also being active in a religious community. I have also been very unwell these last few years, and felt very uncared for during EA Globals, and was at high risk of having a serious health incident, and no one noticed or even reached out in kindness even as I wandered around the conference venue alone and in distress. This could be because they don't understand that distress is expressed differently in different cultures and they lack the intercultural understanding to read different signals of distress. More diversity and inclusion in EA could have made me feel more welcome and supported. \n",
      "\n",
      "Need to build better bridges between academia and industry, to pull professionals into high impact jobs (also the ones who might not be computer scientists or policy analysts)\n",
      "\n",
      "The lack of racial and gender diversity in the movement is a persistent and serious problem for the movement and I see it as direct reason why I (and others) would become less involved (this coming from someone who has dedicated most of my college years to running and EA group and who is dedicating their career to a top EA cause).    Some more thoughts about this lack of diversity.    CAUSES OF THE ISSUE:  To some extent this is \"founder effects\" and a biproduct of the fact that the movement has grown out of cities like Oxford. However, I other factors contribute; such as the inaccessible jargon and narrow definitions of \"rationality\" and \"intelligence\" that have been imported from the rationalist community. The way in which some people in our movement seem to actively derive glee from labeling cause areas and organizations as \"ineffective\" or people as \"irrational\" or \"too emotional\" is an active impediment to having a more inclusive movement.    CONSEQUENCES:  - Heightened risk of making moral errors or prioritizing the wrong issues due to homogeneity among the people in charge of charting the path of our movement.  - Smaller talent pool, loss of engagement from otherwise dedicated members (I've felt this happening myself).  \n",
      "\n",
      "Apart from the general ideas (earn to give, know where to give), the community hasn't given me much. Which is ok! All I need is someone to point me to effective charities, give overall career advice, and that's it. I spent perhaps 1h reading up on these subjects. I don't feel like all those conferences, events etc give me much more than what I now already know. Also, I feel like many discussions in forums etc become overly theoretical, especially the x-risk stuff. I think that \"here and now\" appeals to more people.\n",
      "\n",
      "I am very thankful to Huw Thomas. When I didn't receive 80,000 Hours career coaching I was directed to him instead. Huw had a large influence on improving my career choices and improved how I run EA at Brown.\n",
      "\n",
      "A significant barrier to me becoming more involved in EA is that I struggle to motivate myself to do the work necessary to get myself on a high-impact career trajectory. I've been involved in EA for five years, yet have only applied to one EA job (despite thinking I ought to apply for more), and currently still have little idea what type of job I want or what career path I want to pursue. Doing the work of creating career plans and taking action based on them is something that is hard for me and that I keep putting off.    80,000 Hours provides a lot of career advice that can be helpful to creating career plans, but it is by no means inevitable that a person who strongly agrees with core EA principles with a desire to have a high impact career will thereby transition to a high-impact career in a reasonable amount of time upon discovering 80,000 Hours. It takes a certain amount of motivation and self-direction as well. Any additional support or mentorship that any EAs can provide me to help me create EA career plans and apply to EA jobs would thus be very helpful.\n",
      "\n",
      "I'd love to introduce them to Seattle, to the community at whole though, not at all. ESPECIALLY, as I may say one more time..not to 80,000 who I have strong evidence is an actively oppressive forth. \n",
      "\n",
      "The career focus also doesn't work for me--I do sometimes apply for higher paying jobs thinking I could give more, but I don't want to pivot my life consciously for that end, and considering it from a career perspective I am resistant to the idea that I should be changing to something more lucrative (again, these assumptions often feel very male)\n",
      "\n",
      "I think, there needs to be a list of activities that (new) members can do, that eases them into being active EAs. Currently, it feels like many of the possible actions require taking on big projects or making big life decisions. As a student, that can feel overwhelming (and a lot of new EAs are students, right?).    I have been talking to a few of my fellow EAs in Effective Altruism Aarhus about possibly creating a database with small tasks, that one can do in a few hours or days (does this exist already?). Then researchers and organisations could add the tasks with a small motivation.  I might not be able to take on a big project, but I can definitely spend a weekend improving a researcher's code, preprocessing data, etc. This would require, that the main projects that the task contributes to, has been decided on based on EA principles of course, so the members do not have to spend hours analysing and prioritizing the tasks.  A space for thinking big, and a space for actually doing things.    An example is climate change. We all (should) know, that it is a huge problem, but few people actually have any idea about how to act on that knowledge without making big structural changes to one's life (in terms of career). By having a set of small tasks, that one can complete, we get less \"frozen\" or anxious. Obviously, EA is about having an actual impact, and sometimes people do need to make big structural changes to their lives, but perhaps having a transitional path will make it more clear, where one's skills can actually be used to solve these kinds of problems?\n",
      "\n",
      "I love the community aspect of the NYC EA meetup. The people in that group have given substantial emotional support and guidance to me during a career change. With the help of the EA community, I made two important decisions in 2019. First, I decided to commit to climate change as a cause area (I was considering other cause areas). Second, I decided to leave my job in Mechanical Engineering to learn web development at App Academy. My short term goal is to earn to give to climate charities, and my long term goal is to do direct work on greenhouse gas emissions reduction.\n",
      "\n",
      "When I first entered the community I was quite disappointed. I started by listening to the 80,000 hours podcast. This got me very interested and motivated. When I first went to a couple meetups (Rotterdam and then Amsterdam) however it was rather disappointing. I had imagined I would meet people who were excited to get going - to start actually doing things. It took me a while to realise that if your whole career / education is geared towards achieving EA goals then usually the best that can come of the meetups is simply conversations to network / clarify goals / learn from others. With this perspective, I'm now very happy to continue my studies in Machine Learning, while enjoying valuable conversations with EAs that help clarify and sustain my values, goals and career plans.\n",
      "\n",
      "Positive: a commitment to be evidence based  Negative: seems to fall too often for authority argument, too much inequality in the distribution of status and influence within EA, not enough inclusive to minorities and some member despise other for 'uneffective' career choice. \n",
      "\n",
      "Has done a great job so far on this, but needs to continue to avoid coming across as dogmatic. I worry that some student EA groups can be echo chambers as well.\n",
      "\n",
      "Almost everyone in the community seems to be very young (in their 30s at most), so I'm not so sure they're the best judges of what makes a fulfilling career, since they're only starting their own. (Below, by \"not diverse enough\" I primarily mean this kind of diversity, not, for instance, gender and race diversity.) The ethical and philosophical discussions were also fairly basic, which is understandable given the age of the people involved. For these reasons, I'm not convinced this group should be so eager to influence the lives of trillions of people in the far future (apart from simply helping make sure that future exists). The people seem to be very intellectually curious, however, and discussing various issues with them has been fun. \n",
      "\n",
      "I have a lot of anxiety about EA topics but even with 80k, it is still not clear what is best to do with my career and that's horrifying. I wish there were more resources for those who are not the top people that EA is often looking for.\n",
      "\n",
      "Julia Wise is a god damned hero. I stan a queen!   heard about 80k giving career advice that is bad for the individual. For example, telling them to study to be qualified for a position with not enough available roles. \n",
      "\n",
      "The overall messaging online seems to have moved away from an inclusive \"most people can make a big difference\" to a message about super high value career paths, and that is one way people will feel less valued in the community. I have also seen a large disparity in the distribution of support (monetary and otherwise) to groups and individuals around the world, and that is very offputting, and also signals that the community doesn't value us. \n",
      "\n",
      "Community leaders seem to be doing a good job balancing openness to new ideas while maintaining EA as an intelligible concept. Maybe a little too much favoritism shown towards AI and far future generally, but that's an inside view criticism.  \n",
      "\n",
      "EA feels at first like the greatest thing, but once you start to donate monthly, you quickly run out of things to do, unless you want to expend significant resources and turn EA into your full-time job. It's a bit frustrating. \n",
      "\n",
      "reference to 'the movement', 'the community' etc makes it feel a little cult-like. Surely it is just a way of thinking...?  Also, the focus on 'EA jobs'. This is a very limited field and those working or aspiring to work in this field should not be seen as 'more than'. Those people still need the rest of society to grow their food, build their houses, drive their trains etc\n",
      "\n",
      "I'm annoyed that orgs don't post their past acceptance rates for jobs.  I'm annoyed that the EA Hotel doesn't seem to be taken seriously by the meta funds.\n",
      "\n",
      "I get a slight elitist perception. The organizations I look at for work tend to hire folks with degrees from prestigious institutions. I would love to see passion, and ability to learn prioritized for those of us excited to contribute with a more alternative career path to this point or academic background. \n",
      "\n",
      "Neg:  - the movement is extremely biased towards english speaking countries . I do not see much effort - especially from the english speaking part of the movement - to change this.  - the movement is pretty undemocratic: even as someone who spends a lot of time thinking and working for EA related things I am not able to participate in a sort of election process for the leaders (such as CEA or 80k). And I see no efforts to change this.  - there seems to be a lack of exploring new ideas / ways of doing stuff: the explore / exploit tradeoff says 37%! I feel that we barely have touched 2%.  - EAs seem to neglect the donation part. Many EAs 'invest' in their careers and skip the donation part. I think these are not mutual exclusive and it should be almost obligatory to donate as an aspiring EA.  - EA is relying on signaling a lot: I have spent quite some time with people from the big universities such as Stanford, Harvard or Oxford. They do not differ much from good students at other places.  - EA is degrading the work of many people: The idea of high-impact careers could be communicated in a way so that people that are in their 30-50's don't feel bad for only being a doctor, teacher, nurse or whatever. I think the movement is thereby rejecting a lot of potentially highly valuable people.  - EA events sometimes are extremely competitive and can lack the fun that is necessary to glue together a community  - CEA's community building department with 3(!) people is ridiculous.They need more manpower!  - The EA movement is heavily dependent on Facebook, Google and Slack. Many times it is simply impossible to attend events without having a Facebook Account, CEA forces you to have an Google Account to apply for funding. The reasons for rejecting these services are numerous and there are good open alternatives.  - Additionally: Most of the time it is really really hard to get contact to local EAs because: there is no website for them, a closed facebook group, people do not answer your mails / Facebook requests.    pos:  -  All in all it is an extremely impressive movement with some of the brightest minds. I'm proud being a part of it.  \n",
      "\n",
      "I've been invited to apply for things at CEA, FHI, CHAI, Founders Pledge, etc. But in retrospect I don't think I had a real chance at any of them, and I wonder how many thousands of hours of optimal work we're burning on applications.    It surprises me that 80k doesn't follow the AI safety people it creates more closely, to manage saturation of the junior end of the pipeline.\n",
      "\n",
      "It seems like the EA community is very academic. We can do a better job presenting our worldview to others and bringing new allies into the fold.\n",
      "\n",
      "I love the blog Giving Gladly and the supportive and informative emails I get from Givewell. I don't think I would ever feel comfortable attending an EA event because I'm not \"pure-EA\" enough. I am not planning on changing to a higher earning career, though of course I will do what I can to earn the most I can within my field (massage therapy/energy healing). I feel that my spiritual beliefs would not be accepted in the EA community or would simply make people feel uncomfortable. But I wish that that weren't the case so I could make EA friends without feeling like my own decisions will be frowned upon. \n",
      "\n",
      "• Frequently come across a strong sense of entitlement, or outright arrogance in personal interactions with less-engaged EAs. A common feeling among these people is that they feel uniquely gifted or especially well-prepared to solve problem X despite having virtually no experience — even expressing disbelief when they don't get a grant or a job offer.  • Having lived with several cohorts of EAs for nearly a year, I'm less confident about the general competence of new people I meet — I'm astonished that some of these guys think they'll change the world when they can't even change for clean clothes.\n",
      "\n",
      "A harsh take is that it comes across as a movement for rich educated people. You pretty much have to be rich enough to donate, or otherwise successful enough in the professional sphere to make EA-related career choices, which doesn't leave much room for more marginalized folks to get involved. \n",
      "\n",
      "I’ve noticed some in EA dismissing climate change as a non-major issue, as they think it can just be fixed with geoengineering. But surveys have shown this isn’t what most climate scientists think.     Otherwise all positive experiences. And great information especially by 80000 hours and Give Well\n",
      "\n",
      "It is really hard to be involved in the community itself as someone who is an 'average person'. The EA community itself seems to award high status to Ivy Leaguers who are very accomplished. I did not even consider aligning my career towards it, because it feels like careers for EAs would not even want me. If it were not for Jeff Kauffman's, Julia Wise's, and Kelsey Piper's online presence, I would have a lot of difficulty feeling like this was a movement for me.\n",
      "\n",
      "EA could benefit from being less insular.     The ideas of economists like Tyler Cowen, Robin Hanson, Glen Weyl, etc. are very relevant. There's a great deal of skepticism regarding AI risk from the broader AI research community that isn't taken seriously enough.    Generally I think the standard of diversity of ideas set by the 80,000 hours podcast is great and should be a benchmark for the community more broadly.\n",
      "\n",
      "I've had a very positive experience with the EA community. Considering how multifarious the movement is and how quickly it is changing, I think people have done a great job being inclusive and welcoming to newcomers.\n",
      "\n",
      "+1 on EA is incredibly academically competitive, and that's highly discouraging. On paper, I'm roughly Ivy League level qualified for most academic/career positions, yet most of the opportunities I hear about in EA I couldn't get into, and most of the people who I see doing incredibly impactful work I am not as effective as. Reading lots of EA content regularly gives me status anxiety about not being successful or well-qualified enough to do the high-impact things I want to do. \n",
      "\n",
      "More focus and funding need to be provided to help people successfully pursue effective career.\n",
      "\n",
      "80,000 hours is a great book!\n",
      "\n",
      "80,000 hours has been helpful in thinking clearly about my career path, but it also made me feel overwhelmed. \n",
      "\n",
      "I get that EA (at least from my view and how it's explained to me) is about rationality and a more consequentialist way of thinking. But this modality of spreading the message is, pardon my french, dogshit (IMO).    Everyone I've interacted w/ at EA is so emotionless and too logical; too academic too and not pragmatic enough.    So many look at problems just in terms of numbers instead of seeing what is in front of their own eyes.    Overall, though I can relate to these people as I've worked in tech/STEM for so long, 99% of the general public, IMO, will think they're robots.    It's no way to market what is a very important movement to push.    People in the EA movement, from my view, need to improve their people skills and think more pragmatically.    Otherwise you will have the typical business-douchebags who can talk-the-talk and spin things effectively walk all over the EA side of the fence.    Also, re 80k, maybe I'm misinterpreting their mission, but again, it seems like they think people are robots. You can't expect people en masse to work shitty jobs they don't find maximally fulfilling and donate a decent chunk of their salary to people on the other side of the world.    It's instances like this where a clear lack of human understanding plagues EAs — from my view, anyway.    It just seems to me everything is so oriented towards analytical-thinking that the actual foundational empathy required to do-good is lost.    All just my opinion that I imagine most will disagree with.    Just my observation as somebody who does has dealt with the software-engineer types my whole career. I see similar patterns.\n",
      "\n",
      "It can be difficult to understand what the up to the minute recommendations are donating to specific charities or taking certain career paths. I don’t have the time to do the research and I appreciate the info on GiveWell and other sites but there’s often a disclaimer that the data is a year or two out of date but without much follow up on where to go. \n",
      "\n",
      "I get that this is the EA survey, but it's weird seeing so little references to the rationalist(/ea) community i.e. I basically conflate the two in practice. But yeah, I love the ea/rationality community! I'm super grateful for the two jobs I got through the community, too. I'm mostly (VERY) jaded about grad school and about having discouraging experiences with people who are famous within the community (being brushed off by several people, and being told my research was *harmful* by one person I respected at the time).\n",
      "\n",
      "I think there's a gap in EA in providing advice to average-to-medium-talent individuals on how to be effectively altruistic (I'm particularly thinking of career advice). It makes sense to allocate most/all resources to advising high-talent individuals who will have a much larger impact than everyone else. However, this has the effect of leaving a large population of not-high-talent individuals (who should really just be focusing on getting into a decent career and donating 10% of their income to highly effective charities) with unrealisable ambitions to change the course of humanity. This leads to a) a lot of people who identify as EAs appearing delusional, b) wasted effort being put into learning arcane facts about AI/global poverty/pandemics/etc which would be better be put into learning concrete middle-class career skills, c) frustration at career aspirations not being met. In fact, I wouldn't be surprised if a small amount of exposure to EA (enough to learn how to allocate donations to effective charities) leads not-high-talent individuals to be more effective on average, but a large amount of exposure to EA (enough to affect career decisions) actually leads to *less* total effectiveness on average.    I suspect the status quo of focusing on how high-talent individuals can be effective is in fact the most effective strategy. However, I also think that those in the inner circles of EA surrounded by lots of talent and resources are probably not aware of what I'm describing. And so this may be a problem.\n",
      "\n",
      "EA still seems very idealistic and focused on those who, by virtue of privilege and lack of established obligations, can remain steadfastly idealistic. There seems less direction for those who are either well-established in their career paths or have opportunities closed to them due to personal circumstances.\n",
      "\n",
      "I would be excited to introduce them to professionally managed EA organizations like 80,000 Hours or Givewell.  I would not be so excited to introduce them to the local EA Meetup group, which is not well run.\n",
      "\n",
      "I've heard (first hand account) that a local EA group has started to use IQ test at job interviews. I think that there might be some amount of reputation risk from this (i.e. that EAs will be perceived to be even more cold and calculating), but to be honest I am unsure whether the costs outweigh the benefits.\n",
      "\n",
      "I would feel hesitant to introduce someone to EA who wasn't a) in a high paying job, or b) wasn't on a career path in some very specific areas. Introducing working-to-middle-class folks to the movement has led to some bad outcomes for them in my experience.\n",
      "\n",
      "I said 6 to question 40 because as much as I would enjoy sharing EA with others, I am weary to get them too excited about a community that is challenging to break into - apart from getting a job at an EA org, aligning with an EA career path and donating, EA doesn't have much of a community or culture beyond attending a local event (if one exists) and going to  global. Many other brands and movements have strong cultures that will pull people away from EA. In the long-run I imagine EA will become more of a tool that many people use to select careers and less of an established community with a strong identity and lifestyle. \n",
      "\n",
      "I can experience some frustration with EA community, especially with the younger people getting involved. They can be quite dogmatic, lacking nuance in their thinking, they are also arrogant, and use EA as a signalling contest, to compete to be \"the most effective\". I have a feeling sometime that the \"altruism\" side is left on the side. I also feel that there is a lot of focus on research and researchers, while I do think it is needed, I also beleive that other type of work are very useful, especially for implementation. I have a management background and work as a consultant, and we are very few like this, and there is almost 0 jobs around this type of skills with 80000h. I think that EA could be quite elitist and only value very specific type of people (aka researcher in AI). This make the organization more and more homogenous, and makes me want to leave sometimes. \n",
      "\n",
      "I'm worried the average EA underestimates the number of domains in which doing something is in most cases worse than doing nothing, unless one thinks extremely carefully about it first, due to the majority of possible actions in that domain being net negative. In particular, my guess is that many actions taken in attempt to reduce existential risk so far have in fact increased it, although I suspect most technical alignment research done by people at MIRI, CHAI, FHI, and the DeepMind and OpenAI safety teams—as well as work done to recruit for them (CFAR, 80k) and fund them (Open Phil, BERI)—has been net positive.\n",
      "\n",
      "I would love more career advice that is not aimed at top graduates from impressive universities\n",
      "\n",
      "as to the german community: i can understand their commitment to changing the world simply via getting a fitting job. that´s great. that makes sense. but. it only makes sense, if they are better than those who would get the jobs otherwise. and somehow basically everybody in the community beliefs that they are superior to those others... even if 50% are superior, there is no exciting answer as for the rest.   some/many ea´s in germany want to stay a small group without diluting effects to the core principles. i strongly disagree. it would be great if all people would focus their donations to effective organisations. but as for the reality it might be even better, than the average organisation doubles it´s effectiveness because of hords of people starting to ask questions like: \"hey, organisation x, what do we get... is this the best way... we are not interesting in the percentage of money which reaches africa...\". i think it´s important to get the idea of effectiveness in more peoples mind. they do not need to become effective altruists.     \n",
      "\n",
      "Find it an environment that challengs me to be ambitous, though sometimes leads to feelings of intimidation. This is, however, the main reason I involve myself - to maintain high ambitions in the 'right' cause areas. Though consequently, rejection from EA Orgs / ambitious career paths does lead to feelings of inadequacy that I might not have experienced, outside of the community. For now, I'm comfortable enough with this tradeoff.\n",
      "\n",
      "I'm wholly in favor of effective altruism as a philosophy, and have structured my life and career to a significant extent around doing good effectively. But I've never gotten all that much from the EA community or movement.\n",
      "\n",
      "I've found some of the EA Facebook group comments to be unnecessarily hostile. I also think that EAs could do a better job reaching out to religious communities. I can't remember the source, but I remember seeing a survey suggesting that many EAs are non-religious (admittedly, like me). However, I think that EA principles can be applied well in religious contexts, especially for those concerned with global poverty/public health.\n",
      "\n",
      "I really love EA and would love to live in one of the EA houses and / or work at an EA organization. The blocker for me is lack of connection until that point. Going to events and meeting people is nice, and the job board is great, but until I'm actively immersed in EA on a daily basis, I feel I'm missing a lot.\n",
      "\n",
      "EA Global 2019 SF was well managed and a positive experience. However, it felt a little stale. I would like to see some new voices and perspectives, including those critical of EA. The community is also heavily geared towards young career professionals.  More balance would also be valuable.\n",
      "\n",
      "I resonated a lot with an EA forum post about feeling terribly behind the ball compared to more experienced EAs, about how hard it is to qualify for EA-group jobs, and about feeling depressed by knowing how ineffective one is likely to be over the course of one's life. Still trying to sort out how I feel about the difficulty of contributing to the EA project.\n",
      "\n",
      "Finding and creating opportunities for meaningful involvement was difficult. It was also disheartening not to find any fitting job offers within EA organizations.\n",
      "\n",
      "There's a lot of pressure to align with EA careers without necessary support I think, but I don't have answers to how to fix this.\n",
      "\n",
      "This is likely a very temporary thing, but at the moment, I'm unemployed, and I wish the EA community could help me find a job. This would be good for me, obviously, but I genuinely think that I have a lot to offer and I think it would be good for others as well. Maybe there should be a list/group of EAs-for-hire where you post info about your skills and what you're looking for that employers can recruit from?\n",
      "\n",
      "I find the recent focus on doing a lot with a small group rather than persuading a wider audience to give to higher impact charities very off putting. There is an arrogance about it and I worry it could go very wrong. My experience with the ea community in Montreal was very uncomfortable. I generally find the focus on ai safety comcerningly self serving - working in ML is a very nice career option. The Facebook forum is deeply intimidating.   \n",
      "\n",
      "Answered 40 only with a 6 because I think the EA community is currently lacking in many areas I think and I'm worried that introducing people to EA might actually curtail their impact, mostly due to lack of diversity of opinions, career paths and expertise in EA.\n",
      "\n",
      "While I'd love to work for an EA organization, I don't know that it's realistic for me as a person with a young family needing a stable income and preferably some kind of pension in a city near my aging parents/in-laws. Reading EA material did help me come to terms with certain aspects of how I live my life and the career path I have chosen.\n",
      "\n",
      "The job advice on 80000 hours is mostly for people in the UK or US. The \"best or nothing\" approach gives standards, which are very hard to meet and make choosing a career (especially with additional constraints like location) almost impossible.\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER community: '*community*', '*movement*', '*people*', '*group*', '*individual*'\n",
      "###\n",
      "\n",
      "Too many weird/awkward people.  Too cultish and inward-facing (on a social level) for me to bring in some of my friends.\n",
      "\n",
      "The ethnic diversity in the EA community seems not good.\n",
      "\n",
      "I'm not sure what the community comprises of, or how I can get more involved, as I live somewhere quite remote. \n",
      "\n",
      "In my SF Bay Area experience, I have interacted with two EA communities: EA and \"effective animal advocacy\". Both have wonderful people and many merits, although I find the EA-aligned animal advocacy community to be healthier and more welcoming. \n",
      "\n",
      "I was kicked out of an EA memes group on Facebook for angrily telling someone he shouldn't post a meme with the word \"n*gger\" on it (except he posted the full word as part of the meme). I didn't curse, but I was quite sarcastic in my replies to his self-defenses. In the end, I was kicked out of the group and he wasn't. This really makes me think that EA is overwhelmingly white and not inclusive enough. I also got some bad feelings about EA when I saw so many anti-feminist posts on the \"Dark EA\" facebook group. I've met some wonderful EA people, but this stuff concerns me. \n",
      "\n",
      "The EA community in my experience seems heavily animal rights oriented, which I do not agree with. Because the EA Forum uses a simple voting mechanism similar to Reddit's, there is the potential for a mistaken majority leading the overall movement in a wrong or suboptimal direction.\n",
      "\n",
      "I find the EA community to be in large part exclusionary, particularly to women. I have found EAs that I admire and respect, but as a whole, I would not say that the EA community is interested in helping spread the concept of effective altruism, unfortunately. \n",
      "\n",
      "Still looking for people in the broader category of Doing Good Better, and feeling lonely in the movement as an older woman in a small town.\n",
      "\n",
      "Novelty of thinking is important but I think experience is underrated in the EA community. Very smart and talented people with little life experience have a lot of power. Not terrible in itself, but greater caution is warranted.\n",
      "\n",
      "Much of the EA community is too weird along other dimensions (vegan, poly, mental health issues) and not cool/competent enough    Would be excited to introduce them to specific people\n",
      "\n",
      "I would introduce them to GiveWell, Future Perfect, and Animal Evaluators.  Besides those, my actual experience with EA on facebook has been subpar.  People seem too robotic and even rude on occasion.  They seem more interested in efficiency than they do community building.\n",
      "\n",
      "I love the EA community and hope to continue being a part of it for as long as possible\n",
      "\n",
      "EA needs to be more welcoming of non-English speakers and people with life experiences different to the \"classic EA\" mindset. Not diversity for the sake of diversity but instead about broadening the inputs and voices contributing to EA as a community. Some of the core ideas in EA are unconventional. But now that they have been laid down, influential members defend them against any change or further unconventional influence.\n",
      "\n",
      "I wish I felt closer to the community and that I could have help starting a local group. \n",
      "\n",
      "The lack of clarity about what EA jobs were available, and the credentials required for them, hit me hard last year. I have not been motivated to apply to any jobs other than EA ones and had trouble entering a mindset of satisficing with respect to job choice, since I was so focused on finding a \"calling\" or the \"best\" choice. I thought EA direct work jobs were the answer because I had heard about people who were just out of college getting them in the few years before I applied, and because I thought they were plausibly the best way to do good with my career. But between the time those people were hired and the time I was looking, standards increased. I particularly regret that the advice floating around last year was \"do ops,\" so I decided to do that instead of grad school, and now the advice is \"do grad school.\"\n",
      "\n",
      "I may feel that some people in the EA community lack basic social skills, hence I can be worried that new people will be \"scared off\" if interacting with the wrong people in the beginning. \n",
      "\n",
      "Negative experience, the EA forum is not welcoming, unless you confirm to the groupthink.\n",
      "\n",
      "I would love to see a more diverse array of causes represented and to get the opportunity to meet with NGOs in other fields who have an EA mindset. I worry that the increasing prominence of AI safety research is quite alienating to, say, poverty NGOs. There is very little transferrable information for advocates within the EA community to learn from computer science specialists. I think that a large portion of the EA community should be made up of AI/X-risk folks, but I think it's a shame to lose the much more accessible roots that EA sprung from.\n",
      "\n",
      "Negative: A friend of mine contacted the effective altruist community and asked about effective altruism. That person had a sexual interest in my friend and became quite annoying so my friend did not get into the community.    Positive: It is very fun and meaningful to do things in the community. It have changed some paths in my life and given me very interesting thoughts, and contact with amazing people.\n",
      "\n",
      "Thank you very much! I love the community!\n",
      "\n",
      "I am impressed with the EA community, and happy how how well it's done given the challenges that come with being a community such as ours (with different people, different points of view about contentious topics, etc). That being said, whether I'd recommend the friend you ask about in question 40 would depend on specifics having to do with the friend.\n",
      "\n",
      "I would be excited to tell a person about EA ideas, but less excited to introduce them to the EA community.\n",
      "\n",
      "I don't feel comfortable in the Spanish EA group because it's a \"boy's club\" where I have to bear sexist and sometimes even racist comments. I'm the only woman, and also the only immigrant and non-white person. I don't feel safe and persistently discriminated against. Given this situation, I stopped attending several local meetings and events. \n",
      "\n",
      "Very male dominated. Huge diversity issues in terms of ethnicity. Not welcoming to non-mathsy people. West coast USA is the worst. Oxford office is pretty bad for this too.\n",
      "\n",
      "I would be hesitant to introduce a friend to EA because EAs can be discouraging of do gooding that is not typical EA work but that still makes the world better. EAs also bring up racist or sexist ideas in the spirit of questioning everything, which can be alienating for people of color and women. \n",
      "\n",
      "I worry about the sequestration scenario outlined here: https://forum.effectivealtruism.org/posts/KeBgeY8XvYb3pbFRA/movement-collapse-scenarios\n",
      "\n",
      "I'd like to see less infighting among EAs. As the anonymous author of a recent 80k blog post notes, \"There’s an enormous amount of wasted time on infighting between groups working on the same cause.\"\n",
      "\n",
      "EA suffers from a terrible lack of diversity and inclusion. As a non-White member of the community from a lower income background, I often felt very alienated, lonely, and unwelcome at international EA gatherings such as at EA Globals in 2017 and 2018. I also feel that many EAs including 80 000 Hours career coaches lack empathy for and understanding of people with my kinds of backgrounds and lived experiences such as having faced significant financial stress, relied on some form of charity food aid, lived with systemic and persistent racial discrimination including in the job market, and also being active in a religious community. I have also been very unwell these last few years, and felt very uncared for during EA Globals, and was at high risk of having a serious health incident, and no one noticed or even reached out in kindness even as I wandered around the conference venue alone and in distress. This could be because they don't understand that distress is expressed differently in different cultures and they lack the intercultural understanding to read different signals of distress. More diversity and inclusion in EA could have made me feel more welcome and supported. \n",
      "\n",
      "Positive: it has changed how I view INGOs and their work, become more critical.  Negative/positive: it sometimes feel as if the movement and its members can come of as a bit single-minded: hard to talk about \"new ideas\" that does not fit into established EA views. However, this seems to have changed a bit, like GiveWell investigating opportunities to influence gov. spending and policy.\n",
      "\n",
      "I would have been more excited except that the last few times I've brought it up I was wrong about people agreeing with the core principles.\n",
      "\n",
      "People are always interesting to talk to\n",
      "\n",
      "I would be very excited to introduce a friend to certain people within the EA community, especially those who have experience relevant to my friend's interests, but I would not necessarily be excited to invite them to the average EA social event, mostly because I find people at EA/rationalist events in the Bay area can be awkward and unwelcoming.\n",
      "\n",
      "The community seems to be a little too focused on university students and people in their 20s, and I think it could benefit from having a wider variety of ages involved.    Influencing politics and policy has a direct impact on pretty much every topic.  It's a shame that the EA community doesn't work more in the domain of influencing politics.\n",
      "\n",
      "The lack of racial and gender diversity in the movement is a persistent and serious problem for the movement and I see it as direct reason why I (and others) would become less involved (this coming from someone who has dedicated most of my college years to running and EA group and who is dedicating their career to a top EA cause).    Some more thoughts about this lack of diversity.    CAUSES OF THE ISSUE:  To some extent this is \"founder effects\" and a biproduct of the fact that the movement has grown out of cities like Oxford. However, I other factors contribute; such as the inaccessible jargon and narrow definitions of \"rationality\" and \"intelligence\" that have been imported from the rationalist community. The way in which some people in our movement seem to actively derive glee from labeling cause areas and organizations as \"ineffective\" or people as \"irrational\" or \"too emotional\" is an active impediment to having a more inclusive movement.    CONSEQUENCES:  - Heightened risk of making moral errors or prioritizing the wrong issues due to homogeneity among the people in charge of charting the path of our movement.  - Smaller talent pool, loss of engagement from otherwise dedicated members (I've felt this happening myself).  \n",
      "\n",
      "The people are really nice and actually pretty fun and really open to new experiences and doing wild stuff. That's all really good. \n",
      "\n",
      "Too many people are burned out by having a wrong view of how to incorporate the EA principles into their lives    \n",
      "\n",
      "Ea has a problem of diversity, which makes it difficult to be\"socially satisfying\" for many people\n",
      "\n",
      "global poverty questions are what attracts a lot of new members. If we deemphasize this, people will be right when they criticize us for straying toward the esoteric when there's this low hanging fruit where we can make a huge clear impact now with a clear success rate.\n",
      "\n",
      "I believe we need a message that resonates to the average citizen.  Elitism will limit our impact in the longer term.  On a related note, we (very much including our NYC group) would benefit from more evenly corresponding to the demographic makeups of the communities we live in - not that this is easy, but for our group to be completely unrepresentative will, again, limit us.  We must find ways to connect with and include the public, without sacrificing our core values!\n",
      "\n",
      "Need to create more EA work/project/startup opportunities in different countries to engage people\n",
      "\n",
      "Would like to see a stronger focus on diversity and inclusion, especially as it relates to class differences and physical/cognitive ability.    Also would love to see the online materials be made more accessible for someone who's never heard of ea before. It can be really intimidating to get into this movement if you don't have a local group to smooth the transition and most people don't have access to that.\n",
      "\n",
      "I like the Mental Health group on Facebook. Some interesting stories and sharing have occurred. \n",
      "\n",
      "Apart from the general ideas (earn to give, know where to give), the community hasn't given me much. Which is ok! All I need is someone to point me to effective charities, give overall career advice, and that's it. I spent perhaps 1h reading up on these subjects. I don't feel like all those conferences, events etc give me much more than what I now already know. Also, I feel like many discussions in forums etc become overly theoretical, especially the x-risk stuff. I think that \"here and now\" appeals to more people.\n",
      "\n",
      "The EA community is generally very welcoming and want to have a positive impact on the world but some members lack emotional intelligence \n",
      "\n",
      "It can be tiring to onboard people. Currently I tend to preserve energy and only onborad people who wouldn't require much effort. \n",
      "\n",
      "I wasn't aware that there was a community, really, until I started this survey!\n",
      "\n",
      "The focus on AI stuff turns a lot of people off\n",
      "\n",
      "I have academic friends who are broadly sympathetic to EA, but aren't interested in being more active in the community.\n",
      "\n",
      "I'd love to introduce them to Seattle, to the community at whole though, not at all. ESPECIALLY, as I may say one more time..not to 80,000 who I have strong evidence is an actively oppressive forth. \n",
      "\n",
      "I am somewhat concerned about ideological conformity/in group thinking in the EA community. I'm not sure how much of a problem this is, but I think there are some tendencies towards this and I think it is important to ensure the community takes seriously various perspectives on how to do EA/what EA looks like.\n",
      "\n",
      "Taiwan, \"ROC\", or even \"Taiwan, Province of\" was not listed in the country options. I chose to not list \"China\" because I acknowledge the contentious nature of the 'country status' question. If EA wants to remain truly impartial, it should maybe make an effort in this regard. While I understand the rationale for EA's approach to China, it is also problematic.  There is nothing altruistic in human rights violations and silencing democratic voices. Furthermore, opposing or challenging views are necessary in order to continuously rethink the effectiveness of our approaches. If an institution simply decides to ignore or silence groups/data that do not align with its own goals, and EA just accepts this, then whole point of EA is moot. \n",
      "\n",
      "I'd introduce them to specific friends and parts of the community, but certainly avoid others (e.g., certain parts of the rationalist community)\n",
      "\n",
      "I've had a good experience. Basically answering based on how much other people seem to like EA.\n",
      "\n",
      "Theres a lot of focus on rationality and less on...being a good person also with being social and connecting people  being just..good-hearted. To yourself and everyone around you\n",
      "\n",
      "I think, there needs to be a list of activities that (new) members can do, that eases them into being active EAs. Currently, it feels like many of the possible actions require taking on big projects or making big life decisions. As a student, that can feel overwhelming (and a lot of new EAs are students, right?).    I have been talking to a few of my fellow EAs in Effective Altruism Aarhus about possibly creating a database with small tasks, that one can do in a few hours or days (does this exist already?). Then researchers and organisations could add the tasks with a small motivation.  I might not be able to take on a big project, but I can definitely spend a weekend improving a researcher's code, preprocessing data, etc. This would require, that the main projects that the task contributes to, has been decided on based on EA principles of course, so the members do not have to spend hours analysing and prioritizing the tasks.  A space for thinking big, and a space for actually doing things.    An example is climate change. We all (should) know, that it is a huge problem, but few people actually have any idea about how to act on that knowledge without making big structural changes to one's life (in terms of career). By having a set of small tasks, that one can complete, we get less \"frozen\" or anxious. Obviously, EA is about having an actual impact, and sometimes people do need to make big structural changes to their lives, but perhaps having a transitional path will make it more clear, where one's skills can actually be used to solve these kinds of problems?\n",
      "\n",
      "I love the community aspect of the NYC EA meetup. The people in that group have given substantial emotional support and guidance to me during a career change. With the help of the EA community, I made two important decisions in 2019. First, I decided to commit to climate change as a cause area (I was considering other cause areas). Second, I decided to leave my job in Mechanical Engineering to learn web development at App Academy. My short term goal is to earn to give to climate charities, and my long term goal is to do direct work on greenhouse gas emissions reduction.\n",
      "\n",
      "Many in the community have a holier than thou attitude and a alarmingly high level of arrogance.\n",
      "\n",
      "The reason I did not answer 10 to the previous question is that the subset of the population who would find the core ideas appealing seems much larger than the one that would feel welcome/ enjoy being in the EA community. We often use a lot of jargon and forget what it's like to not be convinced of all these non-obvious conclusions (that have a lot of steps that a reasonable, well-informed person can disagree with). We also seem to forget that most people who are on board with scientific reasoning in general are better convinced with a compelling story to go along with the arguments/evidence than just the arguments in isolation (and that doesn't mean that these people don't have a place in our community). \n",
      "\n",
      "It depends on their background and their way of seeing the world, and which community. The online EA community is very hardcore: I wouldn't introduce many people to that. The local EA community is friendlier, but has diversity gaps (in gender, race, and \"are you highly quantitative/technical in your studies or profession, or a philosopher\"), so I would be cautious about who I introduced to it.\n",
      "\n",
      "It is great for the highly educated and resource-rich... but is hard to be embraced by 1) non-educated who are not going to have capacity/time to absorb complex messages/philosophy, and 2) people who feel they are too exhausted/stressed/indebted to give an amount that feels substantial and/or would need to force a reduced lifestyle on their families to give more.  \n",
      "\n",
      "Sometimes I have the impression that it's hard to join a group (because it is not as open as it should)\n",
      "\n",
      "I love, love, love my NYC EA group and the wonderful people I've met there.    However, \"Big EA\" has always seemed intimidating and off-putting. I was very briefly involved in an EA group in another city around 2010, and it was so unpleasant that I didn't even try to go to another until 2016, when I moved to NYC.    \"Big EA\" always feels like it's a contest who can be the biggest wonk with the mathiest brain. I get it, I get it: making tons of money and/or being extremely clever (in an EA way) are necessary for making the world a better place.    I'm not clever, and certainly not in the ways that \"Big EA\" loves and rewards. The things I'm really good at - being a social worker, being diligent and reliable and unflappable and kind - don't generate much income and don't make EAs excited.    But here I am: diligently and reliably doing the work that I was put on earth to do, making my paltry monthly donations to highly effective causes for the past ten years, and being kind and encouraging to my EA community. So, do I get to call myself an effective altruist?    For my local group, I know the answer is yes. But I always strongly suspect that \"Big EA\" (eg. EA Global, the web forums, groups in other cities, etc.) would not welcome me, and that I would be extremely uncomfortable there.\n",
      "\n",
      "Global poverty and animal welfare/rights can be easier entry points for individuals in to the EA community and focusing too heavily on far future / existential risk causes at the expense of those can dissuade other potentially EA-aligned individuals from becoming involved. I think the movement should try to avoid becoming too narrowly focused or hyper-specialized in one or two cause areas.\n",
      "\n",
      "The EA community doesn't contact me.\n",
      "\n",
      "A question on how people view their subjective life satisfaction now Vs before becoming involved in EA would be very interesting\n",
      "\n",
      "It is at times difficult to describe the concept of EA to people.\n",
      "\n",
      "When I first entered the community I was quite disappointed. I started by listening to the 80,000 hours podcast. This got me very interested and motivated. When I first went to a couple meetups (Rotterdam and then Amsterdam) however it was rather disappointing. I had imagined I would meet people who were excited to get going - to start actually doing things. It took me a while to realise that if your whole career / education is geared towards achieving EA goals then usually the best that can come of the meetups is simply conversations to network / clarify goals / learn from others. With this perspective, I'm now very happy to continue my studies in Machine Learning, while enjoying valuable conversations with EAs that help clarify and sustain my values, goals and career plans.\n",
      "\n",
      "I just attended the EA Doing Good Better Conference in Asia. I am a new community builder in the Philippines and I am really happy that I am part of this social movement.\n",
      "\n",
      "I feel people who call themselves EAs are often overconfident in their ability to calculate all eventualities and what should be done. I think people in general continually overestimate their abilities to predict the future and all influencing factors (there is research supporting this claim as well). Still, EAs in particular don't much take this uncertainty factor into account. Most everytime I talk to someone about this, they are unfazed or don't agree with me. I'm not saying you shouldn't try to calculate things. I'm saying you should include the uncertainty in your forecasts or recommendations.   Second, EAs through this overt trust in their own mental capacity often come across, in my opinion, as cold or calculating. That's why I have many EAs as loose companions, because of the interesting discussions and knowledgeable-ness, but few close friends, because I find it hard to \"connect\", as I am apparently just different than them. Also, lots of EAs didn't like me/find me interesting (I believe).\n",
      "\n",
      "Has done a great job so far on this, but needs to continue to avoid coming across as dogmatic. I worry that some student EA groups can be echo chambers as well.\n",
      "\n",
      "This question is too complex to be answered in detail. There are good things and bad things about the current state of affairs in the EA community.\n",
      "\n",
      "Going to try launching a local group.\n",
      "\n",
      "Almost everyone in the community seems to be very young (in their 30s at most), so I'm not so sure they're the best judges of what makes a fulfilling career, since they're only starting their own. (Below, by \"not diverse enough\" I primarily mean this kind of diversity, not, for instance, gender and race diversity.) The ethical and philosophical discussions were also fairly basic, which is understandable given the age of the people involved. For these reasons, I'm not convinced this group should be so eager to influence the lives of trillions of people in the far future (apart from simply helping make sure that future exists). The people seem to be very intellectually curious, however, and discussing various issues with them has been fun. \n",
      "\n",
      "Positive: people in this community are very open-minded. We can disagree, but but it will always result in constructive discussions.\n",
      "\n",
      "I found it very welcoming and friendly. I've noticed that our group isn't very diverse though.\n",
      "\n",
      "Community \n",
      "\n",
      "I loved the conference for the heart-full-ness, the learning, the sense of community, and being fully accepted as a transgender woman\n",
      "\n",
      "Due to reasons unrelated to my own personal experiences, I would be interested in seeing research into the incidence of sexual harassment in the EA community.\n",
      "\n",
      "The community at many events is not always very welcoming to new people. Cliques/jargon/etc. This seems like a major movement-building problem that for some reason the movement-building people haven't really been doing much about.\n",
      "\n",
      "At this point I'm not convinced that EA as a movement has legs.  I will continue working on my own.\n",
      "\n",
      "In general, I'm very glad about the level of civility in the movement, even in cases of strong disagreement. I'm also very excited about the prospect of ideas such as gains from trade through compromise, which I think relate to the high level of civility.\n",
      "\n",
      "I have a lot of anxiety about EA topics but even with 80k, it is still not clear what is best to do with my career and that's horrifying. I wish there were more resources for those who are not the top people that EA is often looking for.\n",
      "\n",
      "I feel the EA community has become the \"EA / Rationality\" community. I wish there was more separation between both since I'm not really interested in \"Rationality\" and I find the nerdy, AI safety focussed, super-rational approach to EA off-putting sometimes.\n",
      "\n",
      "Don't summarize EA like this to someone new: \"We are elitist who don't think climate change is important. In addition we think Nestle and Monsanto are morally good companies because they act in a capitalist way. Also it is good that we can buy T-shirts for 5€ because those textile factory workers get a few cent of that and don't have to live as a farmer anymore.\"  The friend I brought to the local EA group almost punched him.\n",
      "\n",
      "I watched several videos from a EA global panel (circa 2017?) that expressed views I found abhorrent. I can’t remember precisely but it could have been something involving cities that was extraordinarily dismissive of poor people and common sense. It strongly turned me off EA. Sorry I can’t remember more detail.\n",
      "\n",
      "It's a very nerdy community and people, on average, are a bit more socially awkward than other groups I know. I like it but it may not be everyone's preference (even if they, as an individual, are EA-inclined) \n",
      "\n",
      "The EA community in thoroughly awesome, but I'm not excited about introducing anyone to anything in general. When I meet someone interested by EA principles, the mere mention of the existence of a large and diverse community is usually sufficient to excite *them*.\n",
      "\n",
      "I've so far had very positive experiences when interacting with the EA community. \n",
      "\n",
      "The EA community online currently has issues where a lot of spaces are IMO overmoderated, making it difficult to introduce a newcomer to what feels like a \"natural\" conversation and social hub (and ultimately driving people towards weird areas like Dank EA Memes). I'm not sure where I would suggest a newcomer go in order to hang out and converse with other EAs -- the EA Corner Discord server might be the best option but it itself has major issues with drama and only really accommodating certain conversation styles.\n",
      "\n",
      "I think it would be good for the community if the percentage of women was higher\n",
      "\n",
      "Julia Wise is a god damned hero. I stan a queen!   heard about 80k giving career advice that is bad for the individual. For example, telling them to study to be qualified for a position with not enough available roles. \n",
      "\n",
      "I am solidly behind the basic ideas, but feel like most of my other views (esp. my faith) are out of step with majority of EA community, and perhaps in conflict with it on some values. Not sure whether to pursue EA under that label, or similar ideas but not under that label and better integrated with church.\n",
      "\n",
      "I don't generally discuss a lot of personal and financial matters with others except my wife. (I did teach a course in Effective Philanthropy, including a section on EA). No experience with EA groups, and not sure how that would be useful. I mainly read about EA in books and blogs like GW.\n",
      "\n",
      "I feel like the EA community is very elitist and I am not sure if it's great\n",
      "\n",
      "I dislike the rationality community (lesswrong etc.). I therefore dislike efforts to create overlaps.\n",
      "\n",
      "Generally, extremely lovely people who are very welcoming even to the 'out group'. Generally very excepting, thoughtful, and have in mind what their flaws as a community are.   We are a bit weird, but I like to think it's endearing.\n",
      "\n",
      "I feel very aligned with the core ideas of EA, however my first exposure to people in the community was underwhelming. As a generalisation, I found EA members to be more egotistical, less warm, and less socially aware than the average population. I would like to see the EA community become more diverse (especially more women and more people from humanities backgrounds), and I would like to see the community improve in social skills and interpersonal altruism. \n",
      "\n",
      "my friends who are EA aligned don't tend to enjoy the general EA meetups, and the people who do often attend general EA meetups are often people I don't gel with, which makes them less enjoyable for me to run or attend. This makes me less likely to engage with new EAs, and for the new folks who come to only see the people who I find somewhat annoying and maybe bouncing off.  I don't know how to fix this.\n",
      "\n",
      "As I found out in EA London, the community is interested in finding only people who would commit 100% to EA and I guess this is the reason I came to find the community less welcoming. Having gone to London to attend EAG, having been an EA group organizer and being an EA donor since many years may seem to make me a pretty in-depth ea, but I really felt cut out. If you are still not interested in reaching out to people that correspond to my profile, I trust this to be the most effective way to do the most good as a community. It seems to me that it's making many people abandon the community, and intuitively and emotionally this doesn't sound good, but I hope you guys see where you are going :)  \n",
      "\n",
      "It's a great community for me and others like me, but seems hard to get into if you are not too interested in ideas and nerdy stuff\n",
      "\n",
      "Reach out to more people, not just with insular EA bay area groups, but embedding EA principles more throughout society. The basic principles of EA are pretty good rationalist lenses with which to look at life and the world.\n",
      "\n",
      "I really like the community group dinners. I think it would be cool for us to do volunteer work together. Obviously in Seattle it would be lower-impact than donating malaria nets, but it would still make a difference and is something that people could do.\n",
      "\n",
      "I think it's important to maintain substantial ties outside the EA community, in order to avoid information cascade/status dynamics associated with heavy involvement in EA. For this reason I'm not sure it's always good to increase EA involvement to the maximal extent possible.\n",
      "\n",
      "I am concerned by the culture of effective altruism, especially with respect to awareness of inappropriate power imbalances in sexual relationships, hero worship and the poor incentives to call out bad behaviour of those with status in the community. \n",
      "\n",
      "I feel like the community is a subculture if it’s own and that more disagreement might be healthy\n",
      "\n",
      "I'm somewhat nervous to bring up/introduce EA because it's hard to talk about it without seeming like you're insulting people and you risk personally offending people who are very attached to certain causes.\n",
      "\n",
      "I'm especially curious how EA mixes with religion - the vast majority of donations in the U.S. are religiously motivated - it always struck me as odd that the vast majority of EAs hadn't given more thought to interfacing with religious people\n",
      "\n",
      "The overall messaging online seems to have moved away from an inclusive \"most people can make a big difference\" to a message about super high value career paths, and that is one way people will feel less valued in the community. I have also seen a large disparity in the distribution of support (monetary and otherwise) to groups and individuals around the world, and that is very offputting, and also signals that the community doesn't value us. \n",
      "\n",
      "It sometimes feels like the AI community dominates the conversation, as anything will have a much larger impact when you increase the timescale to centuries or millenia.  But I feel like the problems facing our world (climate change, animal rights to an extent) need to be solved this century, and maybe AI won't help us solve them.\n",
      "\n",
      "Community leaders seem to be doing a good job balancing openness to new ideas while maintaining EA as an intelligible concept. Maybe a little too much favoritism shown towards AI and far future generally, but that's an inside view criticism.  \n",
      "\n",
      "It’s full of well intentioned people but so dominated by white men who are often think themselves superior that I’ve gotten fed up with it all, which is a shame.\n",
      "\n",
      "I am much more interested in introducing my colleagues to EA ideas than I am to the community itself. This is mostly a matter of age and professional development.\n",
      "\n",
      "I'm reasonably smart (IQ-wise), and yet I often feel like I can't measure up to the rest of the community (especially on the EA Forum), even though I appreciate the efforts.    Related to the level of friendliness of the community, I:  - was positively impressed when meeting the community in Utrecht  - didn't feel very included when I met a few members in Beijing (happened once! I may very well have been not very warm myself - but I don't think it was the case).\n",
      "\n",
      "In general a lot of positive experiences, mostly connected with befriending and interacting with a lot of interesting and kind people.\n",
      "\n",
      "it can be difficult to talk about with others as seems cultish. need more business people as they have a lot of influence, and more outreach to people with experience.\n",
      "\n",
      "The EA community is socially stifling. I often find spending time with groups of EAs to be quite tiring. There are many reasons for this:  - Higher than normal fraction of people with limited social skills  - Many people overestimate their social skills  - (Attempted) intellectual showing off  - Intellectual pissing contests  - Many people reject \"normie\" social norms simply because they're normal (for example, the disdain that many people have for small talk or for being gentle about disagreeing)  - Distaste for mainstream culture (sports, for example)  - An insistence that every conversation should be about things that seem EA-related\n",
      "\n",
      "As previously said, I had a bad experience with my local EA community in late 2017 to early 2018. But then going to Australia really re-lit the fire for me - the community there was so interesting and supportive, it made me feel like I'd found a 'home'. I've always got a sense that the online community are welcoming, and willing to help each other out a lot, which I really appreciate.\n",
      "\n",
      "being involved in the EA community at my university seems to take up a lot of time, and i therefore couldn't join\n",
      "\n",
      "I fully identify with the principles of EA, but the community can often be off-putting, especially condescension toward non-longtermist causes.\n",
      "\n",
      "The EA community is pretentious sometimes.\n",
      "\n",
      "Make it more visible to genuine outsiders, high school students outside metro areas, and the Southern US. I could easily have never found EA.I also have several friends who are turned off by the amount of techbros in Cambridge, MA EA. Police those people! They ruin it for more of us than they are worth! \n",
      "\n",
      "I think the community was extremely quick - maybe too quick - in absorbing me. It was a bit weird to experience that I'm \"what the community regards as valuable\". I felt some kind of pressure at times.\n",
      "\n",
      "EAs are pretty awesome people in general and very tolerant of disagreement which I love (even when I disagree). I especially like that I can interact with a lot of right-wingers as a quite left-wing EA and not feel any judgement of my character for that.\n",
      "\n",
      "I have sooo many thoughts, but I’m going to leave them most of them for a later time. I think this movement needs a healthy skepticism for rationalism and the role it has played in our history. I also think “the diversity” issue is way broader in scope than it’s currently being treated as. We should be asking not just, how can we bring more “diverse” people into EA, but rather why does this not appeal to most people (and instead to people who have traditionally and continue to hold great power), and what can we learn about our own movement from the reasons others might reject it? \n",
      "\n",
      "I thought \"Doing Good Better\" was generally well-written and have referred other people to it when the topic of conversation had to do with charitable giving and adjacent topics (like efficient resource allocations).\n",
      "\n",
      "haven't really engaged in the community or felt the need to explicitly identify. should we all be ascribing to the EA values to just be the best humans we can be?\n",
      "\n",
      "I've routinely seen women, people of color, and older people treated dismissively and/or disrespectfully. I know numerous people in those demographics who are bought into EA ideas and actively work to implement them in the world, but want little or nothing to do with the EA community.\n",
      "\n",
      "Like in any community, a multiplicity of different people are active, each for their own reasons. I do not have to like all of these reasons (or people) to contribute. \n",
      "\n",
      "I suppose I would like a shift towards encouraging more people to \"do something\", or donate even small amounts, in whatever ways they can be motivated to do so. That being said, given other priorities than mine it may well be correct to focus on larger donors and one or a few main causes.\n",
      "\n",
      "Movement should not be narrowed down to a small subset of elite researchers on AI. The benefits of having a more diverse and broader movement are substantial.\n",
      "\n",
      "I wish that the EA community were a bit more polished and professional. This would probably attract more of my policy friends. \n",
      "\n",
      "reference to 'the movement', 'the community' etc makes it feel a little cult-like. Surely it is just a way of thinking...?  Also, the focus on 'EA jobs'. This is a very limited field and those working or aspiring to work in this field should not be seen as 'more than'. Those people still need the rest of society to grow their food, build their houses, drive their trains etc\n",
      "\n",
      "I would like to see more women, and more people outside high-tech circles involved and in leadership positions.\n",
      "\n",
      "I worry about introducing it to people as it can feel like a burden sometimes and I don't want to put that burden on them! It can also be perceived as a criticism of people's existing beliefs/behaviour.\n",
      "\n",
      "Elitism makes it hard for lots of people to fully integrate\n",
      "\n",
      "The community is not super impressive yet in terms of people and achievements (for an outsider)\n",
      "\n",
      "Neg:  - the movement is extremely biased towards english speaking countries . I do not see much effort - especially from the english speaking part of the movement - to change this.  - the movement is pretty undemocratic: even as someone who spends a lot of time thinking and working for EA related things I am not able to participate in a sort of election process for the leaders (such as CEA or 80k). And I see no efforts to change this.  - there seems to be a lack of exploring new ideas / ways of doing stuff: the explore / exploit tradeoff says 37%! I feel that we barely have touched 2%.  - EAs seem to neglect the donation part. Many EAs 'invest' in their careers and skip the donation part. I think these are not mutual exclusive and it should be almost obligatory to donate as an aspiring EA.  - EA is relying on signaling a lot: I have spent quite some time with people from the big universities such as Stanford, Harvard or Oxford. They do not differ much from good students at other places.  - EA is degrading the work of many people: The idea of high-impact careers could be communicated in a way so that people that are in their 30-50's don't feel bad for only being a doctor, teacher, nurse or whatever. I think the movement is thereby rejecting a lot of potentially highly valuable people.  - EA events sometimes are extremely competitive and can lack the fun that is necessary to glue together a community  - CEA's community building department with 3(!) people is ridiculous.They need more manpower!  - The EA movement is heavily dependent on Facebook, Google and Slack. Many times it is simply impossible to attend events without having a Facebook Account, CEA forces you to have an Google Account to apply for funding. The reasons for rejecting these services are numerous and there are good open alternatives.  - Additionally: Most of the time it is really really hard to get contact to local EAs because: there is no website for them, a closed facebook group, people do not answer your mails / Facebook requests.    pos:  -  All in all it is an extremely impressive movement with some of the brightest minds. I'm proud being a part of it.  \n",
      "\n",
      "Positive discussion culture. People are aspiring to be rational, but nonetheless kind to each other. \n",
      "\n",
      "I don't know much about your community, and I am not a part of it. I like your ideas, and I appreciate the work you are doing. It's possible I'm being unreasonable, but judging purely by what I've read online, especially LessWrong, your community seems too likely to be unwelcoming for me to want to try to get involved (I'm shy, and Christian, and conflict averse, and not willing to devote my life to EA, and I strongly suspect people would try to talk me out of things I don't want to have to argue about and not take no for an answer - which, again, may be unfair, but it's often the feeling I've gotten.) Your (very early) question about how involved people were was backwards, by the way, at least for me - I follow EA guidelines for donation, but my community involvement is mostly limited to reading GiveWell charity evaluations. And I would be much more excited to introduce my hypothetical friend to the body of research - and idea of \"no, we can actually do this\" - than the community, because... well, see above. I'm not part of the community, and don't know if it'd be good for hypothetical-friend. But the ideas, the work and the research and the chance to save lives, are amazing, and I really do appreciate what you're doing. I just also find you scary. Don't worry; I find lots of people scary. \n",
      "\n",
      "Although I'm still very much interested in the community, I've become more concerned about the current norm for doing prioritization within EA. Specifically, I think that by maximizing impact with respect to our values we end up with \"free-rider\" problems where we each focus on cause areas that only we think are important.    Also, the more weird that EA priorities get (mainly I have in mind the shift towards influencing the far future) the more difficult it is to pitch it to friends.\n",
      "\n",
      "I've been invited to apply for things at CEA, FHI, CHAI, Founders Pledge, etc. But in retrospect I don't think I had a real chance at any of them, and I wonder how many thousands of hours of optimal work we're burning on applications.    It surprises me that 80k doesn't follow the AI safety people it creates more closely, to manage saturation of the junior end of the pipeline.\n",
      "\n",
      "I have issues with the idea of prioritizing or optimizing for any one thing, due to the issues discussed in the Slate Star Codex post \"Meditations on Moloch\". I also have met EA folks who try to counter their moral intuition telling them to take actions that help people in ways other than the ones they've seemed most effective by telling themselves and others that their EA actions have \"bought their ticket to not care\". I think this is a dangerous mindset to get into as it opens up the possibility of being wrong and therefore having completely negative impact because you put all your eggs in the wrong basket. (Moloch again!)\n",
      "\n",
      "In my experience, people that thrive in the EA community have some very specific traits (beyond agreeing with the core principles) —e.g. highly motivated by abstract intellectual pursuits, a quantitative approach to problems, etc.—    Newcomers who share those traits feel at home when they join the community.    People who agree with the EA principles but do not share the traits can be put off by the community.  \n",
      "\n",
      "On average, I perceive the EA community to be somewhat intellectually elitist and low in social skills and \"welcomingness\"\n",
      "\n",
      "I like the people and the basic principles. But I think that EA people and organisations sometimes focus excessively on minor issues, which should really be part of EA, based on its core principles.\n",
      "\n",
      "The first impression of EA's core messages can be a bit black-and-white and pretentious. If you dig deeper and get to know the movement a world of respectful discussion and nuance appears. This makes me sometimes hesitant to introduce my friends to the movement. \n",
      "\n",
      "I have engaged more with the EA idea than the EA community\n",
      "\n",
      "One of the important EA people almost excluded a person I know from various EA activities for something they said that contradicts the feminist discourse. That's scary.\n",
      "\n",
      "Overall it's some of the most wonderful, thoughtful, and focused people I've met. At our worst however, we lose kindness and social intelligence in our efforts to maximize impact. \n",
      "\n",
      "it's impossible to talk to people about EA and get them to buy in, there should be a guide for \"talking to friends about EA\"\n",
      "\n",
      "I would like to see the community become more diverse, particularly with respect to age, gender, and ethnicity. \n",
      "\n",
      "It seems like the EA community is very academic. We can do a better job presenting our worldview to others and bringing new allies into the fold.\n",
      "\n",
      "This doesn't apply to most of the EAs I've met, but at times there's a lack of intellectual humility / failure to recognize the limits of one's knowledge. This seems to apply particularly to members of the Rationalist community.\n",
      "\n",
      "Please dont deemphasize community building\n",
      "\n",
      "I don't experience EA as a \"community\" to which I might \"introduce\" a friend, just as a... worldview.\n",
      "\n",
      "It's a good community. Too elitist perhaps, except the elitism has good rational justifications.\n",
      "\n",
      "With the large shift towards far-future cause areas, it’s becoming much harder to welcome new people into EA. These topics are important, but less accessible to someone that is not from an engineering or science background.    I’m not suggesting that we divert attention away from these causes, but more effort needs to invested into building a pipeline/onboarding for new people to discover and engage with EA.\n",
      "\n",
      "I'm very excited about the principles of EA, but it can at times feel like the people involved in the field can lack \"heart\" - over intellectualised discussion, etc. Not necessarily a bad thing (we probably need more rationality and less gut feeling in general!) but it can be a put-off for some\n",
      "\n",
      "I spent a lot of time in the non-profit, development aid sector and EA has been so far the only community that really seems to unite behind a common goal and where people working at different organizations are seen as companions and not competitors. \n",
      "\n",
      "I love the blog Giving Gladly and the supportive and informative emails I get from Givewell. I don't think I would ever feel comfortable attending an EA event because I'm not \"pure-EA\" enough. I am not planning on changing to a higher earning career, though of course I will do what I can to earn the most I can within my field (massage therapy/energy healing). I feel that my spiritual beliefs would not be accepted in the EA community or would simply make people feel uncomfortable. But I wish that that weren't the case so I could make EA friends without feeling like my own decisions will be frowned upon. \n",
      "\n",
      "For me, EA is more about what I do than about the community. I'm aware the EA community exists, and is important for guiding those of us who are interested in EA, but I don't consider myself part of it.\n",
      "\n",
      "• Frequently come across a strong sense of entitlement, or outright arrogance in personal interactions with less-engaged EAs. A common feeling among these people is that they feel uniquely gifted or especially well-prepared to solve problem X despite having virtually no experience — even expressing disbelief when they don't get a grant or a job offer.  • Having lived with several cohorts of EAs for nearly a year, I'm less confident about the general competence of new people I meet — I'm astonished that some of these guys think they'll change the world when they can't even change for clean clothes.\n",
      "\n",
      "I like the ITN Framework, because it is one attempt to deal with rivalry and achieve some additionality and counterfactual impact. EA needs more diversity in thinking and approaches - less optimization and more search, and explore topics around embodied practices, collective intelligence. My personal interest is rivalry, and antirivalrous goods, or ways how to change mental models (seeing people as processes and not objects, seeing people as emergent properties of whole ecosystems... )\n",
      "\n",
      "One thing I noticed here is there is seemingly a big crossover between those interested in Jordan Peterson and EA broader community here, and that strikes me as presenting a barrier to access. What I mean is, if that is someone's first experience in the community, and they don't know to ask \"so what does this guy think and why do you believe him, \" it's likely that this subject will alienate potential new members, the ones you need for resilience and fresh ideas through diversity. \n",
      "\n",
      "A harsh take is that it comes across as a movement for rich educated people. You pretty much have to be rich enough to donate, or otherwise successful enough in the professional sphere to make EA-related career choices, which doesn't leave much room for more marginalized folks to get involved. \n",
      "\n",
      "Last time I was at a meetup I found myself somehow the most in-touch person present. While it was fun being the only one who knew the HPMOR URL by heart, introducing the organiser to SSC, and giving hope to the only other person present who had heard of Brian Tomasik, I wonder if it's a good or bad thing that the average general EA-related knowledge level in the community appears to be decreasing. I'd say I appreciate the diversity of ideas but am wary about losing our way, in a sense\n",
      "\n",
      "Highly positive experiences, thoughtful and interesting people.\n",
      "\n",
      "It is really hard to be involved in the community itself as someone who is an 'average person'. The EA community itself seems to award high status to Ivy Leaguers who are very accomplished. I did not even consider aligning my career towards it, because it feels like careers for EAs would not even want me. If it were not for Jeff Kauffman's, Julia Wise's, and Kelsey Piper's online presence, I would have a lot of difficulty feeling like this was a movement for me.\n",
      "\n",
      "First EA people I met were just the most wonderful human beings. However, nudity at parties really put me off. Can find that EA people are too elitist.\n",
      "\n",
      "I'm starting to get the feeling that the EA community is a little too interested in just discussing things and not interested enough in putting things into action. Maybe this is due to risk aversion but maybe its also a little to do with enjoying discussing nerdy topics too much.\n",
      "\n",
      "The community needs to focus much more on optics and people skills, and also attempt to gain a more holistic understanding of the cause of global poverty, x risk etc (ie capitalist imperialism)\n",
      "\n",
      "I believe we need to empower individuals to take concrete actions for the sake of the various EA causes.\n",
      "\n",
      "EA could benefit from being less insular.     The ideas of economists like Tyler Cowen, Robin Hanson, Glen Weyl, etc. are very relevant. There's a great deal of skepticism regarding AI risk from the broader AI research community that isn't taken seriously enough.    Generally I think the standard of diversity of ideas set by the 80,000 hours podcast is great and should be a benchmark for the community more broadly.\n",
      "\n",
      "I've had a very positive experience with the EA community. Considering how multifarious the movement is and how quickly it is changing, I think people have done a great job being inclusive and welcoming to newcomers.\n",
      "\n",
      "I think my friends who're devoutly religious and/or politically conservative would be repelled by much of the EA community.  Worse, I'm afraid it would sour them on EA principles.\n",
      "\n",
      "With the rise of longtermism and the dominance of x-risk, I'm more and more embarrassed of the community. But I'm also a big member of the community and I try to carry on talking about what I think is important. \n",
      "\n",
      "I brought up EA with a friend who I had assumed would be broadly interested in learning about EA, but he already had a very bad impression of the movement for \"not attempting to address systemic/structural problems\".\n",
      "\n",
      "+1 on EA is incredibly academically competitive, and that's highly discouraging. On paper, I'm roughly Ivy League level qualified for most academic/career positions, yet most of the opportunities I hear about in EA I couldn't get into, and most of the people who I see doing incredibly impactful work I am not as effective as. Reading lots of EA content regularly gives me status anxiety about not being successful or well-qualified enough to do the high-impact things I want to do. \n",
      "\n",
      "I believe EA should focus more on growth - especially my community.\n",
      "\n",
      "I think many EA members come off as less socially skilled, which can be a problem for people on the other end of that spectrum. I personally don't have too much of an issue with it but I would give pause to introducing certain friends into the core community.\n",
      "\n",
      "Mainly negative experiences are around cause priority arguments - so many people dismissing climate change because it's unlikely to be existential.  That and a general sense that people are very heavily invested in wierd positions/internal debates\n",
      "\n",
      "As this survey will likely show, the movement has some serious diversity problems, which could be symptomatic of, or in the future cause, problems with the ideologies promoted, and if nothing else gives outsiders good reason to distrust us and makes out already controversial views lower traction. I think more thought and research should go into the causes of these problems and what if anything can be done about them.\n",
      "\n",
      "I share the basic goal of doing good more effectively, but I disagree about the specifics to the extent that I'm not sure whether the EA movement will be net positive.\n",
      "\n",
      "More focus and funding need to be provided to help people successfully pursue effective career.\n",
      "\n",
      "I have grown somewhat disillusioned with the EA community and philosophy.  In the community, I perceive intellectual arrogance and some cultish behaviour (although I admit this is not necessarily a \"rational\" perception, but more of an uncomfortable feeling).   In the philosophy or theoretical basis of EA, I feel that   a) the parts that feel most evident and easy to be somewhat certain of are not original (e.g. the morality of maximising utility) and  b) the parts that are original (i.e. the pointing out of particular causes, like XR) are most questionable from an epistemic point of view, hence harder to trust.   \n",
      "\n",
      "I would feel excited to introduced them to many relevant ethical and intellectual ideas associated with EA. I would feel nervous about introducing them to the community itself -- since I think any given person has a decent chance of finding the community offputtingly insular, undersensitive to what people previously unfamiliar with EA will find weird/uncomfortable, etc. \n",
      "\n",
      "My experience with the community has been very positive, however I am more excited to discuss principles and resources than specifically the community.\n",
      "\n",
      "If I'm being completely honest I probably prefer engaging in the community passively, rather than in person, etc, at least for the moment because I feel I'll be judged for not donating enough, living a too-high quality of life, etc\n",
      "\n",
      "My answers might seem strange given that I identified as part of the community, but the fact is I'm a journeyman who wants to learn more.\n",
      "\n",
      "Joining the EA community has had an immense and lasting positive effect on my life (e.g. by feeling more meaningful, having made fantastic smart and caring friends, having received support for major personal projects etc) \n",
      "\n",
      "Community? Meh. I'm a loner. Communities are rife with issues as always. Look, keep up the good work. \n",
      "\n",
      "The EA community is amazing!  I'm worried that there's not enough coordination and transparency in the community. It seems to me that EA orgs tend to optimize a lot for impressiveness at the cost of being less transparent (and perhaps less beneficial). I rarely see public criticism on EA orgs (coming from outside the org).\n",
      "\n",
      "It is very important to prevent local EA groups from being taken over by aggressive militant leftists who care nothing for rationality or our core causes.\n",
      "\n",
      "I fundamentally care about helping the extreme poor, about working against climate change, and more generally leveraging my privileged position to make the world better, not worse. Effective Altruism has useful resources for me to find out how to do this. Not to be rude, but I don't really identify with the EA community. Especially on the forums there are some strange discussions such as plant welfare and the more obscure sounding apocalyptic scenarios that to me just sound outlandish.    Nonetheless there's some fantastic discussions and research here, and it's very encouraging to find like-minded people. For me EA is more of a resource. I suspect there are many people on the fringes with a similar perspective.\n",
      "\n",
      "I get that EA (at least from my view and how it's explained to me) is about rationality and a more consequentialist way of thinking. But this modality of spreading the message is, pardon my french, dogshit (IMO).    Everyone I've interacted w/ at EA is so emotionless and too logical; too academic too and not pragmatic enough.    So many look at problems just in terms of numbers instead of seeing what is in front of their own eyes.    Overall, though I can relate to these people as I've worked in tech/STEM for so long, 99% of the general public, IMO, will think they're robots.    It's no way to market what is a very important movement to push.    People in the EA movement, from my view, need to improve their people skills and think more pragmatically.    Otherwise you will have the typical business-douchebags who can talk-the-talk and spin things effectively walk all over the EA side of the fence.    Also, re 80k, maybe I'm misinterpreting their mission, but again, it seems like they think people are robots. You can't expect people en masse to work shitty jobs they don't find maximally fulfilling and donate a decent chunk of their salary to people on the other side of the world.    It's instances like this where a clear lack of human understanding plagues EAs — from my view, anyway.    It just seems to me everything is so oriented towards analytical-thinking that the actual foundational empathy required to do-good is lost.    All just my opinion that I imagine most will disagree with.    Just my observation as somebody who does has dealt with the software-engineer types my whole career. I see similar patterns.\n",
      "\n",
      "I'm concerned by the disdain shown towards people who take racism & sexism seriously, particularly by sections of the online EA community.\n",
      "\n",
      "I sometimes miss the personal side in the EA community (My local group is cool but on international events I feel quite lost). Furthermore sometimes EA feels a bit elitist and competitive (again this applies more to the international than the local level). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to see more diversity of interventions financed in animal protection-related projects. I'd like to see climate change prioritazed by the EA community.\n",
      "\n",
      "I am very happy with EA thinking, but not with the community. I feel  (and this is just my experience) its very dominated by guys, and mostly the non-social kinds. In the past I've worked for a local EA group and felt my voice was not at all heard, even though I had one of the best credentials (e.g. in terms of university degrees). I felt I was approached as the 'social one', who was good to have at events for mingling, but not for the 'real content'. I have honestly been hesitant to invite friends/colleagues to EA events because of this tendency, even though I know many of them would align with EA thinking. Many of the non-social EA guys I'm referring to here tend to be so fanatic in their EA beliefs that it comes across as closed off and doesn't encourage new people to join. This halters the spread of EA. \n",
      "\n",
      "Definitely not a fan of the \"rationalist\" community\n",
      "\n",
      "I think the existence of the EA community is not advertised enough. \n",
      "\n",
      "Most people are great. Some people are terrible. However, even terrible people have something to contribute (even if it's just becoming less obvious at being terrible.)\n",
      "\n",
      "Sad it isn’t bigger so that there was a closer local group, harder to get to meet ups far away. Would prefer if the talks were more practical focused. \n",
      "\n",
      "I have had no interaction directly with the EA community. I just read Slate Star Codex\n",
      "\n",
      "At meet-ups people can often be very intense in a way that can be off-putting, although, of course I have met some great people through the community. \n",
      "\n",
      "I enjoy the EA community and wish to see it grow. They are people with values and a type of nerd geekiness that is relatable, and home-feeling. I believe continuing to attract such members will be beneficial to the group as a whole.\n",
      "\n",
      "I get that this is the EA survey, but it's weird seeing so little references to the rationalist(/ea) community i.e. I basically conflate the two in practice. But yeah, I love the ea/rationality community! I'm super grateful for the two jobs I got through the community, too. I'm mostly (VERY) jaded about grad school and about having discouraging experiences with people who are famous within the community (being brushed off by several people, and being told my research was *harmful* by one person I respected at the time).\n",
      "\n",
      "I know that this is a pretty common critique, but it feels like AI risk is being prioritized much more than it should be, simply because people are more aware of the dangers of topics they're familiar with and EA is pretty full of techies. \n",
      "\n",
      "I think there's a gap in EA in providing advice to average-to-medium-talent individuals on how to be effectively altruistic (I'm particularly thinking of career advice). It makes sense to allocate most/all resources to advising high-talent individuals who will have a much larger impact than everyone else. However, this has the effect of leaving a large population of not-high-talent individuals (who should really just be focusing on getting into a decent career and donating 10% of their income to highly effective charities) with unrealisable ambitions to change the course of humanity. This leads to a) a lot of people who identify as EAs appearing delusional, b) wasted effort being put into learning arcane facts about AI/global poverty/pandemics/etc which would be better be put into learning concrete middle-class career skills, c) frustration at career aspirations not being met. In fact, I wouldn't be surprised if a small amount of exposure to EA (enough to learn how to allocate donations to effective charities) leads not-high-talent individuals to be more effective on average, but a large amount of exposure to EA (enough to affect career decisions) actually leads to *less* total effectiveness on average.    I suspect the status quo of focusing on how high-talent individuals can be effective is in fact the most effective strategy. However, I also think that those in the inner circles of EA surrounded by lots of talent and resources are probably not aware of what I'm describing. And so this may be a problem.\n",
      "\n",
      "It's very difficult to engage people in tasks beyond the mere agreement that EA, as a movement, is right. We need more people engaging full-time in EA in my country, but it's hard to people to mantain their incentives to this task.\n",
      "\n",
      "It seems to share the biases common to the tech community which skews white, relatively affluent, kinda libertarian and very male, and has trouble considering realities that primarily affect other groups to be truly important, despite the real justification for taking a macro perspective on the effects of giving \n",
      "\n",
      "I feel very comfortable in our lcal EA-group. They combine rational thinking with social skills. I enjoy to spend time with them even outside the EA-topics.\n",
      "\n",
      "Positive: supportive, open community, transparent grant application process (discuss concerns openly), opportunities to get to know CEA better, inspiring people in CEA/FHI office  Negative: previous group leader found me \"ill-suited for EA movement building work\" (in contrast to everyone else who appreciated my work) - seems like she was a bit overconfident in her judgement\n",
      "\n",
      "I was excited to introduce EA to a friend but my excitement was muted due to the fact I think we need to lead the movement locally and we both feel over leveraged at the moment. \n",
      "\n",
      "The local community is okay but the community at large is full of elitism and is not great. \n",
      "\n",
      "It's hard to introduce people to EA when so many of the associated concepts (e.g., X-risk) seem so weird at first glance. \n",
      "\n",
      "I think the effective altruism community is in general too insular and too meta. I think we would have more influence and benefit more from outside ideas if people didn't call themselves EAs but instead felt instead that they were part of the intellectual current known as effective altruism. \n",
      "\n",
      "Sometimes I think EA makes people focus too narrowly and not acknowledge the bigger picture, for example how giving can impact facets of a person's life (education) rather than just one (malaria prevention).\n",
      "\n",
      "The EA movement is full of smart, kind, interesting people. It may have its flaws, but probably far less than any other community I've known. \n",
      "\n",
      "I think it could be more inclusive of other academia such as the humanities, besides philosophy and politics. Even though it is enlightening and I am very happy to be learning information outside of what I am studying, a lot of the talks at my local group can sometimes be hard to understand when you are not surrounded by the discourse that is being discussed. Additionally, I believe the introduction of different academic areas would be more insightful for the community and bring a new perspective, specifically history.\n",
      "\n",
      "I give 10% of my income according to EA principles but do not engage with the community at all (except for reading articles).\n",
      "\n",
      "I would be excited to introduce them to professionally managed EA organizations like 80,000 Hours or Givewell.  I would not be so excited to introduce them to the local EA Meetup group, which is not well run.\n",
      "\n",
      "I've heard (first hand account) that a local EA group has started to use IQ test at job interviews. I think that there might be some amount of reputation risk from this (i.e. that EAs will be perceived to be even more cold and calculating), but to be honest I am unsure whether the costs outweigh the benefits.\n",
      "\n",
      "I love this community.\n",
      "\n",
      "I would feel hesitant to introduce someone to EA who wasn't a) in a high paying job, or b) wasn't on a career path in some very specific areas. Introducing working-to-middle-class folks to the movement has led to some bad outcomes for them in my experience.\n",
      "\n",
      "- The French EA community is welcoming.   - Overlap with the rationalist community, including vocabulary and concepts popular on LessWrong (positive for me since I've known LessWrong for a long time)\n",
      "\n",
      "Most people are very welcoming to newcomers who are unfamiliar to the goals of EA, but sometimes newcomers at in-person events are treated as not worth the time by more experienced EA community members.    Memorably, my wife tried to start a conversation with someone at a Meetup. He asked her her opinion on some particular, and she said she didn't know about it. He simply turned around and left. I think he was \"protecting his time\" but it was very off-putting.\n",
      "\n",
      "I said 6 to question 40 because as much as I would enjoy sharing EA with others, I am weary to get them too excited about a community that is challenging to break into - apart from getting a job at an EA org, aligning with an EA career path and donating, EA doesn't have much of a community or culture beyond attending a local event (if one exists) and going to  global. Many other brands and movements have strong cultures that will pull people away from EA. In the long-run I imagine EA will become more of a tool that many people use to select careers and less of an established community with a strong identity and lifestyle. \n",
      "\n",
      "Communication with most EA people (especially in a professional way) take very very long. Getting answers, even if a date was given, mostly happens after multiple reminders. Also there seems to be an \"EA Elite Group\" where you can only enter if you have contacts or other credentials - makes the community less open for new people. \n",
      "\n",
      "It'd be great to make the resources available for more people in Latin America (translating some of the articles and core principles would be a great first step)\n",
      "\n",
      "I think EAs (at least the ones I’ve interacted with) aren’t willing enough to admit (to themselves and others) that they’re human - with all the ingrained selfishness and dishonesty that entails. They too easily think of themselves as purely utility-maximising, good-doing agents, and then are disappointed when they or others don’t live up to this impossible standard. At least within my group, EA needs a heavy dose of realism and humility with respect to what an individual human can and will do.\n",
      "\n",
      "I can experience some frustration with EA community, especially with the younger people getting involved. They can be quite dogmatic, lacking nuance in their thinking, they are also arrogant, and use EA as a signalling contest, to compete to be \"the most effective\". I have a feeling sometime that the \"altruism\" side is left on the side. I also feel that there is a lot of focus on research and researchers, while I do think it is needed, I also beleive that other type of work are very useful, especially for implementation. I have a management background and work as a consultant, and we are very few like this, and there is almost 0 jobs around this type of skills with 80000h. I think that EA could be quite elitist and only value very specific type of people (aka researcher in AI). This make the organization more and more homogenous, and makes me want to leave sometimes. \n",
      "\n",
      "I really enjoy the EA Sydney crowd. Good group of folks\n",
      "\n",
      "I feel very much out of my personal demographic in the EA community - older, female, country town.\n",
      "\n",
      "Yes - it can be a bit narrow and exclusive, especially in assuming specific world views. eg I am a progressive christian & baby boomer - both are minority groups in EA - that is fine, but assumptions (at times) are frustrating eg assumptions that all EAs are rationalist skeptic atheists or utilitarians or young-ish\n",
      "\n",
      "My excitement about introducing new people to EA is somewhat tempered by a desire not to seem like a cult.\n",
      "\n",
      "EA Global is far too exclusive. Many people who wanted to attend were not allowed to!\n",
      "\n",
      "I'm worried the average EA underestimates the number of domains in which doing something is in most cases worse than doing nothing, unless one thinks extremely carefully about it first, due to the majority of possible actions in that domain being net negative. In particular, my guess is that many actions taken in attempt to reduce existential risk so far have in fact increased it, although I suspect most technical alignment research done by people at MIRI, CHAI, FHI, and the DeepMind and OpenAI safety teams—as well as work done to recruit for them (CFAR, 80k) and fund them (Open Phil, BERI)—has been net positive.\n",
      "\n",
      "The reason it's not higher is because sometimes the community can come across a little unfriendly, and also has some pretty different ideas from the mainstream so it'd have to be a soft introduction! I also didn't get more actively involved in EA stuff for several years because I didn't feel very at home as a woman without a Philosophy post-graduate degree! This has improved a bit since but the EA community is still not at all diverse.\n",
      "\n",
      "I've met some nice and inspiring people in the EA Isreal meetings. Kudos to them. \n",
      "\n",
      "I went to an EA event in Utrecht a year or so ago. I found it disappointing. There were some REALLY fantastic speakers, and I met a few really cool people. But in general the attendees seems very ill-informed. I went to a climate change workshop, and most of the people there could have learnt a huge amount just by reading the Wikipedia page. Interesting discussion was drowned out by naive questions. I did not get the impression that these were the people who were going to fix the world. Sorry for being a grumpy old git... \n",
      "\n",
      "I have had people attempt to optimize my life for me because of their dedication to effectiveness. It has been a great source of unhappiness and discomfort, largely because they value how my output metrics contribute to making the world better over actually valuing me as a living breathing human being. A person. I believe the principles of EA are solid, but they can easily be misapplied to cause harm to individuals.\n",
      "\n",
      "as to the german community: i can understand their commitment to changing the world simply via getting a fitting job. that´s great. that makes sense. but. it only makes sense, if they are better than those who would get the jobs otherwise. and somehow basically everybody in the community beliefs that they are superior to those others... even if 50% are superior, there is no exciting answer as for the rest.   some/many ea´s in germany want to stay a small group without diluting effects to the core principles. i strongly disagree. it would be great if all people would focus their donations to effective organisations. but as for the reality it might be even better, than the average organisation doubles it´s effectiveness because of hords of people starting to ask questions like: \"hey, organisation x, what do we get... is this the best way... we are not interesting in the percentage of money which reaches africa...\". i think it´s important to get the idea of effectiveness in more peoples mind. they do not need to become effective altruists.     \n",
      "\n",
      "Sometimes I am afraid to introduce people to the community because of fear for their mental health. I don't want to put the burden on them that they have to save the world and optimize their life in relation to this. Although this is not what EA is aiming at (in this negative way), I feel like many EAs still struggle with it. \n",
      "\n",
      "I've had some negative experiences with a lack of organizational competence of some people at EA organizations (e.g. not responding to emails, getting stood up for a call, etc.). \n",
      "\n",
      "Find it an environment that challengs me to be ambitous, though sometimes leads to feelings of intimidation. This is, however, the main reason I involve myself - to maintain high ambitions in the 'right' cause areas. Though consequently, rejection from EA Orgs / ambitious career paths does lead to feelings of inadequacy that I might not have experienced, outside of the community. For now, I'm comfortable enough with this tradeoff.\n",
      "\n",
      "I think the EA community has a number of blind spots and biases which put it in danger of simply becoming the Silicon Valley style of giving, rather than a distinctive philosophical approach\n",
      "\n",
      "EA is great because of the people. everyone i've met has been really lovely and interesting and kind.  I'm so involved in the community because of the people i've met, and my conviction that we have shared values, concerns and beliefs.   much less so because of the core EA orgs, although I respect their work.  to me, the community is what makes EA special, and the values that have been cultivated - openness to learn, humbleness, willingness to argue and debate. and a genuine sense of caring for others.  without the community and without having met the people, investing loads of time and resources into EA, specifically community building, wouldn't have 1/10 of the appeal to me. \n",
      "\n",
      "I was enthused at the level of support that exists for new group leaders. I like that the main website (resources.eahub.org) is relatively well-organized, even though it's missing some resources that exist elsewhere. Hopefully it can become the central hub that new group leaders are sent to for getting started.\n",
      "\n",
      "Scott Alexander's https://slatestarcodex.com/2017/08/16/fear-and-loathing-at-effective-altruism-global-2017/ was outright haunting.  Can't invert an ill conditioned matrix and made EA seem more Superman Villain and less be nice and humble and give people bed nets. \n",
      "\n",
      "I'm wholly in favor of effective altruism as a philosophy, and have structured my life and career to a significant extent around doing good effectively. But I've never gotten all that much from the EA community or movement.\n",
      "\n",
      "I've found some of the EA Facebook group comments to be unnecessarily hostile. I also think that EAs could do a better job reaching out to religious communities. I can't remember the source, but I remember seeing a survey suggesting that many EAs are non-religious (admittedly, like me). However, I think that EA principles can be applied well in religious contexts, especially for those concerned with global poverty/public health.\n",
      "\n",
      "Most of my experiences with the EA community have been really positive. I've found a group of people who deeply care about helping others, and are thoughtful and careful in how to do that. They're also individually extremely supportive and caring. \n",
      "\n",
      "Many in the EA community are obsessed with showing off how smart they are, rather than having an impact in the real world.\n",
      "\n",
      "As a digital nomad it's hard to get involved in the community in person, and hang out with value-aligned people.\n",
      "\n",
      "I have nothing but respect for the EA community, but some people perceive its members to be weird/nerdy. I tend to be more excited about communicating the ideas than presenting their exponents.\n",
      "\n",
      "It doesn't always leave room for giving to non-urgent causes. That rigidity can turn people off.\n",
      "\n",
      "Lacking diversity in several ways, making it unappealing to people who don’t fit in with the general EA trope.\n",
      "\n",
      "I'm extremely glad to have found a community of people who share so many of the views I had, think rigorously and write clearly about them, can change my mind and introduce me to new ideas, and help guide and inspire and support me to really act on my principles in an effective way.\n",
      "\n",
      "I really love EA and would love to live in one of the EA houses and / or work at an EA organization. The blocker for me is lack of connection until that point. Going to events and meeting people is nice, and the job board is great, but until I'm actively immersed in EA on a daily basis, I feel I'm missing a lot.\n",
      "\n",
      "EA Global 2019 SF was well managed and a positive experience. However, it felt a little stale. I would like to see some new voices and perspectives, including those critical of EA. The community is also heavily geared towards young career professionals.  More balance would also be valuable.\n",
      "\n",
      "It's a bit disheartening to me to see so few likes/shares on EA's (MacAskill, GiveWell, etc) social channels. Any new YouTube content makes me really happy. Future Perfect makes me happy. Publishing the results of my donations and the community's donations is extremely motivational for me\n",
      "\n",
      "Way too much dancing on the head of a pin. People way too young and inexperienced with how the real world works.\n",
      "\n",
      "Sometimes the ideas come across as a little bit \"crazy\" to normal people (e.g., wild animal suffering) which can make it hard to connect people with the community\n",
      "\n",
      "After reading about the principles of EA, I enthusiastically discussed with some of my friends. Some of my friends had already heard of EA and were already very turned off by it. They told me how the people in the community come off as \"elitist\". I now see how saying something like \"being a doctor is not a good way to save lives, you could do better being a software engineer and buying malaria nets\" can seem condescending. It loosely translates to \"you think you're doing good, but I'm doing MORE good than you.\" \n",
      "\n",
      "I don't know how to effectively connect to the community! I haven't really gone past reading, so would love to meet some people in person. \n",
      "\n",
      "I resonated a lot with an EA forum post about feeling terribly behind the ball compared to more experienced EAs, about how hard it is to qualify for EA-group jobs, and about feeling depressed by knowing how ineffective one is likely to be over the course of one's life. Still trying to sort out how I feel about the difficulty of contributing to the EA project.\n",
      "\n",
      "It's one of the best communities I've found for meeting nice and interesting people, the social benefits are a large part of why I spend time with EAs.  I eat meat and don't think animals have moral value, so I feel alienated by the norm of vegan food.  I think it's quite susceptible to group think, eg on controversial and difficult topics like AI Safety\n",
      "\n",
      "A significant amount of community members have poor social skills. Many come across as naiive and prideful. I'd be worried introducing most people to anything but a hand-selected group of EAs, lest they be turned off by arrogance and inability communicate their views with sensitivity and nuance. Terrible on diversity, not great with women. As a mixed race person who didn't grow up rich, I often feel uncomfortable and out of place, despite having attended elite universities for undergraduate and graduate school.\n",
      "\n",
      "There was a great TED talk on how activist movements need introverts but don't know how to use or engage them. Specifically looking at ways to benefit from people who don't want to meet face-to-face, read social media but don't want to post, etc. can still support and benefit a movement. EA needs to learn those lessons and stop being a movement for extroverts only. Even the questions in this survey show a massive bias against introverts. Look at the pairings in question #12 where learning and personal action are in a forced linkage with social action. So there's no way for a person to read everything they can find and apply the lessons to their own decisions in a meaningful way (half of answer #5) but not participate at all socially (half of answer #1). Which is my truth that is not at all correctly reflected when I answered #3.\n",
      "\n",
      "Most of my interaction with EA has been positive.    I found EA Global London to be a bit overwhelming. I hadn't been interacting with EA for a while before I attended, so I felt very \"out of the loop\", and under-qualified. I did meet a lot of great people there, but overall I didn't enjoy the conference much. I still hope to go again one day.\n",
      "\n",
      "This is likely a very temporary thing, but at the moment, I'm unemployed, and I wish the EA community could help me find a job. This would be good for me, obviously, but I genuinely think that I have a lot to offer and I think it would be good for others as well. Maybe there should be a list/group of EAs-for-hire where you post info about your skills and what you're looking for that employers can recruit from?\n",
      "\n",
      "I find the recent focus on doing a lot with a small group rather than persuading a wider audience to give to higher impact charities very off putting. There is an arrogance about it and I worry it could go very wrong. My experience with the ea community in Montreal was very uncomfortable. I generally find the focus on ai safety comcerningly self serving - working in ML is a very nice career option. The Facebook forum is deeply intimidating.   \n",
      "\n",
      "Answered 40 only with a 6 because I think the EA community is currently lacking in many areas I think and I'm worried that introducing people to EA might actually curtail their impact, mostly due to lack of diversity of opinions, career paths and expertise in EA.\n",
      "\n",
      "Being a young woman without an advanced degree, I haven't always felt like I fit the \"EA stereotype\". It has been difficult for me to make personal connections within the EA community and I would have similar concerns about introducing any of my friends to the community. \n",
      "\n",
      "Met a woman two months ago, who works as a researcher for a charitable cause fund. They had been invited to EAGlobal 2019 in SF, and attended but were turned off by the repetitious questioning they got from other participants. They described the conversations as quite stiff and instrumentalist, and found the lack of diversity in participants frustrating.    Sounds a little like the community they experienced was a little too utility-maximising in their approach to connecting to humans.\n",
      "\n",
      "Somehow didn't get along with EA people I got in touch with. See also my other comment earlier.\n",
      "\n",
      "The most thought provoking and sincere group of people I've met.\n",
      "\n",
      "I've found being involved in my local community has not only caused me to become a lot more involved in EA, but has been surprisingly good for my mental wellbeing\n",
      "\n",
      "I have in the past introduced people to EA who were on board with the concept, but put off by the fact it was associated with LessWrong and overconfident AI risk types.\n",
      "\n",
      "The EA community in Connecticut is organized mostly around students, so it’s harder for others like myself to fit in\n",
      "\n",
      "Lots of friends/classmates agree with the core principles of EA, but don't join the movement/take pledges/etc. because they perceive the movement in application as \"implemented\" (too emotionless, not strategic enough [e.g., discounting less effective campaigns, like to rescue pet dogs, that yield many donations and therefore yield a high rate of return]).\n",
      "\n",
      "There is a difference between \"I know that EA resources exist and sometimes consult them in my decision-making\" and \"I've been introduced to EA and am now an active member of the community\". I want the whole world to fall into the first category, but I'm wary of proselytizing strangers into coming to meetups etc. I really appreciate the warm, close-knit, intellectual-yet-not-obnoxious atmosphere in the community and (selfishly) worry that big waves of newcomers may endanger that.\n",
      "\n",
      "I occasionally feel as though I am not as intelligent as the average member of the EA community, which can be discouraging at times. \n",
      "\n",
      "Some people are lovely but overall I find the EA community very intense. \n",
      "\n",
      "I have many positive thoughts, and many negative experiences. My single-biggest issue with the EA community is arrogance and dogmatic thinking. I have had a difficult time getting individuals past certain 'mantras', for lack of a better word, because they feel that EA is all-or-nothing. This keeps many microdonations from reaching EA supply chains, and I believe is cumulatively worse than having people get involved in small sums at the start, with an increase as their understanding and conviction rises.\n",
      "\n",
      "obviously, not all people from all demographics will find adequate peers in the current EA community - being able to refer them to subgroups in the local community, to specialized online groups, or to international events helps a bit\n",
      "\n",
      "Imo our community was too goal oriented at the expense of friendliness & human relations / friendship. I'm working on improving that.\n",
      "\n",
      "The community is and encourages itself to be: white, male, middle to upper class, US-and UK-centric, colonialist, \"rationalist\". The community does not believe in systemic issues such as racism or sexism. The community does not consider that capitalism may be a problem. The community believes itself to be the most important cause: 'meta' charities get all the focus.    I do frequently tell friends and colleagues about EA, and encourage them to follow the principles around cause selection and donations, however I strongly discourage people from becoming involved in the community itself.\n",
      "\n",
      "Passionate about EA community\n",
      "\n",
      "Arbitrary place to vent: I feel like my local group (shout out to EA Ottawa; I hope this is not public) is not very welcoming. I feel like it's pretty condescending to non-utilitarians or people who don't get the material, and that makes me demotivated about our local group.\n",
      "\n",
      "I’m very dedicated to the core mission of EA, but my experience with the community has been a bit negative. I’m hesitant to meet more EA types because I’m not interested in discourse with people who need to posture to prove just  how rational and good they are. I understand these are not characteristics of the entire community, but have experienced enough of it to not be very interested in future engagement.\n",
      "\n",
      "I am not in the target group of the EA, not enough talent. I used to think I am a good personal fit for EA, but I updated and now think that I am not. I don't believe I can do much useful other than donating, but I do believe my donations are valuable and that's why I stay in touch.\n",
      "\n",
      "I struggle with wanting to make people aware of these efforts and getting people to donate, but feeling like I'm bragging about my own participation. Most people in my life have no idea that I'm a part of this, including my family. I have no interest in evangelizing, but it would be great to find some kind of tools to bring up these conversations to get more people involved organically.\n",
      "\n",
      "Utilitarianism gets bad rap in my academic community. Also in my wider political and cultural community, emphasis on 'rationality' is also unpopular.\n",
      "\n",
      "I think I'd introduce them to EA ideas, but with less jargon. Show them some selected EA resources and introduce them to some select people. But I just don't think \"EA\" generically has that much to offer; on the margin I want people with EA goals to be less rather than more engaged with the EA community/social network. (Because I suspect this is better for the world/higher-impact.)\n",
      "\n",
      "The job advice on 80000 hours is mostly for people in the UK or US. The \"best or nothing\" approach gives standards, which are very hard to meet and make choosing a career (especially with additional constraints like location) almost impossible.\n",
      "\n",
      "The community is a collection of many of the kindest people I've ever met; this doesn't cover every member, but I'm still surprised at the frequency with which an EA I don't know well does something or expresses some view that makes me think something like: \"Wow, that is a very moral person\".\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER principle: '*principle*', '*idea*'\n",
      "###\n",
      "\n",
      "EA needs to be more welcoming of non-English speakers and people with life experiences different to the \"classic EA\" mindset. Not diversity for the sake of diversity but instead about broadening the inputs and voices contributing to EA as a community. Some of the core ideas in EA are unconventional. But now that they have been laid down, influential members defend them against any change or further unconventional influence.\n",
      "\n",
      "I would be excited to tell a person about EA ideas, but less excited to introduce them to the EA community.\n",
      "\n",
      "I would be hesitant to introduce a friend to EA because EAs can be discouraging of do gooding that is not typical EA work but that still makes the world better. EAs also bring up racist or sexist ideas in the spirit of questioning everything, which can be alienating for people of color and women. \n",
      "\n",
      "Positive: it has changed how I view INGOs and their work, become more critical.  Negative/positive: it sometimes feel as if the movement and its members can come of as a bit single-minded: hard to talk about \"new ideas\" that does not fit into established EA views. However, this seems to have changed a bit, like GiveWell investigating opportunities to influence gov. spending and policy.\n",
      "\n",
      "I would have been more excited except that the last few times I've brought it up I was wrong about people agreeing with the core principles.\n",
      "\n",
      "Too many people are burned out by having a wrong view of how to incorporate the EA principles into their lives    \n",
      "\n",
      "Apart from the general ideas (earn to give, know where to give), the community hasn't given me much. Which is ok! All I need is someone to point me to effective charities, give overall career advice, and that's it. I spent perhaps 1h reading up on these subjects. I don't feel like all those conferences, events etc give me much more than what I now already know. Also, I feel like many discussions in forums etc become overly theoretical, especially the x-risk stuff. I think that \"here and now\" appeals to more people.\n",
      "\n",
      "I sometimes wonder if the big EA organizations are actually doing good or whether there is some significant corruption involved.     Even though I'm very sympathetic to EA, I still have my concerns about whether current EA thinking is really in line with the actual stated principles. Sometimes I wonder if donating money to charities is really going to help or whether it's just a bandage on a more systematic issue that EAs seem a bit shy about addressing (for completely understandable reasons). \n",
      "\n",
      "A significant barrier to me becoming more involved in EA is that I struggle to motivate myself to do the work necessary to get myself on a high-impact career trajectory. I've been involved in EA for five years, yet have only applied to one EA job (despite thinking I ought to apply for more), and currently still have little idea what type of job I want or what career path I want to pursue. Doing the work of creating career plans and taking action based on them is something that is hard for me and that I keep putting off.    80,000 Hours provides a lot of career advice that can be helpful to creating career plans, but it is by no means inevitable that a person who strongly agrees with core EA principles with a desire to have a high impact career will thereby transition to a high-impact career in a reasonable amount of time upon discovering 80,000 Hours. It takes a certain amount of motivation and self-direction as well. Any additional support or mentorship that any EAs can provide me to help me create EA career plans and apply to EA jobs would thus be very helpful.\n",
      "\n",
      "The career focus also doesn't work for me--I do sometimes apply for higher paying jobs thinking I could give more, but I don't want to pivot my life consciously for that end, and considering it from a career perspective I am resistant to the idea that I should be changing to something more lucrative (again, these assumptions often feel very male)\n",
      "\n",
      "I think, there needs to be a list of activities that (new) members can do, that eases them into being active EAs. Currently, it feels like many of the possible actions require taking on big projects or making big life decisions. As a student, that can feel overwhelming (and a lot of new EAs are students, right?).    I have been talking to a few of my fellow EAs in Effective Altruism Aarhus about possibly creating a database with small tasks, that one can do in a few hours or days (does this exist already?). Then researchers and organisations could add the tasks with a small motivation.  I might not be able to take on a big project, but I can definitely spend a weekend improving a researcher's code, preprocessing data, etc. This would require, that the main projects that the task contributes to, has been decided on based on EA principles of course, so the members do not have to spend hours analysing and prioritizing the tasks.  A space for thinking big, and a space for actually doing things.    An example is climate change. We all (should) know, that it is a huge problem, but few people actually have any idea about how to act on that knowledge without making big structural changes to one's life (in terms of career). By having a set of small tasks, that one can complete, we get less \"frozen\" or anxious. Obviously, EA is about having an actual impact, and sometimes people do need to make big structural changes to their lives, but perhaps having a transitional path will make it more clear, where one's skills can actually be used to solve these kinds of problems?\n",
      "\n",
      "The reason I did not answer 10 to the previous question is that the subset of the population who would find the core ideas appealing seems much larger than the one that would feel welcome/ enjoy being in the EA community. We often use a lot of jargon and forget what it's like to not be convinced of all these non-obvious conclusions (that have a lot of steps that a reasonable, well-informed person can disagree with). We also seem to forget that most people who are on board with scientific reasoning in general are better convinced with a compelling story to go along with the arguments/evidence than just the arguments in isolation (and that doesn't mean that these people don't have a place in our community). \n",
      "\n",
      "In general, I'm very glad about the level of civility in the movement, even in cases of strong disagreement. I'm also very excited about the prospect of ideas such as gains from trade through compromise, which I think relate to the high level of civility.\n",
      "\n",
      "The EA community in thoroughly awesome, but I'm not excited about introducing anyone to anything in general. When I meet someone interested by EA principles, the mere mention of the existence of a large and diverse community is usually sufficient to excite *them*.\n",
      "\n",
      "It's always remarkably hard to convey the principles of EA to someone. They bring their own emotional baggage and opinions, and my explanation is likely distorted by my own .\n",
      "\n",
      "I am solidly behind the basic ideas, but feel like most of my other views (esp. my faith) are out of step with majority of EA community, and perhaps in conflict with it on some values. Not sure whether to pursue EA under that label, or similar ideas but not under that label and better integrated with church.\n",
      "\n",
      "I feel very aligned with the core ideas of EA, however my first exposure to people in the community was underwhelming. As a generalisation, I found EA members to be more egotistical, less warm, and less socially aware than the average population. I would like to see the EA community become more diverse (especially more women and more people from humanities backgrounds), and I would like to see the community improve in social skills and interpersonal altruism. \n",
      "\n",
      "The principles of effective altruism are commendable, however, meaningful application of those principles is something which appears neglected.  Particularly analysis in this area / meta evaluation of EA \"aligned\" organisations.\n",
      "\n",
      "It's a great community for me and others like me, but seems hard to get into if you are not too interested in ideas and nerdy stuff\n",
      "\n",
      "A sort of moral elitism can be felt sometimes from those very devoted to EA principles.\n",
      "\n",
      "Reach out to more people, not just with insular EA bay area groups, but embedding EA principles more throughout society. The basic principles of EA are pretty good rationalist lenses with which to look at life and the world.\n",
      "\n",
      "Community leaders seem to be doing a good job balancing openness to new ideas while maintaining EA as an intelligible concept. Maybe a little too much favoritism shown towards AI and far future generally, but that's an inside view criticism.  \n",
      "\n",
      "I am much more interested in introducing my colleagues to EA ideas than I am to the community itself. This is mostly a matter of age and professional development.\n",
      "\n",
      "I fully identify with the principles of EA, but the community can often be off-putting, especially condescension toward non-longtermist causes.\n",
      "\n",
      "I've routinely seen women, people of color, and older people treated dismissively and/or disrespectfully. I know numerous people in those demographics who are bought into EA ideas and actively work to implement them in the world, but want little or nothing to do with the EA community.\n",
      "\n",
      "Neg:  - the movement is extremely biased towards english speaking countries . I do not see much effort - especially from the english speaking part of the movement - to change this.  - the movement is pretty undemocratic: even as someone who spends a lot of time thinking and working for EA related things I am not able to participate in a sort of election process for the leaders (such as CEA or 80k). And I see no efforts to change this.  - there seems to be a lack of exploring new ideas / ways of doing stuff: the explore / exploit tradeoff says 37%! I feel that we barely have touched 2%.  - EAs seem to neglect the donation part. Many EAs 'invest' in their careers and skip the donation part. I think these are not mutual exclusive and it should be almost obligatory to donate as an aspiring EA.  - EA is relying on signaling a lot: I have spent quite some time with people from the big universities such as Stanford, Harvard or Oxford. They do not differ much from good students at other places.  - EA is degrading the work of many people: The idea of high-impact careers could be communicated in a way so that people that are in their 30-50's don't feel bad for only being a doctor, teacher, nurse or whatever. I think the movement is thereby rejecting a lot of potentially highly valuable people.  - EA events sometimes are extremely competitive and can lack the fun that is necessary to glue together a community  - CEA's community building department with 3(!) people is ridiculous.They need more manpower!  - The EA movement is heavily dependent on Facebook, Google and Slack. Many times it is simply impossible to attend events without having a Facebook Account, CEA forces you to have an Google Account to apply for funding. The reasons for rejecting these services are numerous and there are good open alternatives.  - Additionally: Most of the time it is really really hard to get contact to local EAs because: there is no website for them, a closed facebook group, people do not answer your mails / Facebook requests.    pos:  -  All in all it is an extremely impressive movement with some of the brightest minds. I'm proud being a part of it.  \n",
      "\n",
      "I don't know much about your community, and I am not a part of it. I like your ideas, and I appreciate the work you are doing. It's possible I'm being unreasonable, but judging purely by what I've read online, especially LessWrong, your community seems too likely to be unwelcoming for me to want to try to get involved (I'm shy, and Christian, and conflict averse, and not willing to devote my life to EA, and I strongly suspect people would try to talk me out of things I don't want to have to argue about and not take no for an answer - which, again, may be unfair, but it's often the feeling I've gotten.) Your (very early) question about how involved people were was backwards, by the way, at least for me - I follow EA guidelines for donation, but my community involvement is mostly limited to reading GiveWell charity evaluations. And I would be much more excited to introduce my hypothetical friend to the body of research - and idea of \"no, we can actually do this\" - than the community, because... well, see above. I'm not part of the community, and don't know if it'd be good for hypothetical-friend. But the ideas, the work and the research and the chance to save lives, are amazing, and I really do appreciate what you're doing. I just also find you scary. Don't worry; I find lots of people scary. \n",
      "\n",
      "I have issues with the idea of prioritizing or optimizing for any one thing, due to the issues discussed in the Slate Star Codex post \"Meditations on Moloch\". I also have met EA folks who try to counter their moral intuition telling them to take actions that help people in ways other than the ones they've seemed most effective by telling themselves and others that their EA actions have \"bought their ticket to not care\". I think this is a dangerous mindset to get into as it opens up the possibility of being wrong and therefore having completely negative impact because you put all your eggs in the wrong basket. (Moloch again!)\n",
      "\n",
      "In my experience, people that thrive in the EA community have some very specific traits (beyond agreeing with the core principles) —e.g. highly motivated by abstract intellectual pursuits, a quantitative approach to problems, etc.—    Newcomers who share those traits feel at home when they join the community.    People who agree with the EA principles but do not share the traits can be put off by the community.  \n",
      "\n",
      "I like the people and the basic principles. But I think that EA people and organisations sometimes focus excessively on minor issues, which should really be part of EA, based on its core principles.\n",
      "\n",
      "I have engaged more with the EA idea than the EA community\n",
      "\n",
      "I'm very excited about the principles of EA, but it can at times feel like the people involved in the field can lack \"heart\" - over intellectualised discussion, etc. Not necessarily a bad thing (we probably need more rationality and less gut feeling in general!) but it can be a put-off for some\n",
      "\n",
      "One thing I noticed here is there is seemingly a big crossover between those interested in Jordan Peterson and EA broader community here, and that strikes me as presenting a barrier to access. What I mean is, if that is someone's first experience in the community, and they don't know to ask \"so what does this guy think and why do you believe him, \" it's likely that this subject will alienate potential new members, the ones you need for resilience and fresh ideas through diversity. \n",
      "\n",
      "Last time I was at a meetup I found myself somehow the most in-touch person present. While it was fun being the only one who knew the HPMOR URL by heart, introducing the organiser to SSC, and giving hope to the only other person present who had heard of Brian Tomasik, I wonder if it's a good or bad thing that the average general EA-related knowledge level in the community appears to be decreasing. I'd say I appreciate the diversity of ideas but am wary about losing our way, in a sense\n",
      "\n",
      "EA could benefit from being less insular.     The ideas of economists like Tyler Cowen, Robin Hanson, Glen Weyl, etc. are very relevant. There's a great deal of skepticism regarding AI risk from the broader AI research community that isn't taken seriously enough.    Generally I think the standard of diversity of ideas set by the 80,000 hours podcast is great and should be a benchmark for the community more broadly.\n",
      "\n",
      "I think my friends who're devoutly religious and/or politically conservative would be repelled by much of the EA community.  Worse, I'm afraid it would sour them on EA principles.\n",
      "\n",
      "I would feel excited to introduced them to many relevant ethical and intellectual ideas associated with EA. I would feel nervous about introducing them to the community itself -- since I think any given person has a decent chance of finding the community offputtingly insular, undersensitive to what people previously unfamiliar with EA will find weird/uncomfortable, etc. \n",
      "\n",
      "My experience with the community has been very positive, however I am more excited to discuss principles and resources than specifically the community.\n",
      "\n",
      "Fun discussions, my club should have more fundraisers, I've made some good friends (including my best friend in NY state) through the club, I'm going to start blogging lots of EA ideas (related to A.I. safety, consciousness, and economics) very soon.\n",
      "\n",
      "EA discussions are often somewhat intimidating because of the particularly high standards of specificity and accountability demanded, or at least endorsed/expected by adherents to EA principles. It can create a barrier to entry when it comes to engaging in the conversations.\n",
      "\n",
      "EA is a great principle, but it can be hard to introduce others to the concept as it can seem both somewhat rigid, and somewhat cultish.  I personally also find the 'approved' EA charities very narrow in scope (even if this is understandable).\n",
      "\n",
      "I've tried to introduce friends in the past to the most basic principles of EA. They haven't really gone for it, largely because they associate it with what they consider to be absolutely unhinged catastrophizing about the AI future coupled with millenarian hopefulness for the AI god. It's a bummer.\n",
      "\n",
      "EA still seems very idealistic and focused on those who, by virtue of privilege and lack of established obligations, can remain steadfastly idealistic. There seems less direction for those who are either well-established in their career paths or have opportunities closed to them due to personal circumstances.\n",
      "\n",
      "I think the effective altruism community is in general too insular and too meta. I think we would have more influence and benefit more from outside ideas if people didn't call themselves EAs but instead felt instead that they were part of the intellectual current known as effective altruism. \n",
      "\n",
      "I give 10% of my income according to EA principles but do not engage with the community at all (except for reading articles).\n",
      "\n",
      "It'd be great to make the resources available for more people in Latin America (translating some of the articles and core principles would be a great first step)\n",
      "\n",
      "EA lacks standardisation or a guide book which is agreed upon and updated regularly to provide a foundational understanding of EA’s principles. For this reason, I find it hard to explain what EA is uniquely.\n",
      "\n",
      "The reason it's not higher is because sometimes the community can come across a little unfriendly, and also has some pretty different ideas from the mainstream so it'd have to be a soft introduction! I also didn't get more actively involved in EA stuff for several years because I didn't feel very at home as a woman without a Philosophy post-graduate degree! This has improved a bit since but the EA community is still not at all diverse.\n",
      "\n",
      "I have had people attempt to optimize my life for me because of their dedication to effectiveness. It has been a great source of unhappiness and discomfort, largely because they value how my output metrics contribute to making the world better over actually valuing me as a living breathing human being. A person. I believe the principles of EA are solid, but they can easily be misapplied to cause harm to individuals.\n",
      "\n",
      "as to the german community: i can understand their commitment to changing the world simply via getting a fitting job. that´s great. that makes sense. but. it only makes sense, if they are better than those who would get the jobs otherwise. and somehow basically everybody in the community beliefs that they are superior to those others... even if 50% are superior, there is no exciting answer as for the rest.   some/many ea´s in germany want to stay a small group without diluting effects to the core principles. i strongly disagree. it would be great if all people would focus their donations to effective organisations. but as for the reality it might be even better, than the average organisation doubles it´s effectiveness because of hords of people starting to ask questions like: \"hey, organisation x, what do we get... is this the best way... we are not interesting in the percentage of money which reaches africa...\". i think it´s important to get the idea of effectiveness in more peoples mind. they do not need to become effective altruists.     \n",
      "\n",
      "I've found some of the EA Facebook group comments to be unnecessarily hostile. I also think that EAs could do a better job reaching out to religious communities. I can't remember the source, but I remember seeing a survey suggesting that many EAs are non-religious (admittedly, like me). However, I think that EA principles can be applied well in religious contexts, especially for those concerned with global poverty/public health.\n",
      "\n",
      "I have nothing but respect for the EA community, but some people perceive its members to be weird/nerdy. I tend to be more excited about communicating the ideas than presenting their exponents.\n",
      "\n",
      "I'm extremely glad to have found a community of people who share so many of the views I had, think rigorously and write clearly about them, can change my mind and introduce me to new ideas, and help guide and inspire and support me to really act on my principles in an effective way.\n",
      "\n",
      "Sometimes the ideas come across as a little bit \"crazy\" to normal people (e.g., wild animal suffering) which can make it hard to connect people with the community\n",
      "\n",
      "After reading about the principles of EA, I enthusiastically discussed with some of my friends. Some of my friends had already heard of EA and were already very turned off by it. They told me how the people in the community come off as \"elitist\". I now see how saying something like \"being a doctor is not a good way to save lives, you could do better being a software engineer and buying malaria nets\" can seem condescending. It loosely translates to \"you think you're doing good, but I'm doing MORE good than you.\" \n",
      "\n",
      "I feel consideration of or research into moral compass of humans and the following basis of human ethics would be a good idea, given the neuroscience of ethics:  value, practicality, reality, sentience, well-being  (the number of items \"pinged\" seems to vary from 1-5)\n",
      "\n",
      "There is not sufficient quality outreach to high schoolers, who I believe resonate with principles of EA.\n",
      "\n",
      "Lots of friends/classmates agree with the core principles of EA, but don't join the movement/take pledges/etc. because they perceive the movement in application as \"implemented\" (too emotionless, not strategic enough [e.g., discounting less effective campaigns, like to rescue pet dogs, that yield many donations and therefore yield a high rate of return]).\n",
      "\n",
      "The community is and encourages itself to be: white, male, middle to upper class, US-and UK-centric, colonialist, \"rationalist\". The community does not believe in systemic issues such as racism or sexism. The community does not consider that capitalism may be a problem. The community believes itself to be the most important cause: 'meta' charities get all the focus.    I do frequently tell friends and colleagues about EA, and encourage them to follow the principles around cause selection and donations, however I strongly discourage people from becoming involved in the community itself.\n",
      "\n",
      "It is really difficult to align your life with EA principles if you have already finished your studies before getting in contact with EA.\n",
      "\n",
      "I struggle with wanting to make people aware of these efforts and getting people to donate, but feeling like I'm bragging about my own participation. Most people in my life have no idea that I'm a part of this, including my family. I have no interest in evangelizing, but it would be great to find some kind of tools to bring up these conversations to get more people involved organically.\n",
      "\n",
      "I think I'd introduce them to EA ideas, but with less jargon. Show them some selected EA resources and introduce them to some select people. But I just don't think \"EA\" generically has that much to offer; on the margin I want people with EA goals to be less rather than more engaged with the EA community/social network. (Because I suspect this is better for the world/higher-impact.)\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER cause: '*climate*', '* ai *', '* cause*'\n",
      "###\n",
      "\n",
      "Early on, I encountered some EAs who seemed like hardliners and that turned me off - they were really adamant about not taking action on climate change, which I was passionate about at the time. (I currently believe that society should devote more resources to mitigating and adapting to climate change, but not necessarily EA.)\n",
      "\n",
      "EA can seem inaccessible and I sometimes wonder if the advice is appropriate for me. I feel like there should be more advice for those who maybe aren't going to be/ or are unable to be at the cutting edge of EA work, but would still like to be involved where their skills can be used. As in, not everyone can be an AI researcher, and so more advice for less ambitious or intellectual jobs would be good.\n",
      "\n",
      "I would love to see a more diverse array of causes represented and to get the opportunity to meet with NGOs in other fields who have an EA mindset. I worry that the increasing prominence of AI safety research is quite alienating to, say, poverty NGOs. There is very little transferrable information for advocates within the EA community to learn from computer science specialists. I think that a large portion of the EA community should be made up of AI/X-risk folks, but I think it's a shame to lose the much more accessible roots that EA sprung from.\n",
      "\n",
      "Disregarding the impacts of climate change and the 6th extinction event, even from a solely human welfare point of view seems incredibly silly, but is quite common\n",
      "\n",
      "I'd like to see less infighting among EAs. As the anonymous author of a recent 80k blog post notes, \"There’s an enormous amount of wasted time on infighting between groups working on the same cause.\"\n",
      "\n",
      "The lack of racial and gender diversity in the movement is a persistent and serious problem for the movement and I see it as direct reason why I (and others) would become less involved (this coming from someone who has dedicated most of my college years to running and EA group and who is dedicating their career to a top EA cause).    Some more thoughts about this lack of diversity.    CAUSES OF THE ISSUE:  To some extent this is \"founder effects\" and a biproduct of the fact that the movement has grown out of cities like Oxford. However, I other factors contribute; such as the inaccessible jargon and narrow definitions of \"rationality\" and \"intelligence\" that have been imported from the rationalist community. The way in which some people in our movement seem to actively derive glee from labeling cause areas and organizations as \"ineffective\" or people as \"irrational\" or \"too emotional\" is an active impediment to having a more inclusive movement.    CONSEQUENCES:  - Heightened risk of making moral errors or prioritizing the wrong issues due to homogeneity among the people in charge of charting the path of our movement.  - Smaller talent pool, loss of engagement from otherwise dedicated members (I've felt this happening myself).  \n",
      "\n",
      "The focus on AI stuff turns a lot of people off\n",
      "\n",
      "I feel like I want some more guidance that is outside of pandemic control in the realm of health - I don't want to work in it andt feel like there are other worthwhile causes\n",
      "\n",
      "I wish there were more information on volunteering causes for those of us who don't have money to donate.\n",
      "\n",
      "I think, there needs to be a list of activities that (new) members can do, that eases them into being active EAs. Currently, it feels like many of the possible actions require taking on big projects or making big life decisions. As a student, that can feel overwhelming (and a lot of new EAs are students, right?).    I have been talking to a few of my fellow EAs in Effective Altruism Aarhus about possibly creating a database with small tasks, that one can do in a few hours or days (does this exist already?). Then researchers and organisations could add the tasks with a small motivation.  I might not be able to take on a big project, but I can definitely spend a weekend improving a researcher's code, preprocessing data, etc. This would require, that the main projects that the task contributes to, has been decided on based on EA principles of course, so the members do not have to spend hours analysing and prioritizing the tasks.  A space for thinking big, and a space for actually doing things.    An example is climate change. We all (should) know, that it is a huge problem, but few people actually have any idea about how to act on that knowledge without making big structural changes to one's life (in terms of career). By having a set of small tasks, that one can complete, we get less \"frozen\" or anxious. Obviously, EA is about having an actual impact, and sometimes people do need to make big structural changes to their lives, but perhaps having a transitional path will make it more clear, where one's skills can actually be used to solve these kinds of problems?\n",
      "\n",
      "I love the community aspect of the NYC EA meetup. The people in that group have given substantial emotional support and guidance to me during a career change. With the help of the EA community, I made two important decisions in 2019. First, I decided to commit to climate change as a cause area (I was considering other cause areas). Second, I decided to leave my job in Mechanical Engineering to learn web development at App Academy. My short term goal is to earn to give to climate charities, and my long term goal is to do direct work on greenhouse gas emissions reduction.\n",
      "\n",
      "Over obsession with fraudulent issues (AGI) obsuring discussion on real world issues (poverty, climate change, human rights etc.)    Certain members are racist arseholes.\n",
      "\n",
      "I love, love, love my NYC EA group and the wonderful people I've met there.    However, \"Big EA\" has always seemed intimidating and off-putting. I was very briefly involved in an EA group in another city around 2010, and it was so unpleasant that I didn't even try to go to another until 2016, when I moved to NYC.    \"Big EA\" always feels like it's a contest who can be the biggest wonk with the mathiest brain. I get it, I get it: making tons of money and/or being extremely clever (in an EA way) are necessary for making the world a better place.    I'm not clever, and certainly not in the ways that \"Big EA\" loves and rewards. The things I'm really good at - being a social worker, being diligent and reliable and unflappable and kind - don't generate much income and don't make EAs excited.    But here I am: diligently and reliably doing the work that I was put on earth to do, making my paltry monthly donations to highly effective causes for the past ten years, and being kind and encouraging to my EA community. So, do I get to call myself an effective altruist?    For my local group, I know the answer is yes. But I always strongly suspect that \"Big EA\" (eg. EA Global, the web forums, groups in other cities, etc.) would not welcome me, and that I would be extremely uncomfortable there.\n",
      "\n",
      "Global poverty and animal welfare/rights can be easier entry points for individuals in to the EA community and focusing too heavily on far future / existential risk causes at the expense of those can dissuade other potentially EA-aligned individuals from becoming involved. I think the movement should try to avoid becoming too narrowly focused or hyper-specialized in one or two cause areas.\n",
      "\n",
      "I was disappointed EA doesn’t recommend any Climate Change charities.\n",
      "\n",
      "Worried about too large influence of AI researchers \n",
      "\n",
      "I feel the EA community has become the \"EA / Rationality\" community. I wish there was more separation between both since I'm not really interested in \"Rationality\" and I find the nerdy, AI safety focussed, super-rational approach to EA off-putting sometimes.\n",
      "\n",
      "Don't summarize EA like this to someone new: \"We are elitist who don't think climate change is important. In addition we think Nestle and Monsanto are morally good companies because they act in a capitalist way. Also it is good that we can buy T-shirts for 5€ because those textile factory workers get a few cent of that and don't have to live as a farmer anymore.\"  The friend I brought to the local EA group almost punched him.\n",
      "\n",
      "Not diverse enough. Too male, white, math & computer science, young. I can't understand most of the discussions on EA Forum and LessWrong. Too much emphasis on AI rather than global poverty. Not enough in the developing world. \n",
      "\n",
      "Since climate change is of paramount importance, I would like more guidance on a charity working on that issue that would be truly effective.\n",
      "\n",
      "I'm somewhat nervous to bring up/introduce EA because it's hard to talk about it without seeming like you're insulting people and you risk personally offending people who are very attached to certain causes.\n",
      "\n",
      "I wish they would focus more on existing risks and situations (i.e. climate change) rather than hypothetical (A.I.)\n",
      "\n",
      "It sometimes feels like the AI community dominates the conversation, as anything will have a much larger impact when you increase the timescale to centuries or millenia.  But I feel like the problems facing our world (climate change, animal rights to an extent) need to be solved this century, and maybe AI won't help us solve them.\n",
      "\n",
      "Community leaders seem to be doing a good job balancing openness to new ideas while maintaining EA as an intelligible concept. Maybe a little too much favoritism shown towards AI and far future generally, but that's an inside view criticism.  \n",
      "\n",
      "I fully identify with the principles of EA, but the community can often be off-putting, especially condescension toward non-longtermist causes.\n",
      "\n",
      "I suppose I would like a shift towards encouraging more people to \"do something\", or donate even small amounts, in whatever ways they can be motivated to do so. That being said, given other priorities than mine it may well be correct to focus on larger donors and one or a few main causes.\n",
      "\n",
      "Movement should not be narrowed down to a small subset of elite researchers on AI. The benefits of having a more diverse and broader movement are substantial.\n",
      "\n",
      "Although I'm still very much interested in the community, I've become more concerned about the current norm for doing prioritization within EA. Specifically, I think that by maximizing impact with respect to our values we end up with \"free-rider\" problems where we each focus on cause areas that only we think are important.    Also, the more weird that EA priorities get (mainly I have in mind the shift towards influencing the far future) the more difficult it is to pitch it to friends.\n",
      "\n",
      "I've been invited to apply for things at CEA, FHI, CHAI, Founders Pledge, etc. But in retrospect I don't think I had a real chance at any of them, and I wonder how many thousands of hours of optimal work we're burning on applications.    It surprises me that 80k doesn't follow the AI safety people it creates more closely, to manage saturation of the junior end of the pipeline.\n",
      "\n",
      "Though I'm now involved with EA on mostly theoretical level, I've noticed it's really important way of thinking to me, and disagreement on EA was even one of the causes on my last break-up.\n",
      "\n",
      "With the large shift towards far-future cause areas, it’s becoming much harder to welcome new people into EA. These topics are important, but less accessible to someone that is not from an engineering or science background.    I’m not suggesting that we divert attention away from these causes, but more effort needs to invested into building a pipeline/onboarding for new people to discover and engage with EA.\n",
      "\n",
      "It would be nice to have a clear and frequently updated list of what most EAs believe to be the most important cause areas. I have seen different lists around, and it can be difficult to communicate about EA to others when there is not a centralized, updated, defensible resource to use as a tool.\n",
      "\n",
      "I’ve noticed some in EA dismissing climate change as a non-major issue, as they think it can just be fixed with geoengineering. But surveys have shown this isn’t what most climate scientists think.     Otherwise all positive experiences. And great information especially by 80000 hours and Give Well\n",
      "\n",
      "The community needs to focus much more on optics and people skills, and also attempt to gain a more holistic understanding of the cause of global poverty, x risk etc (ie capitalist imperialism)\n",
      "\n",
      "I believe we need to empower individuals to take concrete actions for the sake of the various EA causes.\n",
      "\n",
      "EA could benefit from being less insular.     The ideas of economists like Tyler Cowen, Robin Hanson, Glen Weyl, etc. are very relevant. There's a great deal of skepticism regarding AI risk from the broader AI research community that isn't taken seriously enough.    Generally I think the standard of diversity of ideas set by the 80,000 hours podcast is great and should be a benchmark for the community more broadly.\n",
      "\n",
      "Mainly negative experiences are around cause priority arguments - so many people dismissing climate change because it's unlikely to be existential.  That and a general sense that people are very heavily invested in wierd positions/internal debates\n",
      "\n",
      "EA has Money and Ressources to Act and Support for the climate. Instead of discuss stuff they cant Change. \n",
      "\n",
      "As this survey will likely show, the movement has some serious diversity problems, which could be symptomatic of, or in the future cause, problems with the ideologies promoted, and if nothing else gives outsiders good reason to distrust us and makes out already controversial views lower traction. I think more thought and research should go into the causes of these problems and what if anything can be done about them.\n",
      "\n",
      "I have grown somewhat disillusioned with the EA community and philosophy.  In the community, I perceive intellectual arrogance and some cultish behaviour (although I admit this is not necessarily a \"rational\" perception, but more of an uncomfortable feeling).   In the philosophy or theoretical basis of EA, I feel that   a) the parts that feel most evident and easy to be somewhat certain of are not original (e.g. the morality of maximising utility) and  b) the parts that are original (i.e. the pointing out of particular causes, like XR) are most questionable from an epistemic point of view, hence harder to trust.   \n",
      "\n",
      "Fun discussions, my club should have more fundraisers, I've made some good friends (including my best friend in NY state) through the club, I'm going to start blogging lots of EA ideas (related to A.I. safety, consciousness, and economics) very soon.\n",
      "\n",
      "It is very important to prevent local EA groups from being taken over by aggressive militant leftists who care nothing for rationality or our core causes.\n",
      "\n",
      "I fundamentally care about helping the extreme poor, about working against climate change, and more generally leveraging my privileged position to make the world better, not worse. Effective Altruism has useful resources for me to find out how to do this. Not to be rude, but I don't really identify with the EA community. Especially on the forums there are some strange discussions such as plant welfare and the more obscure sounding apocalyptic scenarios that to me just sound outlandish.    Nonetheless there's some fantastic discussions and research here, and it's very encouraging to find like-minded people. For me EA is more of a resource. I suspect there are many people on the fringes with a similar perspective.\n",
      "\n",
      "I'd like to see more diversity of interventions financed in animal protection-related projects. I'd like to see climate change prioritazed by the EA community.\n",
      "\n",
      "I've tried to introduce friends in the past to the most basic principles of EA. They haven't really gone for it, largely because they associate it with what they consider to be absolutely unhinged catastrophizing about the AI future coupled with millenarian hopefulness for the AI god. It's a bummer.\n",
      "\n",
      "I know that this is a pretty common critique, but it feels like AI risk is being prioritized much more than it should be, simply because people are more aware of the dangers of topics they're familiar with and EA is pretty full of techies. \n",
      "\n",
      "I can experience some frustration with EA community, especially with the younger people getting involved. They can be quite dogmatic, lacking nuance in their thinking, they are also arrogant, and use EA as a signalling contest, to compete to be \"the most effective\". I have a feeling sometime that the \"altruism\" side is left on the side. I also feel that there is a lot of focus on research and researchers, while I do think it is needed, I also beleive that other type of work are very useful, especially for implementation. I have a management background and work as a consultant, and we are very few like this, and there is almost 0 jobs around this type of skills with 80000h. I think that EA could be quite elitist and only value very specific type of people (aka researcher in AI). This make the organization more and more homogenous, and makes me want to leave sometimes. \n",
      "\n",
      "I went to an EA event in Utrecht a year or so ago. I found it disappointing. There were some REALLY fantastic speakers, and I met a few really cool people. But in general the attendees seems very ill-informed. I went to a climate change workshop, and most of the people there could have learnt a huge amount just by reading the Wikipedia page. Interesting discussion was drowned out by naive questions. I did not get the impression that these were the people who were going to fix the world. Sorry for being a grumpy old git... \n",
      "\n",
      "I have had people attempt to optimize my life for me because of their dedication to effectiveness. It has been a great source of unhappiness and discomfort, largely because they value how my output metrics contribute to making the world better over actually valuing me as a living breathing human being. A person. I believe the principles of EA are solid, but they can easily be misapplied to cause harm to individuals.\n",
      "\n",
      "Find it an environment that challengs me to be ambitous, though sometimes leads to feelings of intimidation. This is, however, the main reason I involve myself - to maintain high ambitions in the 'right' cause areas. Though consequently, rejection from EA Orgs / ambitious career paths does lead to feelings of inadequacy that I might not have experienced, outside of the community. For now, I'm comfortable enough with this tradeoff.\n",
      "\n",
      "It doesn't always leave room for giving to non-urgent causes. That rigidity can turn people off.\n",
      "\n",
      "It's one of the best communities I've found for meeting nice and interesting people, the social benefits are a large part of why I spend time with EAs.  I eat meat and don't think animals have moral value, so I feel alienated by the norm of vegan food.  I think it's quite susceptible to group think, eg on controversial and difficult topics like AI Safety\n",
      "\n",
      "Excellent cause. Glad you are bringing a new perspective to doing good. Thank you for all your work. \n",
      "\n",
      "It’s simply an amazing cause:)\n",
      "\n",
      "I find the recent focus on doing a lot with a small group rather than persuading a wider audience to give to higher impact charities very off putting. There is an arrogance about it and I worry it could go very wrong. My experience with the ea community in Montreal was very uncomfortable. I generally find the focus on ai safety comcerningly self serving - working in ML is a very nice career option. The Facebook forum is deeply intimidating.   \n",
      "\n",
      "Met a woman two months ago, who works as a researcher for a charitable cause fund. They had been invited to EAGlobal 2019 in SF, and attended but were turned off by the repetitious questioning they got from other participants. They described the conversations as quite stiff and instrumentalist, and found the lack of diversity in participants frustrating.    Sounds a little like the community they experienced was a little too utility-maximising in their approach to connecting to humans.\n",
      "\n",
      "I've found being involved in my local community has not only caused me to become a lot more involved in EA, but has been surprisingly good for my mental wellbeing\n",
      "\n",
      "I have in the past introduced people to EA who were on board with the concept, but put off by the fact it was associated with LessWrong and overconfident AI risk types.\n",
      "\n",
      "The community is and encourages itself to be: white, male, middle to upper class, US-and UK-centric, colonialist, \"rationalist\". The community does not believe in systemic issues such as racism or sexism. The community does not consider that capitalism may be a problem. The community believes itself to be the most important cause: 'meta' charities get all the focus.    I do frequently tell friends and colleagues about EA, and encourage them to follow the principles around cause selection and donations, however I strongly discourage people from becoming involved in the community itself.\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER resource: '*resource*'\n",
      "###\n",
      "\n",
      "Early on, I encountered some EAs who seemed like hardliners and that turned me off - they were really adamant about not taking action on climate change, which I was passionate about at the time. (I currently believe that society should devote more resources to mitigating and adapting to climate change, but not necessarily EA.)\n",
      "\n",
      "It is great for the highly educated and resource-rich... but is hard to be embraced by 1) non-educated who are not going to have capacity/time to absorb complex messages/philosophy, and 2) people who feel they are too exhausted/stressed/indebted to give an amount that feels substantial and/or would need to force a reduced lifestyle on their families to give more.  \n",
      "\n",
      "I think we should care more about diversity especially in leading EA .org positions. I am also concerned about spending all our resources on long-termism forgetting about actual suffering of humans and animals \n",
      "\n",
      "I have a lot of anxiety about EA topics but even with 80k, it is still not clear what is best to do with my career and that's horrifying. I wish there were more resources for those who are not the top people that EA is often looking for.\n",
      "\n",
      "I'd like an onboarding guide for new members with all links and resources in one place \n",
      "\n",
      "EA feels at first like the greatest thing, but once you start to donate monthly, you quickly run out of things to do, unless you want to expend significant resources and turn EA into your full-time job. It's a bit frustrating. \n",
      "\n",
      "I thought \"Doing Good Better\" was generally well-written and have referred other people to it when the topic of conversation had to do with charitable giving and adjacent topics (like efficient resource allocations).\n",
      "\n",
      "It would be nice to have a clear and frequently updated list of what most EAs believe to be the most important cause areas. I have seen different lists around, and it can be difficult to communicate about EA to others when there is not a centralized, updated, defensible resource to use as a tool.\n",
      "\n",
      "My experience with the community has been very positive, however I am more excited to discuss principles and resources than specifically the community.\n",
      "\n",
      "I fundamentally care about helping the extreme poor, about working against climate change, and more generally leveraging my privileged position to make the world better, not worse. Effective Altruism has useful resources for me to find out how to do this. Not to be rude, but I don't really identify with the EA community. Especially on the forums there are some strange discussions such as plant welfare and the more obscure sounding apocalyptic scenarios that to me just sound outlandish.    Nonetheless there's some fantastic discussions and research here, and it's very encouraging to find like-minded people. For me EA is more of a resource. I suspect there are many people on the fringes with a similar perspective.\n",
      "\n",
      "I think there's a gap in EA in providing advice to average-to-medium-talent individuals on how to be effectively altruistic (I'm particularly thinking of career advice). It makes sense to allocate most/all resources to advising high-talent individuals who will have a much larger impact than everyone else. However, this has the effect of leaving a large population of not-high-talent individuals (who should really just be focusing on getting into a decent career and donating 10% of their income to highly effective charities) with unrealisable ambitions to change the course of humanity. This leads to a) a lot of people who identify as EAs appearing delusional, b) wasted effort being put into learning arcane facts about AI/global poverty/pandemics/etc which would be better be put into learning concrete middle-class career skills, c) frustration at career aspirations not being met. In fact, I wouldn't be surprised if a small amount of exposure to EA (enough to learn how to allocate donations to effective charities) leads not-high-talent individuals to be more effective on average, but a large amount of exposure to EA (enough to affect career decisions) actually leads to *less* total effectiveness on average.    I suspect the status quo of focusing on how high-talent individuals can be effective is in fact the most effective strategy. However, I also think that those in the inner circles of EA surrounded by lots of talent and resources are probably not aware of what I'm describing. And so this may be a problem.\n",
      "\n",
      "It'd be great to make the resources available for more people in Latin America (translating some of the articles and core principles would be a great first step)\n",
      "\n",
      "EA is great because of the people. everyone i've met has been really lovely and interesting and kind.  I'm so involved in the community because of the people i've met, and my conviction that we have shared values, concerns and beliefs.   much less so because of the core EA orgs, although I respect their work.  to me, the community is what makes EA special, and the values that have been cultivated - openness to learn, humbleness, willingness to argue and debate. and a genuine sense of caring for others.  without the community and without having met the people, investing loads of time and resources into EA, specifically community building, wouldn't have 1/10 of the appeal to me. \n",
      "\n",
      "I was enthused at the level of support that exists for new group leaders. I like that the main website (resources.eahub.org) is relatively well-organized, even though it's missing some resources that exist elsewhere. Hopefully it can become the central hub that new group leaders are sent to for getting started.\n",
      "\n",
      "There is a difference between \"I know that EA resources exist and sometimes consult them in my decision-making\" and \"I've been introduced to EA and am now an active member of the community\". I want the whole world to fall into the first category, but I'm wary of proselytizing strangers into coming to meetups etc. I really appreciate the warm, close-knit, intellectual-yet-not-obnoxious atmosphere in the community and (selfishly) worry that big waves of newcomers may endanger that.\n",
      "\n",
      "I think I'd introduce them to EA ideas, but with less jargon. Show them some selected EA resources and introduce them to some select people. But I just don't think \"EA\" generically has that much to offer; on the margin I want people with EA goals to be less rather than more engaged with the EA community/social network. (Because I suspect this is better for the world/higher-impact.)\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER animal: '*animal*'\n",
      "###\n",
      "\n",
      "In my SF Bay Area experience, I have interacted with two EA communities: EA and \"effective animal advocacy\". Both have wonderful people and many merits, although I find the EA-aligned animal advocacy community to be healthier and more welcoming. \n",
      "\n",
      "The EA community in my experience seems heavily animal rights oriented, which I do not agree with. Because the EA Forum uses a simple voting mechanism similar to Reddit's, there is the potential for a mistaken majority leading the overall movement in a wrong or suboptimal direction.\n",
      "\n",
      "I would introduce them to GiveWell, Future Perfect, and Animal Evaluators.  Besides those, my actual experience with EA on facebook has been subpar.  People seem too robotic and even rude on occasion.  They seem more interested in efficiency than they do community building.\n",
      "\n",
      "Global poverty and animal welfare/rights can be easier entry points for individuals in to the EA community and focusing too heavily on far future / existential risk causes at the expense of those can dissuade other potentially EA-aligned individuals from becoming involved. I think the movement should try to avoid becoming too narrowly focused or hyper-specialized in one or two cause areas.\n",
      "\n",
      "I think we should care more about diversity especially in leading EA .org positions. I am also concerned about spending all our resources on long-termism forgetting about actual suffering of humans and animals \n",
      "\n",
      "I am quite disappointed in the choices of animal welfare charities you recommend.  They seem to prefer to actually eliminate all farmed animals, rather than work for animals to be raised and slain more humanely.      \n",
      "\n",
      "It sometimes feels like the AI community dominates the conversation, as anything will have a much larger impact when you increase the timescale to centuries or millenia.  But I feel like the problems facing our world (climate change, animal rights to an extent) need to be solved this century, and maybe AI won't help us solve them.\n",
      "\n",
      "Over-focus on animal welfare which detracts and distracts from more important issues.\n",
      "\n",
      "I'd like to see more diversity of interventions financed in animal protection-related projects. I'd like to see climate change prioritazed by the EA community.\n",
      "\n",
      "Sometimes the ideas come across as a little bit \"crazy\" to normal people (e.g., wild animal suffering) which can make it hard to connect people with the community\n",
      "\n",
      "It's one of the best communities I've found for meeting nice and interesting people, the social benefits are a large part of why I spend time with EAs.  I eat meat and don't think animals have moral value, so I feel alienated by the norm of vegan food.  I think it's quite susceptible to group think, eg on controversial and difficult topics like AI Safety\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER giving: '*donat*', '*giving*'\n",
      "###\n",
      "\n",
      "I sometimes wonder if the big EA organizations are actually doing good or whether there is some significant corruption involved.     Even though I'm very sympathetic to EA, I still have my concerns about whether current EA thinking is really in line with the actual stated principles. Sometimes I wonder if donating money to charities is really going to help or whether it's just a bandage on a more systematic issue that EAs seem a bit shy about addressing (for completely understandable reasons). \n",
      "\n",
      "I wish there were more information on volunteering causes for those of us who don't have money to donate.\n",
      "\n",
      "I love, love, love my NYC EA group and the wonderful people I've met there.    However, \"Big EA\" has always seemed intimidating and off-putting. I was very briefly involved in an EA group in another city around 2010, and it was so unpleasant that I didn't even try to go to another until 2016, when I moved to NYC.    \"Big EA\" always feels like it's a contest who can be the biggest wonk with the mathiest brain. I get it, I get it: making tons of money and/or being extremely clever (in an EA way) are necessary for making the world a better place.    I'm not clever, and certainly not in the ways that \"Big EA\" loves and rewards. The things I'm really good at - being a social worker, being diligent and reliable and unflappable and kind - don't generate much income and don't make EAs excited.    But here I am: diligently and reliably doing the work that I was put on earth to do, making my paltry monthly donations to highly effective causes for the past ten years, and being kind and encouraging to my EA community. So, do I get to call myself an effective altruist?    For my local group, I know the answer is yes. But I always strongly suspect that \"Big EA\" (eg. EA Global, the web forums, groups in other cities, etc.) would not welcome me, and that I would be extremely uncomfortable there.\n",
      "\n",
      "Julia Wise is a god damned hero. I stan a queen!   heard about 80k giving career advice that is bad for the individual. For example, telling them to study to be qualified for a position with not enough available roles. \n",
      "\n",
      "I really like the community group dinners. I think it would be cool for us to do volunteer work together. Obviously in Seattle it would be lower-impact than donating malaria nets, but it would still make a difference and is something that people could do.\n",
      "\n",
      "I'm especially curious how EA mixes with religion - the vast majority of donations in the U.S. are religiously motivated - it always struck me as odd that the vast majority of EAs hadn't given more thought to interfacing with religious people\n",
      "\n",
      "EA feels at first like the greatest thing, but once you start to donate monthly, you quickly run out of things to do, unless you want to expend significant resources and turn EA into your full-time job. It's a bit frustrating. \n",
      "\n",
      "I thought \"Doing Good Better\" was generally well-written and have referred other people to it when the topic of conversation had to do with charitable giving and adjacent topics (like efficient resource allocations).\n",
      "\n",
      "I suppose I would like a shift towards encouraging more people to \"do something\", or donate even small amounts, in whatever ways they can be motivated to do so. That being said, given other priorities than mine it may well be correct to focus on larger donors and one or a few main causes.\n",
      "\n",
      "Neg:  - the movement is extremely biased towards english speaking countries . I do not see much effort - especially from the english speaking part of the movement - to change this.  - the movement is pretty undemocratic: even as someone who spends a lot of time thinking and working for EA related things I am not able to participate in a sort of election process for the leaders (such as CEA or 80k). And I see no efforts to change this.  - there seems to be a lack of exploring new ideas / ways of doing stuff: the explore / exploit tradeoff says 37%! I feel that we barely have touched 2%.  - EAs seem to neglect the donation part. Many EAs 'invest' in their careers and skip the donation part. I think these are not mutual exclusive and it should be almost obligatory to donate as an aspiring EA.  - EA is relying on signaling a lot: I have spent quite some time with people from the big universities such as Stanford, Harvard or Oxford. They do not differ much from good students at other places.  - EA is degrading the work of many people: The idea of high-impact careers could be communicated in a way so that people that are in their 30-50's don't feel bad for only being a doctor, teacher, nurse or whatever. I think the movement is thereby rejecting a lot of potentially highly valuable people.  - EA events sometimes are extremely competitive and can lack the fun that is necessary to glue together a community  - CEA's community building department with 3(!) people is ridiculous.They need more manpower!  - The EA movement is heavily dependent on Facebook, Google and Slack. Many times it is simply impossible to attend events without having a Facebook Account, CEA forces you to have an Google Account to apply for funding. The reasons for rejecting these services are numerous and there are good open alternatives.  - Additionally: Most of the time it is really really hard to get contact to local EAs because: there is no website for them, a closed facebook group, people do not answer your mails / Facebook requests.    pos:  -  All in all it is an extremely impressive movement with some of the brightest minds. I'm proud being a part of it.  \n",
      "\n",
      "I don't know much about your community, and I am not a part of it. I like your ideas, and I appreciate the work you are doing. It's possible I'm being unreasonable, but judging purely by what I've read online, especially LessWrong, your community seems too likely to be unwelcoming for me to want to try to get involved (I'm shy, and Christian, and conflict averse, and not willing to devote my life to EA, and I strongly suspect people would try to talk me out of things I don't want to have to argue about and not take no for an answer - which, again, may be unfair, but it's often the feeling I've gotten.) Your (very early) question about how involved people were was backwards, by the way, at least for me - I follow EA guidelines for donation, but my community involvement is mostly limited to reading GiveWell charity evaluations. And I would be much more excited to introduce my hypothetical friend to the body of research - and idea of \"no, we can actually do this\" - than the community, because... well, see above. I'm not part of the community, and don't know if it'd be good for hypothetical-friend. But the ideas, the work and the research and the chance to save lives, are amazing, and I really do appreciate what you're doing. I just also find you scary. Don't worry; I find lots of people scary. \n",
      "\n",
      "I love the blog Giving Gladly and the supportive and informative emails I get from Givewell. I don't think I would ever feel comfortable attending an EA event because I'm not \"pure-EA\" enough. I am not planning on changing to a higher earning career, though of course I will do what I can to earn the most I can within my field (massage therapy/energy healing). I feel that my spiritual beliefs would not be accepted in the EA community or would simply make people feel uncomfortable. But I wish that that weren't the case so I could make EA friends without feeling like my own decisions will be frowned upon. \n",
      "\n",
      "A harsh take is that it comes across as a movement for rich educated people. You pretty much have to be rich enough to donate, or otherwise successful enough in the professional sphere to make EA-related career choices, which doesn't leave much room for more marginalized folks to get involved. \n",
      "\n",
      "Last time I was at a meetup I found myself somehow the most in-touch person present. While it was fun being the only one who knew the HPMOR URL by heart, introducing the organiser to SSC, and giving hope to the only other person present who had heard of Brian Tomasik, I wonder if it's a good or bad thing that the average general EA-related knowledge level in the community appears to be decreasing. I'd say I appreciate the diversity of ideas but am wary about losing our way, in a sense\n",
      "\n",
      "If I'm being completely honest I probably prefer engaging in the community passively, rather than in person, etc, at least for the moment because I feel I'll be judged for not donating enough, living a too-high quality of life, etc\n",
      "\n",
      "I get that EA (at least from my view and how it's explained to me) is about rationality and a more consequentialist way of thinking. But this modality of spreading the message is, pardon my french, dogshit (IMO).    Everyone I've interacted w/ at EA is so emotionless and too logical; too academic too and not pragmatic enough.    So many look at problems just in terms of numbers instead of seeing what is in front of their own eyes.    Overall, though I can relate to these people as I've worked in tech/STEM for so long, 99% of the general public, IMO, will think they're robots.    It's no way to market what is a very important movement to push.    People in the EA movement, from my view, need to improve their people skills and think more pragmatically.    Otherwise you will have the typical business-douchebags who can talk-the-talk and spin things effectively walk all over the EA side of the fence.    Also, re 80k, maybe I'm misinterpreting their mission, but again, it seems like they think people are robots. You can't expect people en masse to work shitty jobs they don't find maximally fulfilling and donate a decent chunk of their salary to people on the other side of the world.    It's instances like this where a clear lack of human understanding plagues EAs — from my view, anyway.    It just seems to me everything is so oriented towards analytical-thinking that the actual foundational empathy required to do-good is lost.    All just my opinion that I imagine most will disagree with.    Just my observation as somebody who does has dealt with the software-engineer types my whole career. I see similar patterns.\n",
      "\n",
      "It can be difficult to understand what the up to the minute recommendations are donating to specific charities or taking certain career paths. I don’t have the time to do the research and I appreciate the info on GiveWell and other sites but there’s often a disclaimer that the data is a year or two out of date but without much follow up on where to go. \n",
      "\n",
      "I think there's a gap in EA in providing advice to average-to-medium-talent individuals on how to be effectively altruistic (I'm particularly thinking of career advice). It makes sense to allocate most/all resources to advising high-talent individuals who will have a much larger impact than everyone else. However, this has the effect of leaving a large population of not-high-talent individuals (who should really just be focusing on getting into a decent career and donating 10% of their income to highly effective charities) with unrealisable ambitions to change the course of humanity. This leads to a) a lot of people who identify as EAs appearing delusional, b) wasted effort being put into learning arcane facts about AI/global poverty/pandemics/etc which would be better be put into learning concrete middle-class career skills, c) frustration at career aspirations not being met. In fact, I wouldn't be surprised if a small amount of exposure to EA (enough to learn how to allocate donations to effective charities) leads not-high-talent individuals to be more effective on average, but a large amount of exposure to EA (enough to affect career decisions) actually leads to *less* total effectiveness on average.    I suspect the status quo of focusing on how high-talent individuals can be effective is in fact the most effective strategy. However, I also think that those in the inner circles of EA surrounded by lots of talent and resources are probably not aware of what I'm describing. And so this may be a problem.\n",
      "\n",
      "It seems to share the biases common to the tech community which skews white, relatively affluent, kinda libertarian and very male, and has trouble considering realities that primarily affect other groups to be truly important, despite the real justification for taking a macro perspective on the effects of giving \n",
      "\n",
      "Sometimes I think EA makes people focus too narrowly and not acknowledge the bigger picture, for example how giving can impact facets of a person's life (education) rather than just one (malaria prevention).\n",
      "\n",
      "I said 6 to question 40 because as much as I would enjoy sharing EA with others, I am weary to get them too excited about a community that is challenging to break into - apart from getting a job at an EA org, aligning with an EA career path and donating, EA doesn't have much of a community or culture beyond attending a local event (if one exists) and going to  global. Many other brands and movements have strong cultures that will pull people away from EA. In the long-run I imagine EA will become more of a tool that many people use to select careers and less of an established community with a strong identity and lifestyle. \n",
      "\n",
      "It was easier to introduce and \"sell\" EA previously, when there was more focus from the core organizations on near-term issues and donating\n",
      "\n",
      "as to the german community: i can understand their commitment to changing the world simply via getting a fitting job. that´s great. that makes sense. but. it only makes sense, if they are better than those who would get the jobs otherwise. and somehow basically everybody in the community beliefs that they are superior to those others... even if 50% are superior, there is no exciting answer as for the rest.   some/many ea´s in germany want to stay a small group without diluting effects to the core principles. i strongly disagree. it would be great if all people would focus their donations to effective organisations. but as for the reality it might be even better, than the average organisation doubles it´s effectiveness because of hords of people starting to ask questions like: \"hey, organisation x, what do we get... is this the best way... we are not interesting in the percentage of money which reaches africa...\". i think it´s important to get the idea of effectiveness in more peoples mind. they do not need to become effective altruists.     \n",
      "\n",
      "I think the EA community has a number of blind spots and biases which put it in danger of simply becoming the Silicon Valley style of giving, rather than a distinctive philosophical approach\n",
      "\n",
      "It doesn't always leave room for giving to non-urgent causes. That rigidity can turn people off.\n",
      "\n",
      "It's a bit disheartening to me to see so few likes/shares on EA's (MacAskill, GiveWell, etc) social channels. Any new YouTube content makes me really happy. Future Perfect makes me happy. Publishing the results of my donations and the community's donations is extremely motivational for me\n",
      "\n",
      "Lots of friends/classmates agree with the core principles of EA, but don't join the movement/take pledges/etc. because they perceive the movement in application as \"implemented\" (too emotionless, not strategic enough [e.g., discounting less effective campaigns, like to rescue pet dogs, that yield many donations and therefore yield a high rate of return]).\n",
      "\n",
      "I have many positive thoughts, and many negative experiences. My single-biggest issue with the EA community is arrogance and dogmatic thinking. I have had a difficult time getting individuals past certain 'mantras', for lack of a better word, because they feel that EA is all-or-nothing. This keeps many microdonations from reaching EA supply chains, and I believe is cumulatively worse than having people get involved in small sums at the start, with an increase as their understanding and conviction rises.\n",
      "\n",
      "The community is and encourages itself to be: white, male, middle to upper class, US-and UK-centric, colonialist, \"rationalist\". The community does not believe in systemic issues such as racism or sexism. The community does not consider that capitalism may be a problem. The community believes itself to be the most important cause: 'meta' charities get all the focus.    I do frequently tell friends and colleagues about EA, and encourage them to follow the principles around cause selection and donations, however I strongly discourage people from becoming involved in the community itself.\n",
      "\n",
      "I am not in the target group of the EA, not enough talent. I used to think I am a good personal fit for EA, but I updated and now think that I am not. I don't believe I can do much useful other than donating, but I do believe my donations are valuable and that's why I stay in touch.\n",
      "\n",
      "I struggle with wanting to make people aware of these efforts and getting people to donate, but feeling like I'm bragging about my own participation. Most people in my life have no idea that I'm a part of this, including my family. I have no interest in evangelizing, but it would be great to find some kind of tools to bring up these conversations to get more people involved organically.\n",
      "\n",
      "\n",
      "\n",
      "###\n",
      "CLUSTER lonely: '*lonely*', '*remote*', '*connection*', '*closer*'\n",
      "###\n",
      "\n",
      "I'm not sure what the community comprises of, or how I can get more involved, as I live somewhere quite remote. \n",
      "\n",
      "Still looking for people in the broader category of Doing Good Better, and feeling lonely in the movement as an older woman in a small town.\n",
      "\n",
      "I wish I felt closer to the community and that I could have help starting a local group. \n",
      "\n",
      "EA suffers from a terrible lack of diversity and inclusion. As a non-White member of the community from a lower income background, I often felt very alienated, lonely, and unwelcome at international EA gatherings such as at EA Globals in 2017 and 2018. I also feel that many EAs including 80 000 Hours career coaches lack empathy for and understanding of people with my kinds of backgrounds and lived experiences such as having faced significant financial stress, relied on some form of charity food aid, lived with systemic and persistent racial discrimination including in the job market, and also being active in a religious community. I have also been very unwell these last few years, and felt very uncared for during EA Globals, and was at high risk of having a serious health incident, and no one noticed or even reached out in kindness even as I wandered around the conference venue alone and in distress. This could be because they don't understand that distress is expressed differently in different cultures and they lack the intercultural understanding to read different signals of distress. More diversity and inclusion in EA could have made me feel more welcome and supported. \n",
      "\n",
      "I do share EA connection with like minded freinds\n",
      "\n",
      "I'm not blaming anyone but myself, but it would be nice if it were easier to have real EA friends remotely. Like maybe their could be some slightly facilitated thing where remote EAs could call each other once a week.\n",
      "\n",
      "Sad it isn’t bigger so that there was a closer local group, harder to get to meet ups far away. Would prefer if the talks were more practical focused. \n",
      "\n",
      "I really love EA and would love to live in one of the EA houses and / or work at an EA organization. The blocker for me is lack of connection until that point. Going to events and meeting people is nice, and the job board is great, but until I'm actively immersed in EA on a daily basis, I feel I'm missing a lot.\n",
      "\n",
      "Being a young woman without an advanced degree, I haven't always felt like I fit the \"EA stereotype\". It has been difficult for me to make personal connections within the EA community and I would have similar concerns about introducing any of my friends to the community. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manual_loadings = {'diversity': ['divers', 'white', 'men ', 'man ', 'young', 'inclusi', 'exclusi', 'unwelcom'],\n",
    "                   'weird': ['weird', 'awkward', 'social', 'offputting', 'comfortable',\n",
    "                             'cult', 'rude', 'nerd', 'off-putting', 'offputting'],\n",
    "                   'elitist': ['elitis', 'hostile', 'condescen', 'dismissive'],\n",
    "                   'hard': ['intimidat', 'hard', 'difficult', 'overwhelm', 'tiring', 'obscure'],\n",
    "                   'job': ['job', 'career', '80'],\n",
    "                   'community': ['community', 'movement', 'people', 'group', 'individual'],\n",
    "                   'principle': ['principle', 'idea'],\n",
    "                   'cause': ['climate', ' ai ', ' cause'],\n",
    "                   'resource': ['resource'],\n",
    "                   'animal': ['animal'],\n",
    "                   'giving': ['donat', 'giving'],\n",
    "                   'lonely': ['lonely', 'remote', 'connection', 'closer']}\n",
    "\n",
    "def count_loadings(details):\n",
    "    loading_counts = {}\n",
    "    loading_occurances = {}\n",
    "    for name, loadings in manual_loadings.items():\n",
    "        for detail in details:\n",
    "            clean_detail = clean_text(detail)\n",
    "            found = False\n",
    "            for loading in loadings:\n",
    "                if loading in clean_detail:\n",
    "                    found = True\n",
    "            if found:\n",
    "                if loading_counts.get(name):\n",
    "                    loading_counts[name] += 1\n",
    "                    loading_occurances[name] += [detail]\n",
    "                else:\n",
    "                    loading_counts[name] = 1\n",
    "                    loading_occurances[name] = [detail]\n",
    "    return loading_counts, loading_occurances\n",
    "    \n",
    "loading_counts, loading_occurances = count_loadings([v for v in group['details'].values])\n",
    "print(sorted(list(loading_counts.items()), key=lambda x: x[1], reverse=True))\n",
    "print('')\n",
    "print('')\n",
    "for k, vs in loading_occurances.items():\n",
    "    print('###')\n",
    "    print('CLUSTER {}: {}'.format(k, ', '.join(['\\'*{}*\\''.format(w) for w in manual_loadings[k]])))\n",
    "    print('###')\n",
    "    print('')\n",
    "    for v in vs:\n",
    "        print(v)\n",
    "        print('')\n",
    "    print('')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
